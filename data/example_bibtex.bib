


@article{Krishnamoorthy2021ADF,
  title={A distributed feedback-based online process optimization framework for optimal resource sharing},
  author={D. Krishnamoorthy},
  journal={Journal of Process Control},
  year={2021},
  volume={97},
  pages={72-83}
}

@article{Paulson2022a,
author = {Paulson, Joel and Makrigiorgos, George and Mesbah, Ali},
year = {2022},
month = {01},
pages = {},
title = {Adversarially Robust Bayesian Optimization for Efficient Auto‐Tuning of Generic Control Structures under Uncertainty},
journal = {AIChE Journal},
doi = {10.1002/aic.17591}
}

@article{makrigiorgos2022,
author = {Makrigiorgos, George and Bonzanini, Angelo Domenico and Miller, Victor and Mesbah, Ali},
year = {2022},
month = {03},
pages = {107770},
title = {Performance-Oriented Model Learning for Control via Multi-Objective Bayesian Optimization},
journal = {Computers \& Chemical Engineering},
doi = {10.1016/j.compchemeng.2022.107770}
}

@article{allman2022107777,
title = {Distributed fairness-guided optimization for coordinated demand response in multi-stakeholder process networks},
journal = {Computers \& Chemical Engineering},
volume = {161},
pages = {107777},
year = {2022},
issn = {0098-1354},
doi = {https://doi.org/10.1016/j.compchemeng.2022.107777},
url = {https://www.sciencedirect.com/science/article/pii/S0098135422001181},
author = {Andrew Allman and Qi Zhang},
keywords = {Industrial demand response, Coordination, Nash bargaining, Distributed optimization, ADMM},
abstract = {Demand response has become an essential operating paradigm for enabling high penetration of intermittent, renewable energy into the power grid. To maximize a process’s potential to perform demand response, it is important to not only consider that single process but also coordinate with the entire network of self-interested supplier and customer entities. In this work, we develop optimization formulations that enable the network-wide coordination of different processes’ operating schedules such that the benefits of coordination are shared fairly amongst stakeholders. We propose methods for solving the problems in a distributed manner that allow stakeholders to retain data privacy and avoid sharing their process models with one another. Computational studies are performed to analyze the difference in costs for different formulations and the difference in computational performance for different distributed algorithms. The applicability of the proposed approaches to problems of practical significance is further demonstrated through a chlorine network case study.}
}

@book{garnett_bayesoptbook_2022,
  author    = {Garnett, Roman},
  title     = {{Bayesian Optimization}},
  year      = {2022},
  publisher = {Cambridge University Press},
  note      = {in preparation}
}

@INPROCEEDINGS{vanDeBerg2022,  author={Damien van de Berg and Panagiotis Petsagkourakis and Nilay Shah and Ehecatl Antonio del Rio-Chanona},  booktitle={14th International Symposium on Process Systems Engineering (accepted)},   title={Data-driven distributed optimization for systems consisting of expensive black-box subproblems},   year={2022},  volume={},  number={},  pages={},  doi={}}

@article{yang2019278,
title = {A survey of distributed optimization},
journal = {Annual Reviews in Control},
volume = {47},
pages = {278-305},
year = {2019},
issn = {1367-5788},
doi = {https://doi.org/10.1016/j.arcontrol.2019.05.006},
url = {https://www.sciencedirect.com/science/article/pii/S1367578819300082},
author = {Tao Yang and Xinlei Yi and Junfeng Wu and Ye Yuan and Di Wu and Ziyang Meng and Yiguang Hong and Hong Wang and Zongli Lin and Karl H. Johansson},
keywords = {Distributed optimization, Coordination of distributed energy resources},
abstract = {In distributed optimization of multi-agent systems, agents cooperate to minimize a global function which is a sum of local objective functions. Motivated by applications including power systems, sensor networks, smart buildings, and smart manufacturing, various distributed optimization algorithms have been developed. In these algorithms, each agent performs local computation based on its own information and information received from its neighboring agents through the underlying communication network, so that the optimization problem can be solved in a distributed manner. This survey paper aims to offer a detailed overview of existing distributed optimization algorithms and their applications in power systems. More specifically, we first review discrete-time and continuous-time distributed optimization algorithms for undirected graphs. We then discuss how to extend these algorithms in various directions to handle more realistic scenarios. Finally, we focus on the application of distributed optimization in the optimal coordination of distributed energy resources.}
}

@INPROCEEDINGS{Tsianos2012,  author={Tsianos, Konstantinos I. and Lawlor, Sean and Rabbat, Michael G.},  booktitle={2012 50th Annual Allerton Conference on Communication, Control, and Computing (Allerton)},   title={Consensus-based distributed optimization: Practical issues and applications in large-scale machine learning},   year={2012},  volume={},  number={},  pages={1543-1550},  doi={10.1109/Allerton.2012.6483403}}

@article{Fourer2010,
 ISSN = {0030364X, 15265463},
 URL = {http://www.jstor.org/stable/40984032},
 abstract = {We describe a research project to design a distributed optimization environment in which solvers, modeling languages, registries, analyzers, and simulation engines can be implemented as services and utilities under a unified framework. Our work, which we call optimization services or OS, defines standards for all activities necessary to support decentralized optimization on the Internet: representation of optimization instances, results, and solver options; communication between clients and solvers; and discovery and registration of optimization-related software using the concept of Web services. In this paper we place emphasis on issues in distributed computing that are posed by the special character of optimization. We also describe a reference implementation that is freely available as an open-source project of COIN-OR.},
 author = {Robert Fourer and Jun Ma and Kipp Martin},
 journal = {Operations Research},
 number = {6},
 pages = {1624--1636},
 publisher = {INFORMS},
 title = {Optimization Services: A Framework for Distributed Optimization},
 urldate = {2022-04-11},
 volume = {58},
 year = {2010}
}

@web_page{animalFeedstock,
   title = {Tables of composition and nutritional values of feed materials INRA CIRAD AFZ},
   url = {https://www.feedtables.com/},
}


@inproceedings{XuADMM,
author = {Xu, Yi and Liu, Mingrui and Lin, Qihang and Yang, Tianbao},
title = {ADMM without a Fixed Penalty Parameter: Faster Convergence with New Adaptive Penalization},
year = {2017},
isbn = {9781510860964},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Alternating direction method of multipliers (ADMM) has received tremendous interest for solving numerous problems in machine learning, statistics and signal processing. However, it is known that the performance of ADMM and many of its variants is very sensitive to the penalty parameter of a quadratic penalty applied to the equality constraints. Although several approaches have been proposed for dynamically changing this parameter during the course of optimization, they do not yield theoretical improvement in the convergence rate and are not directly applicable to stochastic ADMM. In this paper, we develop a new ADMM and its linearized variant with a new adaptive scheme to update the penalty parameter. Our methods can be applied under both deterministic and stochastic optimization settings for structured non-smooth objective function. The novelty of the proposed scheme lies at that it is adaptive to a local sharpness property of the objective function, which marks the key difference from previous adaptive scheme that adjusts the penalty parameter per-iteration based on certain conditions on iterates. On theoretical side, given the local sharpness characterized by an exponent θ ∈ (0,1], we show that the proposed ADMM enjoys an improved iteration complexity of \^{O} (1/ε1-θ)1 in the deterministic setting and an iteration complexity of \^{O}(1/ε2(1-θ)) in the stochastic setting without smoothness and strong convexity assumptions. The complexity in either setting improves that of the standard ADMM which only uses a fixed penalty parameter. On the practical side, we demonstrate that the proposed algorithms converge comparably to, if not much faster than, ADMM with a fine-tuned fixed penalty parameter.},
booktitle = {Proceedings of the 31st International Conference on Neural Information Processing Systems},
pages = {1267–1277},
numpages = {11},
location = {Long Beach, California, USA},
series = {NIPS'17}
}

@article{Ghadimi,
author = {Ghadimi, Euhanna and Teixeira, André and Shames, Iman and Johansson, Mikael},
year = {2014},
month = {09},
pages = {},
title = {Optimal Parameter Selection for the Alternating Direction Method of Multipliers (ADMM): Quadratic Problems},
journal = {IEEE Transactions on Automatic Control},
doi = {10.1109/TAC.2014.2354892}
}

@article{Chen,
author = {Chen, Cheng-Liang and Lee, Wen-Cheng},
year = {2004},
month = {06},
pages = {1131-1144},
title = {Multi-objective optimization of multi-echelon supply chain networks with uncertain product demands and prices},
volume = {28},
journal = {computers \& Chemical Engineering},
doi = {10.1016/j.compchemeng.2003.09.014}
}

@incollection{ZAVALA2016169,
title = {Chapter Seven - Managing Conflicts Among Decision-Makers in Multiobjective Design and Operations},
editor = {Gerardo Ruiz-Mercado and Heriberto Cabezas},
booktitle = {Sustainability in the Design, Synthesis and Analysis of Chemical Engineering Processes},
publisher = {Butterworth-Heinemann},
address = {Oxford},
pages = {169-180},
year = {2016},
isbn = {978-0-12-802032-6},
doi = {https://doi.org/10.1016/B978-0-12-802032-6.00007-4},
url = {https://www.sciencedirect.com/science/article/pii/B9780128020326000074},
author = {V.M. Zavala},
keywords = {Conditional-value-at-risk metric, Decision making, Disagreement, Multiobjective, Pareto front, Stakeholders},
abstract = {We present a systematic framework to manage conflicts among decision makers (stakeholders) arising in multiobjective design and operations of process systems. Conflicts arise in these settings because stakeholders have different opinions about objectives and/or their relative priorities. The proposed framework factors in the opinion of all the stakeholders and computes a compromise solution that seeks to minimize disagreement among the stakeholders. A key advantage of the framework is that it does not require the computation of a Pareto front and can thus be used to address problems with many stakeholders and objectives. Examples are presented to illustrate the concepts.}
}

@article{SHAH2004929,
title = {Pharmaceutical supply chains: key issues and strategies for optimisation},
journal = {computers \& Chemical Engineering},
volume = {28},
number = {6},
pages = {929-941},
year = {2004},
note = {FOCAPO 2003 Special issue},
issn = {0098-1354},
doi = {https://doi.org/10.1016/j.compchemeng.2003.09.022},
url = {https://www.sciencedirect.com/science/article/pii/S0098135403002333},
author = {Nilay Shah},
keywords = {Pharmaceutical industries, Supply chain optimisation, Pipeline management},
abstract = {Supply chain optimisation is now a major research theme in process operations and management. A great deal of research has been undertaken on facility location and design, inventory and distribution planning, capacity and production planning and detailed scheduling. Only a small proportion of this work directly addresses the issues faced in the pharmaceutical sector. On the other hand, this sector is very much ready for and in need of sophisticated supply chain optimisation techniques. At the supply chain design stage, a particular problem faced by this industry is the need to balance future capacity with anticipated demands in the face of the very significant uncertainty that arises out of clinical trials and competitor activity. Efficient capacity utilisation plans and robust infrastructure investment decisions will be important as regulatory pressures increase and margins are eroded. The ability to locate nodes of the supply chain in tax havens and optimise trading and transfer price structures results in interesting degrees of freedom in the supply chain design problem. Prior even to capacity planning comes the problem of pipeline and testing planning, where the selection of products for development and the scheduling of the development tasks requires a careful management of risk and potential rewards. At the operation stage, it is often difficult to ensure responsiveness. Most pharmaceutical products involve primary active ingredient (AI) production (often multi-stage chemical synthesis or bioprocess) and secondary (formulation) production. Both of the stages are characterised by low manufacturing velocities and are hampered by the need for quality assurance activities at several points. It is not unusual for the overall supply chain cycle time to be 300 days. In this environment, supply chain debottlenecking and decoupling strategies together with co-ordinated inventory management are crucial for quick responses to changing market trends. A good understanding of what actually drives the supply chain dynamics is also required. As often as not, erratic dynamics are introduced by business processes rather than by external demand, and may be eliminated by the re-design of internal business processes or supplier/customer relationships. This paper will consider important issues in supply chain design and operation drawn from the literature and from our collaborative research projects in this area. The main features of the problems will be reviewed as will the literature to date. Some strategies for solution will be identified, as will some future research needs.}
}


@Article{Sarkis,
AUTHOR = {Sarkis, Miriam and Bernardi, Andrea and Shah, Nilay and Papathanasiou, Maria M.},
TITLE = {Emerging Challenges and Opportunities in Pharmaceutical Manufacturing and Distribution},
JOURNAL = {Processes},
VOLUME = {9},
YEAR = {2021},
NUMBER = {3},
ARTICLE-NUMBER = {457},
URL = {https://www.mdpi.com/2227-9717/9/3/457},
ISSN = {2227-9717},
ABSTRACT = {The rise of personalised and highly complex drug product profiles necessitates significant advancements in pharmaceutical manufacturing and distribution. Efforts to develop more agile, responsive, and reproducible manufacturing processes are being combined with the application of digital tools for seamless communication between process units, plants, and distribution nodes. In this paper, we discuss how novel therapeutics of high-specificity and sensitive nature are reshaping well-established paradigms in the pharmaceutical industry. We present an overview of recent research directions in pharmaceutical manufacturing and supply chain design and operations. We discuss topical challenges and opportunities related to small molecules and biologics, dividing the latter into patient- and non-specific. Lastly, we present the role of process systems engineering in generating decision-making tools to assist manufacturing and distribution strategies in the pharmaceutical sector and ultimately embrace the benefits of digitalised operations.},
DOI = {10.3390/pr9030457}
}

@article{GARCIA201649,
title = {The water-energy-food nexus and process systems engineering: A new focus},
journal = {computers \& Chemical Engineering},
volume = {91},
pages = {49-67},
year = {2016},
note = {12th International Symposium on Process Systems Engineering \& 25th European Symposium of Computer Aided Process Engineering (PSE-2015/ESCAPE-25), 31 May - 4 June 2015, Copenhagen, Denmark},
issn = {0098-1354},
doi = {https://doi.org/10.1016/j.compchemeng.2016.03.003},
url = {https://www.sciencedirect.com/science/article/pii/S0098135416300552},
author = {Daniel J. Garcia and Fengqi You},
keywords = {Water-energy-food nexus, Modeling and optimization of multiple spatial and temporal scales, Life cycle optimization, Multi-scale modeling, Modeling of multiple stakeholders},
abstract = {As the global population grows, consumption of water, energy, and food will also increase, placing stresses on these three sectors, raising the importance of the Water-Energy-Food Nexus (WEFN). This article highlights research challenges and identifies process systems engineering research opportunities to appropriately model and optimize the WEFN. A brief overview of relevant, foundational WEFN research is first presented. We then identify challenges in the multiple scales of the WEFN, ranging from the household scale to the global scale. There are further challenges with appropriate system boundary definitions, and challenges in modeling the decision-making and conflicting objectives of multiple stakeholders in the WEFN. Uncertainties of all kinds appear at all scales of the WEFN and must also be considered. We use two motivating WEFN examples to frame these challenges and propose future avenues and opportunities for research. Possible approaches to the abovementioned challenges are proposed.}
}

@article{SAMPAT2017296,
title = {Optimization formulations for multi-product supply chain networks},
journal = {computers \& Chemical Engineering},
volume = {104},
pages = {296-310},
year = {2017},
issn = {0098-1354},
doi = {https://doi.org/10.1016/j.compchemeng.2017.04.021},
url = {https://www.sciencedirect.com/science/article/pii/S0098135417301849},
author = {Apoorva M. Sampat and Edgar Martin and Mariano Martin and Victor M. Zavala},
keywords = {Multi-product, Graph, Supply chain, Priorities, Multi-stakeholders, Organic waste},
abstract = {We present optimization formulations for multi-product supply chain networks. The formulations use a general graph representation that captures dependencies between an arbitrary number of products, technologies, and transportation paths. We discuss how to use the framework to compute compromise solutions that resolve geographical and stakeholder conflicts. We present case studies in which we seek to design supply chains to collect and process organic waste from a large number of farms in the State of Wisconsin to mitigate point phosphorus and methane emissions.}
}

@article{SHAH20051225,
title = {Process industry supply chains: Advances and challenges},
journal = {computers \& Chemical Engineering},
volume = {29},
number = {6},
pages = {1225-1235},
year = {2005},
note = {Selected Papers Presented at the 14th European Symposium on Computer Aided Process Engineering},
issn = {0098-1354},
doi = {https://doi.org/10.1016/j.compchemeng.2005.02.023},
url = {https://www.sciencedirect.com/science/article/pii/S009813540500013X},
author = {Nilay Shah},
keywords = {Network design, Supply chain modelling and planning, Future challenges},
abstract = {A large body of work exists in process industry supply chain optimisation. We describe the state of the art of research in infrastructure design, modelling and analysis and planning and scheduling, together with some industrial examples. We draw some conclusions about the degree to which different classes of problem have been solved, and discuss challenges for the future.}
}

@inproceedings{McMahan2017CommunicationEfficientLO,
  title={Communication-Efficient Learning of Deep Networks from Decentralized Data},
  author={H. B. McMahan and Eider Moore and Daniel Ramage and Seth Hampson and Blaise Ag{\"u}era y Arcas},
  booktitle={AISTATS},
  year={2017}
}

@BOOK{yang,  author={Yang, Qiang and Liu, Yang and Cheng, Yong and Kang, Yan and Chen, Tianjian and Yu, Han},  booktitle={Federated Learning},  year={2019},  volume={},  number={},  pages={},  doi={}}

@INPROCEEDINGS{Crypt,  author={Yao, Andrew C.},  booktitle={23rd Annual Symposium on Foundations of Computer Science (sfcs 1982)},   title={Protocols for secure computations},   year={1982},  volume={},  number={},  pages={160-164},  doi={10.1109/SFCS.1982.38}}

@article{RODRIGUEZBARROSO2020270,
title = {Federated Learning and Differential Privacy: Software tools analysis, the Sherpa.ai FL framework and methodological guidelines for preserving data privacy},
journal = {Information Fusion},
volume = {64},
pages = {270-292},
year = {2020},
issn = {1566-2535},
doi = {https://doi.org/10.1016/j.inffus.2020.07.009},
url = {https://www.sciencedirect.com/science/article/pii/S1566253520303213},
author = {Nuria Rodríguez-Barroso and Goran Stipcich and Daniel Jiménez-López and José Antonio Ruiz-Millán and Eugenio Martínez-Cámara and Gerardo González-Seco and M. Victoria Luzón and Miguel Angel Veganzones and Francisco Herrera},
keywords = {Federated learning, Differential privacy, Software framework,  Federated Learning framework},
abstract = {The high demand of artificial intelligence services at the edges that also preserve data privacy has pushed the research on novel machine learning paradigms that fit these requirements. Federated learning has the ambition to protect data privacy through distributed learning methods that keep the data in its storage silos. Likewise, differential privacy attains to improve the protection of data privacy by measuring the privacy loss in the communication among the elements of federated learning. The prospective matching of federated learning and differential privacy to the challenges of data privacy protection has caused the release of several software tools that support their functionalities, but they lack a unified vision of these techniques, and a methodological workflow that supports their usage. Hence, we present the Sherpa.ai Federated Learning framework that is built upon a holistic view of federated learning and differential privacy. It results from both the study of how to adapt the machine learning paradigm to federated learning, and the definition of methodological guidelines for developing artificial intelligence services based on federated learning and differential privacy. We show how to follow the methodological guidelines with the Sherpa.ai Federated Learning framework by means of a classification and a regression use cases.}
}

@article{kairouz,
url = {http://dx.doi.org/10.1561/2200000083},
year = {2021},
volume = {14},
journal = {Foundations and Trends in Machine Learning},
title = {Advances and Open Problems in Federated Learning},
doi = {10.1561/2200000083},
issn = {1935-8237},
number = {1–2},
pages = {1-210},
author = {Peter Kairouz and H. Brendan McMahan and Brendan Avent and Aurélien Bellet and Mehdi Bennis and Arjun Nitin Bhagoji and Kallista Bonawitz and Zachary Charles and Graham Cormode and Rachel Cummings and Rafael G. L. D’Oliveira and Hubert Eichner and Salim El Rouayheb and David Evans and Josh Gardner and Zachary Garrett and Adrià Gascón and Badih Ghazi and Phillip B. Gibbons and Marco Gruteser and Zaid Harchaoui and Chaoyang He and Lie He and Zhouyuan Huo and Ben Hutchinson and Justin Hsu and Martin Jaggi and Tara Javidi and Gauri Joshi and Mikhail Khodak and Jakub Konecný and Aleksandra Korolova and Farinaz Koushanfar and Sanmi Koyejo and Tancrède Lepoint and Yang Liu and Prateek Mittal and Mehryar Mohri and Richard Nock and Ayfer Özgür and Rasmus Pagh and Hang Qi and Daniel Ramage and Ramesh Raskar and Mariana Raykova and Dawn Song and Weikang Song and Sebastian U. Stich and Ziteng Sun and Ananda Theertha Suresh and Florian Tramèr and Praneeth Vepakomma and Jianyu Wang and Li Xiong and Zheng Xu and Qiang Yang and Felix X. Yu and Han Yu and Sen Zhao}
}

@article{maestre2011,
author = {Maestre, J.M. and Pena, D. and Camacho, Eduardo},
year = {2011},
month = {03},
pages = {153 - 176},
title = {Distributed model predictive control based on a cooperative game},
volume = {32},
journal = {Optimal Control Applications and Methods},
doi = {10.1002/oca.940}
}

@book {Fudenberg,
	title = {Game Theory},
	year = {1991},
	note = {Translated into Chinesse by Renin University Press, Bejing: China. },
	publisher = {MIT Press},
	organization = {MIT Press},
	address = {Cambridge, MA},
	author = {Drew Fudenberg and Jean Tirole}
}

@misc{gurobi,
  author = {{Gurobi Optimization, LLC}},
  title = {{Gurobi Optimizer Reference Manual}},
  year = 2022,
  url = "https://www.gurobi.com"
}

@book{bynum2021pyomo,
title={Pyomo--optimization modeling in python},
author={Bynum, Michael L. and Hackebeil, Gabriel A. and Hart, William E. and Laird, Carl D. and Nicholson, Bethany L. and Siirola, John D. and Watson, Jean-Paul and Woodruff, David L.},
edition={Third},
volume={67},
year={2021},
publisher={Springer Science \& Business Media}
}
@article{hart2011pyomo,
title={Pyomo: modeling and solving mathematical programs in Python},
author={Hart, William E and Watson, Jean-Paul and Woodruff, David L},
journal={Mathematical Programming Computation},
volume={3},
number={3},
pages={219--260},
year={2011},
publisher={Springer}
}

@manual{NLopt,
author = {Steven G. Johnson},
title = "The NLopt nonlinear-optimization package",
year = 2020,
url = "http://github.com/stevengj/nlopt"
}

@article{LI2021109407,
title = {Surrogate-based distributed optimisation for expensive black-box functions},
journal = {Automatica},
volume = {125},
pages = {109407},
year = {2021},
issn = {0005-1098},
doi = {https://doi.org/10.1016/j.automatica.2020.109407},
url = {https://www.sciencedirect.com/science/article/pii/S0005109820306099},
author = {Zhongguo Li and Zhen Dong and Zhongchao Liang and Zhengtao Ding},
keywords = {Distributed algorithms, Expensive optimisation methods, Black-box functions, Surrogate models, Multi-agent systems},
abstract = {This paper considers distributed optimisation problems with black-box functions using surrogate-assisted methods. Since the cost functions and their derivatives are usually impossible to be expressed by explicit functions due to the complexity of modern systems, function calls have to be performed to obtain those values. Moreover, the cost functions are often expensive to evaluate, and therefore designers prefer to reduce the number of evaluations. In this paper, surrogate-based methods are utilised to approximate the true functions, and conditions for constructing smooth and convex surrogates are established, by which the requirements for explicit functions are eliminated. To improve the quality of surrogate models, a distance-based infill strategy is proposed to balance the exploitation and exploration, which guarantees the density of the decision sequence in a compact set. Then, a distributed optimisation algorithm is developed to solve the reformulated auxiliary sub-problems, and the convergence of the proposed algorithm is established via Lyapunov theory. Simulation examples are provided to validate the effectiveness of the theoretical development and demonstrate the potential significance of the framework.}
}

@article{Nishihara2015AGA,
  title={A General Analysis of the Convergence of ADMM},
  author={Robert Nishihara and Laurent Lessard and Benjamin Recht and Andrew Packard and Michael I. Jordan},
  journal={ArXiv},
  year={2015},
  volume={abs/1502.02009}
}

@inbook{Beykal,
author = {Beykal, Burcu and Avraamidou, Styliani and Pistikopoulos, Efstratios},
year = {2021},
month = {01},
pages = {1707-1713},
title = {Bi-level Mixed-Integer Data-Driven Optimization of Integrated Planning and Scheduling Problems},
volume = {50},
isbn = {9780323885065},
journal = {Computer Aided Chemical Engineering},
doi = {10.1016/B978-0-323-88506-5.50265-5}
}

@article{buccini,
author = {Buccini, Alessandro and Dell'Acqua, Pietro and Donatelli, Marco},
year = {2020},
month = {11},
pages = {},
title = {A general framework for ADMM acceleration},
volume = {85},
journal = {Numerical Algorithms},
doi = {10.1007/s11075-019-00839-y}
}

@article{rodriguez,
author = {Rodriguez, Jose and Nicholson, Bethany and Laird, Carl and Zavala, Victor},
year = {2018},
month = {08},
pages = {},
title = {Benchmarking ADMM in nonconvex NLPs},
volume = {119},
journal = {Computers \& Chemical Engineering},
doi = {10.1016/j.compchemeng.2018.08.036}
}

@ARTICLE{shin,  author={Shin, Sungho and Hart, Philip and Jahns, Thomas and Zavala, Victor M.},  journal={IEEE Transactions on Control of Network Systems},   title={A Hierarchical Optimization Architecture for Large-Scale Power Networks},   year={2019},  volume={6},  number={3},  pages={1004-1014},  doi={10.1109/TCNS.2019.2906917}}

@article{Heever,
author = {Heever, Susara and Grossmann, Ignacio},
year = {2001},
month = {06},
pages = {},
title = {A Lagrangean Decomposition Heuristic for the Design and Planning of Offshore Hydrocarbon Field Infrastructures with Complex Economic Objectives},
volume = {40},
journal = {Industrial & Engineering Chemistry Research - IND ENG CHEM RES},
doi = {10.1021/ie000755e}
}

@article{Sousa,
author = {Sousa, Rui and Liu, Songsong and Papageorgiou, Lazaros and Shah, Nilay},
year = {2011},
month = {11},
pages = {2396-2409},
title = {Global supply chain planning for pharmaceuticals},
volume = {89},
journal = {Chemical Engineering Research \& Design - CHEM ENG RES DES},
doi = {10.1016/j.cherd.2011.04.005}
}

@article{TerrazasMoreno2011,
author = {Terrazas-Moreno, Sebastian and Grossmann, Ignacio},
year = {2011},
month = {10},
pages = {4307-4318},
title = {A multiscale decomposition method for the optimal planning and scheduling of multi-site continuous multiproduct plants},
volume = {66},
journal = {Chemical Engineering Science - CHEM ENG SCI},
doi = {10.1016/j.ces.2011.03.017}
}

@article{TerrazasMoreno2011TemporalAS,
  title={Temporal and spatial Lagrangean decompositions in multi-site, multi-period production planning problems with sequence-dependent changeovers},
  author={Sebastian Terrazas-Moreno and Philipp A. Trotter and Ignacio E. Grossmann},
  journal={Comput. Chem. Eng.},
  year={2011},
  volume={35},
  pages={2913-2928}
}

@article{Oliveira2013ALD,
  title={A Lagrangean decomposition approach for oil supply chain investment planning under uncertainty with risk considerations},
  author={F. Oliveira and Vijay Gupta and Silvio Hamacher and Ignacio E. Grossmann},
  journal={Comput. Chem. Eng.},
  year={2013},
  volume={50},
  pages={184-195}
}

@article{Jackson,
author = {Jackson, Jennifer R. and Grossmann, Ignacio E.},
title = {Temporal Decomposition Scheme for Nonlinear Multisite Production Planning and Distribution Models},
journal = {Industrial \& Engineering Chemistry Research},
volume = {42},
number = {13},
pages = {3045-3055},
year = {2003},
doi = {10.1021/ie030070p},
URL = { 
        https://doi.org/10.1021/ie030070p
},
eprint = { 
        https://doi.org/10.1021/ie030070p
}
}


@book{Santoso,
author = {Santoso, Tjendera and Ahmed, Shabbir and Goetschalckx, Marc and Shapiro, Alexander},
year = {2003},
month = {07},
pages = {},
title = {A stochastic programming approach for supply chain network design under uncertainty},
doi = {10.18452/8297}
}

@article{Halit,
author = {Uster, Halit and Easwaran, Gopalakrishnan and Akcali, Elif and Çetinkaya, Sila},
year = {2007},
month = {12},
pages = {890 - 907},
title = {Benders decomposition with alternative multiple cuts for a multi-product closed-loop supply chain network design model},
volume = {54},
journal = {Naval Research Logistics (NRL)},
doi = {10.1002/nav.20262}
}

@article{OLIVEIRA201447,
title = {Accelerating Benders stochastic decomposition for the optimization under uncertainty of the petroleum product supply chain},
journal = {Computers \& Operations Research},
volume = {49},
pages = {47-58},
year = {2014},
issn = {0305-0548},
doi = {https://doi.org/10.1016/j.cor.2014.03.021},
url = {https://www.sciencedirect.com/science/article/pii/S0305054814000768},
author = {F. Oliveira and I.E. Grossmann and S. Hamacher},
keywords = {Stochastic programming, Supply chain investment planning, Stochastic Benders decomposition, Acceleration techniques},
abstract = {This paper addresses the solution of a two-stage stochastic programming model for an investment planning problem applied to the petroleum products supply chain. In this context, we present the development of acceleration techniques for the stochastic Benders decomposition that aim to strengthen the cuts generated, as well as to improve the quality of the solutions obtained during the execution of the algorithm. Computational experiments are presented for assessing the efficiency of the proposed framework. We compare the performance of the proposed algorithm with two other acceleration techniques. Results suggest that the proposed approach is able to efficiently solve the problem under consideration, achieving better performance in terms of computational times when compared to other two techniques.}
}

@article{Pishvaee_Razmi_Torabi_2014,
title = {An accelerated Benders decomposition algorithm for sustainable supply chain network design under uncertainty: A case study of medical needle and syringe supply chain},
journal = {Transportation Research Part E: Logistics and Transportation Review},
volume = {67},
pages = {14-38},
year = {2014},
issn = {1366-5545},
doi = {https://doi.org/10.1016/j.tre.2014.04.001},
url = {https://www.sciencedirect.com/science/article/pii/S1366554514000520},
author = {M.S. Pishvaee and J. Razmi and S.A. Torabi},
keywords = {Supply chain management, Sustainability, Benders decomposition, Possibilistic programming, Social responsibility, Life cycle assessment},
abstract = {This paper proposes a multi-objective possibilistic programming model to design a sustainable medical supply chain network under uncertainty considering conflicting economic, environmental and social objectives. Effective social and environmental life cycle assessment-based methods are incorporated in the model to estimate the relevant environmental and social impacts. An accelerated Benders decomposition algorithm utilizing three efficient acceleration mechanisms is devised to cope with computational complexity of solving the proposed model. Computational analysis is also provided by using a medical industrial case study to present the significance of the proposed model as well as the efficiency of the accelerated Benders decomposition algorithm.}
}

@article{Dogan2006ADM,
  title={A Decomposition Method for the Simultaneous Planning and Scheduling of Single-Stage Continuous Multiproduct Plants},
  author={Muge Erdirik Dogan and Ignacio E. Grossmann},
  journal={Industrial \& Engineering Chemistry Research},
  year={2006},
  volume={45},
  pages={299-315}
}

@article{Iyer1998ABD,
  title={A Bilevel Decomposition Algorithm for Long-Range Planning of Process Networks},
  author={Ramaswamy R. Iyer and Ignacio E. Grossmann},
  journal={Industrial \& Engineering Chemistry Research},
  year={1998},
  volume={37},
  pages={474-481}
}

@article{Bok_2000,
	doi = {10.1021/ie990526w},
	url = {https://doi.org/10.1021%2Fie990526w},
	year = 2000,
	month = {mar},
	publisher = {American Chemical Society ({ACS})},
	volume = {39},
	number = {5},
	pages = {1279--1290},
	author = {Jin-Kwang Bok and Ignacio E. Grossmann and Sunwon Park},
	title = {Supply Chain Optimization in Continuous Flexible Process Networks},
	journal = {Industrial {\&} Engineering Chemistry Research}
}

@article{Geoffrion1970,
abstract = {A framework of concepts is developed which helps to unify a substantial portion of the literature on large-scale mathematical programming. These concepts fall into two categories. The first category consists of problem manipulations that can be used to derive what are often referred to as "master" problems; the principal manipulations discussed are Projection, Inner Linearization, and Outer Linearization. The second category consists of solution strategies that can be used to solve the master problems, often with the result that "subproblems" arise which can then be solved by specialized algorithms. The Piecewise, Restriction, and Relaxation strategies are the principal ones discussed. Numerous algorithms found in the literature are classified according to the manipulation/strategy pattern they can be viewed as using, and the usefulness of the framework is demonstrated by using it (see Part II of this paper) to rederive a representative selection of algorithms. The material presented is listed in the following order: The first section is introductory in nature, and discusses types of large-scale problems, the scope of discussion and the literature, and the notation used. The second section, entitled "Problem Manipulations: Source of 'Master' Problems" covers the subjects of projection, inner linearization and outer linearization. The third section, "Solution Strategies: Source of 'Subproblems'," discusses piecewise strategy, restriction and relaxation. The fourth section is entitled "Synthesizing Known Algorithms from Manipulations and Strategies," and is followed by a concluding section and an extensive bibliography.},
author = {Geoffrion, Arthur M.},
doi = {10.1287/mnsc.16.11.652},
issn = {0025-1909},
journal = {Management Science},
month = {jul},
number = {11},
pages = {652--675},
publisher = {Institute for Operations Research and the Management Sciences (INFORMS)},
title = {{Elements of Large-Scale Mathematical Programming Part I: Concepts}},
url = {https://pubsonline.informs.org/doi/abs/10.1287/mnsc.16.11.652},
volume = {16},
year = {1970}
}
@inproceedings{DelRioChanona2019,
abstract = {This paper investigates modifier-adaptation schemes based on Gaussian processes to handle plant-model mismatch in real-time optimization of uncertain processes. Building upon the recent work by Ferreira et al. [European Control Conference, 2018], we present two improved algorithms that rely on trust-region ideas in order to speed-up and robustify the approach. The first variant introduces a conventional trust region on the input variables, whose radius is adjusted based on the Gaussian process predictors' ability to capture the cost and constraint mismatch. The second variant exploits the variance estimates from the Gaussian processes to define multiple trust regions directly on the cost and constraint predictors. These algorithms are demonstrated and compared on a Williams-Otto reactor benchmark problem.},
author = {{Del Rio Chanona}, E. A. and {Alves Graciano}, J. E. and Bradford, E. and Chachuat, B.},
booktitle = {IFAC-PapersOnLine},
doi = {10.1016/j.ifacol.2019.06.036},
file = {::},
issn = {24058963},
keywords = {Gaussian process,Modifier adaptation,Real-time optimization,Trust region},
month = {jan},
number = {1},
pages = {52--57},
publisher = {Elsevier B.V.},
title = {{Modifier-adaptation schemes employing Gaussian processes and trust regions for real-time optimization}},
volume = {52},
year = {2019}
}
@article{Yue2017,
abstract = {While Stackelberg leader–follower games and bilevel programming have become increasingly prevalent in game-theoretic modeling and optimization of decentralized supply chains, existing models can only handle linear programming or quadratic programming followers' problems. When discrete decisions are involved in the follower's problem, the resulting lower-level mixed-integer program prohibits direct transformation of the bilevel program into a single-level mathematical program using the KKT conditions. To address this challenge, we propose a mixed-integer bilevel programming (MIBP) modeling framework and solution algorithm for optimal supply chain design and operations, where the follower is allowed to have discrete decisions, e.g., facility location, technology selection, and opening/shutting-down of production lines. A reformulation-and-decomposition algorithm is developed for global optimization of the MIBP problems. A case study on an integrated forestry and biofuel supply chain is presented to demonstrate the application, along with comparisons to conventional centralized modeling and optimization methods.},
author = {Yue, Dajun and You, Fengqi},
doi = {10.1016/J.COMPCHEMENG.2016.07.026},
file = {:C\:/Users/dv516/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Yue, You - 2017 - Stackelberg-game-based modeling and optimization for supply chain design and operations A mixed integer bilevel progra.pdf:pdf},
issn = {0098-1354},
journal = {Computers \& Chemical Engineering},
month = {jul},
pages = {81--95},
publisher = {Pergamon},
title = {{Stackelberg-game-based modeling and optimization for supply chain design and operations: A mixed integer bilevel programming framework}},
url = {https://www.sciencedirect.com/science/article/pii/S0098135416302460?via%3Dihub},
volume = {102},
year = {2017}
}

@techreport{Cartis2019,
abstract = {We apply a state-of-the-art, local derivative-free solver, Py-BOBYQA [8], to global optimization problems, and propose an algorithmic improvement that is beneficial in this context. Our numerical findings are illustrated on a commonly-used but small-scale test set of global optimization problems [1] and associated noisy variants, and on hyperparameter tuning for the machine learning test set MNIST [48]. As Py-BOBYQA is a model-based trust-region method, we compare mostly (but not exclusively) with other global optimization methods for which (global) models are important, such as Bayesian optimization and response surface methods; we also consider state-of-the-art representative determin-istic and stochastic codes, such as DIRECT and CMA-ES. As a heuristic for escaping local minima, we find numerically that Py-BOBYQA is competitive with global optimization solvers for all accuracy/budget regimes, in both smooth and noisy settings. In particular, Py-BOBYQA variants are best performing for smooth and multiplicative noise problems in high-accuracy regimes. As a by-product, some preliminary conclusions can be drawn on the relative performance of the global solvers we have tested with default settings.},
archivePrefix = {arXiv},
arxivId = {1812.11343v2},
author = {Cartis, Coralia and Roberts, Lindon and Sheridan-Methven, Oliver},
eprint = {1812.11343v2},
file = {:C\:/Users/dv516/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Cartis, Roberts, Sheridan-Methven - 2019 - Escaping local minima with derivative-free methods a numerical investigation.pdf:pdf},
keywords = {90C26,90C30,90C56,derivative-free optimization,global optimization,trust region methods Mathematics Subject Classific},
title = {{Escaping local minima with derivative-free methods: a numerical investigation}},
year = {2019}
}
@article{Lucia2015,
abstract = {We address the problemof controlling interconnected, possibly large-scale systems of systems using distributed model predictive control. We consider the case in which the nonlinear subsystems can be coupled physically and can have shared constraints. The presented approach is based on the transmission of contracts between neighboring subsystems. Contracts are guaranteed sequences of possible future trajectories or trajectory sets of the coupling variables of the subsystems. We derive for the approach sufficient conditions for guaranteeing recursive feasibility and Input-to-State stability. Furthermore, we discuss the case of the so-called Plug & Play operations in which a subsystem in the network is replaced by a new, possibly different, one and when a subsystem is removed or added to the network.},
author = {Lucia, Sergio and K{\"{o}}gel, Markus and Findeisen, Rolf},
doi = {10.1016/J.IFACOL.2015.11.284},
file = {:C\:/Users/dv516/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Lucia, K{\"{o}}gel, Findeisen - 2015 - Contract-based Predictive Control of Distributed Systems with Plug and Play Capabilities.pdf:pdf},
issn = {2405-8963},
journal = {IFAC-PapersOnLine},
month = {jan},
number = {23},
pages = {205--211},
publisher = {Elsevier},
title = {{Contract-based Predictive Control of Distributed Systems with Plug and Play Capabilities}},
url = {https://www.sciencedirect.com/science/article/pii/S2405896315025689},
volume = {48},
year = {2015}
}
@article{Zheng2016,
abstract = {The platooning of autonomous vehicles has the potential to significantly improve traffic capacity, enhance highway safety, and reduce fuel consumption. This paper studies the scalability limitations of large-scale vehicular platoons moving in rigid formation, and proposes two basic ways to improve stability margins, i.e., enlarging information topology and employing asymmetric control. A vehicular platoon is considered as a combination of four components: 1) node dynamics; 2) decentralized controller; 3) information flow topology; and 4) formation geometry. Tools, such as the algebraic graph theory and matrix factorization technique, are employed to model and analyze scalability limitations. The major findings include: 1) under linear identical decentralized controllers, the stability thresholds of control gains are explicitly established for platoons under undirected topologies. It is proved that the stability margins decay to zero as the platoon size increases unless there is a large number of following vehicles pinned to the leader and 2) the stability margins of vehicular platoons under bidirectional topologies using asymmetric controllers are always bounded away from zero and independent of the platoon size. Simulations with a platoon of passenger cars are used to demonstrate the findings.},
author = {Zheng, Yang and Li, Shengbo Eben and Li, Keqiang and Wang, Le Yi},
doi = {10.1109/TCST.2015.2483564},
issn = {10636536},
journal = {IEEE Transactions on Control Systems Technology},
keywords = {Autonomous vehicles,decentralized control,platoon,scalability,stability margin},
month = {jul},
number = {4},
pages = {1253--1265},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{Stability Margin Improvement of Vehicular Platoon Considering Undirected Topology and Asymmetric Control}},
volume = {24},
year = {2016}
}
@inproceedings{Kouzoupis2016a,
abstract = {Nonlinear Model Predictive Control (NMPC) requires the online solution of a nonlinear Optimal Control Problem (OCP) at each sampling instant. This paper presents a novel, block based and highly parallelizable algorithm which solves nonlinear OCPs using a recently proposed Augmented Lagrangian based method (ALADIN). The latter employs techniques from standard Sequential Quadratic Programming (SQP) methods within a more parallelizable framework. An implementation tailored to optimal control is proposed where Nonlinear Programs (NLPs) are solved approximately and concurrently on each stage while a centralized consensus step is used to update the dual variables of the coupling constraints. The implementation also comprises algorithmic concepts to extend the parallelizability of the consensus step and a blocking technique to accelerate convergence. The performance of the resulting scheme is illustrated using as benchmark example the control of an overhead crane.},
author = {Kouzoupis, Dimitris and Quirynen, Rien and Houska, Boris and Diehl, Moritz},
booktitle = {Proceedings of the American Control Conference},
doi = {10.1109/ACC.2016.7525066},
isbn = {9781467386821},
issn = {07431619},
title = {{A block based ALADIN scheme for highly parallelizable direct Optimal Control}},
year = {2016}
}
@techreport{Gonzalez,
abstract = {The popularity of Bayesian optimization methods for efficient exploration of parameter spaces has lead to a series of papers applying Gaussian processes as surrogates in the optimization of functions. However, most proposed approaches only allow the exploration of the parameter space to occur sequentially. Often, it is desirable to simultaneously propose batches of parameter values to explore. This is particularly the case when large parallel processing facilities are available. These could either be computational or physical facets of the process being optimized. Batch methods, however, require the modeling of the interaction between the different evaluations in the batch, which can be expensive in complex scenarios. We investigate this issue and propose a highly effective heuristic based on an estimate of the func-tion's Lipschitz constant that captures the most important aspect of this interaction-local repulsion-at negligible computational overhead. A penalized acquisition function is used to collect batches of points minimizing the non-parallelizable computational effort. The resulting algorithm compares very well, in run-time, with much more elaborate alternatives.},
author = {Gonz{\'{a}}lez, Javier and Dai, Zhenwen and Hennig, Philipp and Lawrence, Neil},
file = {::},
title = {{Batch Bayesian Optimization via Local Penalization}},
url = {http://sheffieldml.github.io/GPyOpt/.}
}
@article{Chu2014,
abstract = {We solve the challenging problem of integrated planning, scheduling, and dynamic optimization for sequential batch processes with fixed batch sizes. The integrated problem is first formulated into a complicated mixed-integer dynamic optimization (MIDO) problem that is then discretized into a large-scale mixed-integer nonlinear programing (MINLP) problem. There are a planning model, multiple scheduling models in planning periods, and a number of dynamic models describing task execution processes. To efficiently solve the complex MINLP problem, we develop two efficient methods that separate the subproblems using surrogate models to represent the linking functions. The first method decomposes the dynamic optimization problems from the integrated planning and scheduling problem where the surrogate models represent task processing costs dependent on the processing times. The second method further decomposes the scheduling problems from the planning problem where the surrogate models represent production costs dependent on production quantities. Compared to the direct solution approach, the proposed methods reduce the computational time by more than 4 orders of magnitude in the case studies. {\textcopyright} 2014 American Chemical Society.},
author = {Chu, Yunfei and You, Fengqi},
doi = {10.1021/ie501986d},
file = {::},
issn = {15205045},
journal = {Industrial and Engineering Chemistry Research},
month = {aug},
number = {34},
pages = {13391--13411},
publisher = {American Chemical Society},
title = {{Integrated planning, scheduling, and dynamic optimization for batch processes: MINLP model formulation and efficient solution methods via surrogate modeling}},
url = {https://pubs.acs.org/sharingguidelines},
volume = {53},
year = {2014}
}
@article{Beykal2018,
abstract = {This work presents recent advances within the AlgoRithms for Global Optimization of coNstrAined grey-box compUTational problems (ARGONAUT) framework, developed for optimization of systems which lack analytical forms and derivatives. A new parallel version of ARGONAUT (p-ARGONAUT) is introduced to solve high dimensional problems with a large number of constraints. This development is motivated by a challenging case study, namely the operation of an oilfield using water-flooding. The objective of this case study is the maximization of the Net Present Value over a five-year time horizon by manipulating the well pressures, while satisfying a set of complicating constraints related to water-cut limitations and water handling and storage. Dimensionality reduction is performed via the parametrization of the pressure control domain, which is then followed by global optimization of the constrained grey-box system. Results are presented for multiple case studies and the performance of p-ARGONAUT is compared to existing derivative-free optimization methods.},
author = {Beykal, Burcu and Boukouvala, Fani and Floudas, Christodoulos A. and Sorek, Nadav and Zalavadia, Hardikkumar and Gildin, Eduardo},
doi = {10.1016/j.compchemeng.2018.01.005},
issn = {00981354},
journal = {Computers \& Chemical Engineering},
keywords = {Derivative-free optimization,Grey/black-box optimization,Oil-well control,Oilfield operations,Waterflooding},
month = {jun},
pages = {99--110},
publisher = {Elsevier Ltd},
title = {{Global optimization of grey-box computational systems using surrogate functions and application to highly constrained oil-field operations}},
volume = {114},
year = {2018}
}
@article{Agrawal2017,
abstract = {We describe a modular rewriting system for translating optimization problems written in a domain-specific language to forms compatible with low-level solver interfaces. Translation is facilitated by reductions, which accept a category of problems and transform instances of that category to equivalent instances of another category. Our system proceeds in two key phases: analysis, in which we attempt to find a suitable solver for a supplied problem, and canonicalization, in which we rewrite the problem in the selected solver's standard form. We implement the described system in version 1.0 of CVXPY, a domain-specific language for mathematical and especially convex optimization. By treating reductions as first-class objects, our method makes it easy to match problems to solvers well-suited for them and to support solvers with a wide variety of standard forms.},
archivePrefix = {arXiv},
arxivId = {1709.04494},
author = {Agrawal, Akshay and Verschueren, Robin and Diamond, Steven and Boyd, Stephen},
eprint = {1709.04494},
file = {::},
journal = {Journal of Control and Decision},
keywords = {Convex optimization,domain-specific languages,reductions,rewriting systems},
month = {sep},
number = {1},
pages = {42--60},
publisher = {Taylor and Francis Ltd.},
title = {{A Rewriting System for Convex Optimization Problems}},
url = {http://arxiv.org/abs/1709.04494},
volume = {5},
year = {2017}
}
@techreport{Kimiaei2020,
abstract = {For the unconstrained optimization of black box functions, this paper presents a new stochastic algorithm called VSBBO. In practice, VSBBO matches the quality of other state-of-the-art algorithms for finding, in small and large dimensions, a local minimizer with reasonable accuracy. Although our theory guarantees only local minimizers our heuristic techniques turn VSBBO into an efficient global solver. In very thorough numerical experiments, we found in most cases either a global minimizer, or where this could not be checked, at least a point of similar quality with the best competitive global solvers. For smooth, everywhere defined functions, it is proved that, with probability arbitrarily close to 1, the basic version of our algorithm finds with O(nRR −2) function evaluations a point with gradient 2-norm ≤ , where n is the dimension and R is the number of random directions used in each iteration. In the smooth convex case, this number improves to O(nRR −1) and in the smooth (strongly) convex case to O(nR log −1). This matches known recent complexity results for reaching a slightly different goal, namely the expected gradient 2-norm ≤ .},
author = {Kimiaei, Morteza and Neumaier, Arnold},
file = {::},
keywords = {primary 90C56},
title = {{Efficient global unconstrained black box optimization}},
url = {http://www.mat.univie.ac.at/$\sim$neum/},
year = {2020}
}
@techreport{Takapoui,
abstract = {In this paper, we propose a fast optimisation algorithm for approximately minimising convex quadratic functions over the intersection of affine and separable constraints (i.e. the Cartesian product of possibly nonconvex real sets). This problem class contains many NP-hard problems such as mixed-integer quadratic programming. Our heuristic is based on a variation of the alternating direction method of multipliers (ADMM), an algorithm for solving convex optimisation problems. We discuss the favourable computational aspects of our algorithm, which allow it to run quickly even on very modest computational platforms such as embedded processors. We give several examples for which an approximate solution should be found very quickly, such as management of a hybrid-electric vehicle drivetrain and control of switched-mode power converters. Our numerical experiments suggest that our method is very effective in finding a feasible point with small objective value; indeed, we see that in many cases, it finds the global solution.},
author = {Takapoui, Reza and Moehle, Nicholas and Boyd, Stephen and Bemporad, Alberto},
file = {:C\:/Users/dv516/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Takapoui et al. - Unknown - A simple effective heuristic for embedded mixed-integer quadratic programming(2).pdf:pdf},
keywords = {ADMM,Mixed-integer quadratic programming,embedded applications,heuristic},
title = {{A simple effective heuristic for embedded mixed-integer quadratic programming}},
url = {https://doi.org/}
}
@inproceedings{Rios2013,
abstract = {This paper addresses the solution of bound-constrained optimization problems using algorithms that require only the availability of objective function values but no derivative information. We refer to these algorithms as derivative-free algorithms. Fueled by a growing number of applications in science and engineering, the development of derivative-free optimization algorithms has long been studied, and it has found renewed interest in recent time. Along with many derivative-free algorithms, many software implementations have also appeared. The paper presents a review of derivative-free algorithms, followed by a systematic comparison of 22 related implementations using a test set of 502 problems. The test bed includes convex and nonconvex problems, smooth as well as nonsmooth problems. The algorithms were tested under the same conditions and ranked under several criteria, including their ability to find near-global solutions for nonconvex problems, improve a given starting point, and refine a near-optimal solution. A total of 112,448 problem instances were solved. We find that the ability of all these solvers to obtain good solutions diminishes with increasing problem size. For the problems used in this study, TOMLAB/MULTIMIN, TOMLAB/GLCCLUSTER, MCS and TOMLAB/LGO are better, on average, than other derivative-free solvers in terms of solution quality within 2,500 function evaluations. These global solvers outperform local solvers even for convex problems. Finally, TOMLAB/OQNLP, NEWUOA, and TOMLAB/MULTIMIN show superior performance in terms of refining a near-optimal solution. {\textcopyright} 2012 Springer Science+Business Media, LLC.},
author = {Rios, Luis Miguel and Sahinidis, Nikolaos V.},
booktitle = {Journal of Global Optimization},
doi = {10.1007/s10898-012-9951-y},
file = {:C\:/Users/dv516/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Rios, Sahinidis - 2013 - Derivative-free optimization A review of algorithms and comparison of software implementations.pdf:pdf},
issn = {09255001},
keywords = {Derivative-free algorithms,Direct search methods,Surrogate models},
month = {jul},
number = {3},
pages = {1247--1293},
publisher = {Springer},
title = {{Derivative-free optimization: A review of algorithms and comparison of software implementations}},
url = {https://link.springer.com/article/10.1007/s10898-012-9951-y},
volume = {56},
year = {2013}
}
@article{PaulaBarbosa-Povoa2020,
abstract = {Process systems engineering (PSE) has been an active research area for nearly seventy years and addresses multiple systems from the process industry. Among these are Process Supply Chains that can be described as interconnected sets of entities responsible for the sourcing, production and distribution of a large set of chemical and/or bio-based products. Due to the high diversity of materials, processes and information flows such networks result in highly complex systems that are very difficult to manage. The PSE community has a critical role to support the design and management of such systems through the development of tools that are able to address such complexity. Focusing initially on a real-world process supply chain, the industrial gas supply chain, this paper identifies and discusses current contributions, challenges and perspectives in process supply chains that can guide research professionals to address such challenges. In general, such challenges encompass supply chain scope representations, modeling approaches , data management and implementation. Examples include supply chain risk and uncertainty, multiscale decisions, sustainability and resiliency.},
author = {{Paula Barbosa-Povoa}, Ana and Pinto, Jos{\'{e}} Mauricio},
doi = {10.1016/j.compchemeng.2019.106606},
file = {:C\:/Users/dv516/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Paula Barbosa-Povoa, Pinto - 2020 - Process supply chains Perspectives from academia and industry.pdf:pdf},
journal = {Computers \& Chemical Engineering},
keywords = {Challenges,Industrial gases,Multiscale,Optimization,Perspectives,Process supply chains,Sustainability,Uncertainty},
pages = {106606},
title = {{Process supply chains: Perspectives from academia and industry}},
url = {https://doi.org/10.1016/j.compchemeng.2019.106606},
volume = {132},
year = {2020}
}
@misc{Bhosekar2018a,
abstract = {The idea of using a simpler surrogate to represent a complex phenomenon has gained increasing popularity over past three decades. Due to their ability to exploit the black-box nature of the problem and the attractive computational simplicity, surrogates have been studied by researchers in multiple scientific and engineering disciplines. Successful use of surrogates shall result in significant savings in terms of computational time and resources. However, with a wide variety of approaches available in the literature, the correct choice of surrogate is a difficult task. An important aspect of this choice is based on the type of problem at hand. This paper reviews recent advances in the area of surrogate models for problems in modeling, feasibility analysis, and optimization. Two of the frequently used surrogates, radial basis functions, and Kriging are tested on a variety of test problems. Finally, guidelines for the choice of appropriate surrogate model are discussed.},
author = {Bhosekar, Atharv and Ierapetritou, Marianthi},
booktitle = {Computers \& Chemical Engineering},
doi = {10.1016/j.compchemeng.2017.09.017},
issn = {00981354},
keywords = {Derivative-free optimization,Feasibility analysis,Model selection,Sampling,Surrogate models},
month = {jan},
pages = {250--267},
publisher = {Elsevier Ltd},
title = {{Advances in surrogate based modeling, feasibility analysis, and optimization: A review}},
volume = {108},
year = {2018}
}
@article{Beykal2018a,
abstract = {This work presents recent advances within the AlgoRithms for Global Optimization of coNstrAined grey-box compUTational problems (ARGONAUT) framework, developed for optimization of systems which lack analytical forms and derivatives. A new parallel version of ARGONAUT (p-ARGONAUT) is introduced to solve high dimensional problems with a large number of constraints. This development is motivated by a challenging case study, namely the operation of an oilfield using water-flooding. The objective of this case study is the maximization of the Net Present Value over a five-year time horizon by manipulating the well pressures, while satisfying a set of complicating constraints related to water-cut limitations and water handling and storage. Dimensionality reduction is performed via the parametrization of the pressure control domain, which is then followed by global optimization of the constrained grey-box system. Results are presented for multiple case studies and the performance of p-ARGONAUT is compared to existing derivative-free optimization methods.},
author = {Beykal, Burcu and Boukouvala, Fani and Floudas, Christodoulos A. and Sorek, Nadav and Zalavadia, Hardikkumar and Gildin, Eduardo},
doi = {10.1016/j.compchemeng.2018.01.005},
issn = {00981354},
journal = {Computers \& Chemical Engineering},
keywords = {Derivative-free optimization,Grey/black-box optimization,Oil-well control,Oilfield operations,Waterflooding},
month = {jun},
pages = {99--110},
publisher = {Elsevier Ltd},
title = {{Global optimization of grey-box computational systems using surrogate functions and application to highly constrained oil-field operations}},
volume = {114},
year = {2018}
}
@article{Stephanopoulos1990,
abstract = {Recent advances in artificial intelligence have changed the fundamental assumptions upon which the progress of computer-aided process engineering (modeling and methodologies) during the last 30 yr has been founded. Thus, in certain instances, numerical computations today constitute inferior alternatives to qualitative and/or semi-quantitative models and procedures which can capture and utilize more broadly- based sources of knowledge. In this paper it will be shown how process development and design, as well as planning, scheduling, monitoring, analysis and control of process operations can benefit from improved knowledge-representation schemes and advanced reasoning control strategies. It will also be argued that the central challenge coming from research advances in artificial intelligence is "modeling the knowledge", i.e. modeling: (a) physical phenomena and the systems in which they occur; (b) information handling and processing systems; and (c) problem-solving strategies in design, operations and control. Thus, different strategies require different forms of declarative knowledge, and the success or failure of various design, planning, diagnostic and control systems depends on the extent of actively utilizable knowledge. Furthermore, this paper will outline the theoretical scope of important contributions from AI and what their impact has been and will be on the formulation and solution of process engineering problems. {\textcopyright} 1990.},
author = {Stephanopoulos, G.},
doi = {10.1016/0098-1354(90)80006-W},
issn = {00981354},
journal = {Computers \& Chemical Engineering},
month = {nov},
number = {11},
pages = {1259--1270},
publisher = {Pergamon},
title = {{Artificial intelligence in process engineering-current state and future trends}},
volume = {14},
year = {1990}
}

@Misc{gpyopt2016,
  author =   {The GPyOpt authors},
  title =    {GPyOpt: A Bayesian Optimization framework in Python},
  howpublished = {\url{http://github.com/SheffieldML/GPyOpt}},
  year = {2016}
}

@article{Palomar2006,
abstract = {A systematic understanding of the decomposability structures in network utility maximization is key to both resource allocation and functionality allocation. It helps us obtain the most appropriate distributed algorithm for a given network resource allocation problem, and quantifies the comparison across architectural alternatives of modularized network design. Decomposition theory naturally provides the mathematical language to build an analytic foundation for the design of modularized and distributed control of networks. In this tutorial paper, we first review the basics of convexity, Lagrange duality, distributed subgradient method, Jacobi and Gauss-Seidel iterations, and implication of different time scales of variable updates. Then, we introduce primal, dual, indirect, partial, and hierarchical decompositions, focusing on network utility maximization problem formulations and the meanings of primal and dual decompositions in terms of network architectures. Finally, we present recent examples on: systematic search for alternative decompositions; decoupling techniques for coupled objective functions; and decoupling techniques for coupled constraint sets that are not readily decomposable. {\textcopyright} 2006 IEEE.},
author = {Palomar, Daniel P. and Chiang, Mung},
doi = {10.1109/JSAC.2006.879350},
issn = {07338716},
journal = {IEEE Journal on Selected Areas in Communications},
keywords = {Congestion control,Cross-layer design,Decomposition,Distributed algorithm,Network architecture,Network control by pricing,Network utility maximization,Optimization,Power control,Resource allocation},
month = {aug},
number = {8},
pages = {1439--1451},
title = {{A tutorial on decomposition methods for network utility maximization}},
volume = {24},
year = {2006}
}
@article{Tang2010,
abstract = {In industrial production, one usually wants to seek an optimal product recipe or operation condition; however, due to the possible or known presence of multiple local optima in an unknown system such as a newly developed fermentation process, one may need to find the best global solution via the global optimization approach. An effective-global optimizer of non-convex functions can be applied to an unknown system with constraints to reach the global optimum by obtaining the surrogate model experimentally. Nevertheless, large experiments are usually indispensable for achieving a defined target. In this work, a monitoring chart describing objective function values with respect to cluster centers of local and global minima (or maxima) is proposed to follow the development of the identified radial basis function (RBF) model which is based on the information gathering from experiments specially designed. Based on the monitoring chart, whether the region surrounding the global extreme is reached can be followed. The proposed optimizing algorithm to reach the global optimum in an unknown process consists of the following two steps. Initially, the experiments designed by the global optimizer (rbfSolve routine in TOMLAB/CGO) is conducted before the region surrounding the global extreme is reached. When the region of global extreme is approaching, additional-optimizing experiments designed by the identified RBF model are then carried out to accelerate the rate to achieve the global optimum. The performance of the optimizing algorithm and the monitoring chart on an unknown process with the constraints proposed in this work was evaluated through (a) a constrained multimodal function as a problem of finding the recipe for a newly developed product and (b) a feed-rate optimization of a fed-batch fermentation process as a problem in obtaining an optimal-feeding trajectory. One can conclude that the experimental approach for achieving global optimization of an unknown process with constraints via an RBF based method is achievable in limited experiments. {\textcopyright} 2010 The Society of Chemical Engineers, Japan.},
author = {Tang, Jiun-Kai and Chang, Jyh-Shyong},
doi = {10.1252/jcej.10we056},
issn = {0021-9592},
journal = {JOURNAL OF CHEMICAL ENGINEERING OF JAPAN},
keywords = {Fed-batch fermentation process,Global optimization,Process monitoring,Radial basis functions},
month = {sep},
number = {9},
pages = {777--791},
publisher = {The Society of Chemical Engineers, Japan},
title = {{Data-Driven Global Optimization of Constrained Process Systems via a Radial Basis Function Based Method}},
url = {http://joi.jlc.jst.go.jp/JST.JSTAGE/jcej/10we056?from=CrossRef},
volume = {43},
year = {2010}
}
@article{Spendley1962,
abstract = {A technique for empirical optimisation is presented in which a sequence of experimental designs each in the form of a regular or irregular simplex is used, each simplex having all vertices but one in common with the preceding simplex, and being completed by one new point. Reasons for the choice of design are outlined, and a formal procedure given. The performance of the technique in the presence and absence of error is studied and it is shown (a) that in the presence of error the rate of advance is inversely proportional to the error standard deviation, so that replication of observations is not beneficial, and (b) that the “efficiency” of the technique appears to increase in direct proportion to the number of factors investigated. It is also noted that, since the direction of movement from each simplex is dependent solely on the ranking of the observations, the technique may be used even in circumstances when a response cannot be quantitatively assessed. Attention is drawn to the ease with which second-order designs having the minimum number of experimental points may be derived from a regular simplex, and a fitting procedure which avoids a direct matrix inversion is suggested. In a brief appendix one or two new rotatable designs derivable from a simplex are noted. {\textcopyright} 1962 Taylor & Francis Group, LLC.},
author = {Spendley, W. and Hext, G. R. and Himsworth, F. R.},
doi = {10.1080/00401706.1962.10490033},
file = {::},
issn = {15372723},
journal = {Technometrics},
number = {4},
pages = {441--461},
title = {{Sequential Application of Simplex Designs in Optimisation and Evolutionary Operation}},
volume = {4},
year = {1962}
}
@article{PaulaBarbosa-Povoa2020a,
abstract = {Process systems engineering (PSE) has been an active research area for nearly seventy years and addresses multiple systems from the process industry. Among these are Process Supply Chains that can be described as interconnected sets of entities responsible for the sourcing, production and distribution of a large set of chemical and/or bio-based products. Due to the high diversity of materials, processes and information flows such networks result in highly complex systems that are very difficult to manage. The PSE community has a critical role to support the design and management of such systems through the development of tools that are able to address such complexity. Focusing initially on a real-world process supply chain, the industrial gas supply chain, this paper identifies and discusses current contributions, challenges and perspectives in process supply chains that can guide research professionals to address such challenges. In general, such challenges encompass supply chain scope representations, modeling approaches , data management and implementation. Examples include supply chain risk and uncertainty, multiscale decisions, sustainability and resiliency.},
author = {{Paula Barbosa-Povoa}, Ana and Pinto, Jos{\'{e}} Mauricio},
doi = {10.1016/j.compchemeng.2019.106606},
file = {:C\:/Users/dv516/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Paula Barbosa-Povoa, Pinto - 2020 - Process supply chains Perspectives from academia and industry.pdf:pdf},
journal = {Computers \& Chemical Engineering},
keywords = {Challenges,Industrial gases,Multiscale,Optimization,Perspectives,Process supply chains,Sustainability,Uncertainty},
pages = {106606},
title = {{Process supply chains: Perspectives from academia and industry}},
url = {https://doi.org/10.1016/j.compchemeng.2019.106606},
volume = {132},
year = {2020}
}
@article{Scattolinia,
abstract = {The aim of this paper is to review and to propose a classification of a number of decentralized, distributed and hierarchical control architectures for large scale systems. Attention is focused on the design approaches based on Model Predictive Control. For the considered architectures, the underlying rationale, the fields of application, the merits and limitations are discussed, the main references to the literature are reported and some future developments are suggested. Finally, a number of open problems is listed.},
author = {Scattolini, Riccardo},
doi = {10.1016/j.jprocont.2009.02.003},
file = {:C\:/Users/dv516/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Scattolini - Unknown - Architectures for distributed and hierarchical Model Predictive Control – A review.pdf:pdf},
journal = {Journal of Process Control},
keywords = {Distributed control,Hierarchical control,Model Predictive Control,Process control},
pages = {723--731},
title = {{Architectures for distributed and hierarchical Model Predictive Control – A review}},
url = {http://bme2.aut.ac.ir/$\sim$towhidkhah/mpc/seminars-ppt/90/seminar MPC/Fazane karami/Reference/Architectures for distributed and hierarchical Model Predictive Control – A review.pdf},
volume = {19}
}
@misc{Boyd2010,
abstract = {Many problems of recent interest in statistics and machine learning can be posed in the framework of convex optimization. Due to the explosion in size and complexity of modern datasets, it is increasingly important to be able to solve problems with a very large number of features or training examples. As a result, both the decentralized collection or storage of these datasets as well as accompanying distributed solution methods are either necessary or at least highly desirable. In this review, we argue that the alternating direction method of multipliers is well suited to distributed convex optimization, and in particular to large-scale problems arising in statistics, machine learning, and related areas. The method was developed in the 1970s, with roots in the 1950s, and is equivalent or closely related to many other algorithms, such as dual decomposition, the method of multipliers, Douglas-Rachford splitting, Spingarn's method of partial inverses, Dykstra's alternating projections, Bregman iterative algorithms for ℓ1 problems, proximal methods, and thers. After briefly surveying the theory and history of the algorithm, we discuss applications to a wide variety of statistical and machine learning problems of recent interest, including the lasso, sparse logistic regression, basis pursuit, covariance selection, support vector machines, and many others. We also discuss general distributed optimization, extensions to the nonconvex setting, and efficient implementation, including some details on distributed MPI and Hadoop MapReduce implementations. {\textcopyright} 2011 S. Boyd, N. Parikh, E. Chu, B. Peleato and J. Eckstein.},
author = {Boyd, Stephen and Parikh, Neal and Chu, Eric and Peleato, Borja and Eckstein, Jonathan},
booktitle = {Foundations and Trends in Machine Learning},
doi = {10.1561/2200000016},
file = {:C\:/Users/dv516/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Boyd et al. - 2010 - Distributed optimization and statistical learning via the alternating direction method of multipliers.pdf:pdf},
issn = {19358237},
number = {1},
pages = {1--122},
title = {{Distributed optimization and statistical learning via the alternating direction method of multipliers}},
url = {http://www.nowpublishers.com/article/Details/MAL-016},
volume = {3},
year = {2010}
}
@misc{,
title = {{(No Title)}},
url = {https://www.pac.gr/bcm/uploads/industry-4-0-top-challenges-for-chemical-manufacturing.pdf},
urldate = {2021-05-01}
}
@misc{Sinha2018,
abstract = {Bilevel optimization is defined as a mathematical program, where an optimization problem contains another optimization problem as a constraint. These problems have received significant attention from the mathematical programming community. Only limited work exists on bilevel problems using evolutionary computation techniques; however, recently there has been an increasing interest due to the proliferation of practical applications and the potential of evolutionary algorithms in tackling these problems. This paper provides a comprehensive review on bilevel optimization from the basic principles to solution strategies; both classical and evolutionary. A number of potential application problems are also discussed. To offer the readers insights on the prominent developments in the field of bilevel optimization, we have performed an automated text-analysis of an extended list of papers published on bilevel optimization to date. This paper should motivate evolutionary computation researchers to pay more attention to this practical yet challenging area.},
archivePrefix = {arXiv},
arxivId = {1705.06270},
author = {Sinha, Ankur and Malo, Pekka and Deb, Kalyanmoy},
booktitle = {IEEE Transactions on Evolutionary Computation},
doi = {10.1109/TEVC.2017.2712906},
eprint = {1705.06270},
issn = {1089778X},
keywords = {Bilevel optimization,Stackelberg games,evolutionary algorithms},
month = {apr},
number = {2},
pages = {276--295},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{A Review on Bilevel Optimization: From Classical to Evolutionary Approaches and Applications}},
volume = {22},
year = {2018}
}
@article{Thebelt2021,
author = {Thebelt, Alexander and Kronqvist, Jan and Mistry, Miten and Lee, Robert M. and Sudermann-Merx, Nathan and Misener, Ruth},
doi = {10.1016/j.compchemeng.2021.107343},
issn = {00981354},
journal = {Computers \& Chemical Engineering},
month = {may},
pages = {107343},
publisher = {Pergamon},
title = {{ENTMOOT: A Framework for Optimization over Ensemble Tree Models}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0098135421001216},
year = {2021}
}
@article{Castro2018,
abstract = {In this paper, we present a brief overview of enterprise-wide optimization and challenges in multiscale temporal modeling and integration of different models for the levels of planning, scheduling and control. Next, we review Generalized Disjunctive Programming (GDP), as a new modeling paradigm for scheduling problems that are illustrated with the STN and RTN models. We then address scheduling problems that expand the scope of the area: simultaneous scheduling and heat integration, pipeline scheduling, crude oil and refined products blending, and demand side management. We illustrate the advantage of the GDP modeling framework, describe effective strategies for global optimization, and describe multistage affinely adjustable robust optimization for uncertain interruptible load. We address integration of planning and scheduling, for which several approaches are reviewed, including use of traveling salesman constraints for multiperiod refinery planning, and multisite planning and scheduling of multiproduct batch plants. We report computational results to highlight the challenges.},
author = {Castro, Pedro M. and Grossmann, Ignacio E. and Zhang, Qi},
doi = {10.1016/j.compchemeng.2018.01.020},
issn = {00981354},
journal = {Computers \& Chemical Engineering},
keywords = {Demand side management,Generalized disjunctive programming,Mixed-integer programming,Planning,Scheduling},
month = {jun},
pages = {14--42},
publisher = {Elsevier Ltd},
title = {{Expanding scope and computational challenges in process scheduling}},
volume = {114},
year = {2018}
}
@article{Curtis2020,
abstract = {A stochastic second-order trust region method is proposed, which can be viewed as an extension of the trust-region-ish (TRish) algorithm proposed by Curtis et al. [A stochastic trust region algorithm based on careful step normalization. INFORMS J. Optim. 1(3) 200–220, 2019]. In each iteration, a search direction is computed by (approximately) solving a subproblem defined by stochastic gradient and Hessian estimates. The algorithm has convergence guarantees in the fully stochastic regime, i.e. when each stochastic gradient is merely an unbiased estimate of the gradient with bounded variance and the stochastic Hessian estimates are bounded. This framework covers a variety of implementations, such as when the stochastic Hessians are defined by sampled second-order derivatives or diagonal matrices, such as in RMSprop, Adagrad, Adam and other popular algorithms. The proposed algorithm has a worst-case complexity guarantee in the nearly deterministic regime, i.e. when the stochastic gradients and Hessians are close in expectation to the true gradients and Hessians. The results of numerical experiments for training CNNs for image classification and an RNN for time series forecasting are presented. These results show that the algorithm can outperform a stochastic gradient and first-order TRish algorithm.},
archivePrefix = {arXiv},
arxivId = {1911.06920},
author = {Curtis, Frank E. and Shi, Rui},
doi = {10.1080/10556788.2020.1852403},
eprint = {1911.06920},
issn = {10294937},
journal = {Optimization Methods and Software},
keywords = {Stochastic optimization,deep neural networks,finite-sum optimization,machine learning,stochastic Newton methods,time series forecasting,trust region methods},
publisher = {Taylor and Francis Ltd.},
title = {{A fully stochastic second-order trust region method}},
url = {https://www.tandfonline.com/doi/abs/10.1080/10556788.2020.1852403},
year = {2020}
}

@incollection{Xie2018,
abstract = {This paper presents a novel data-driven modeling strategy for highly accurate prediction and optimization of complex chemical processes. The material balance, equilibrium, and heat balance equations addressed in a chemical process are nonlinear, thus making it very difficult to optimize. To overcome the above difficulty, a high dimensional model representation (HDMR) method was developed to represent a complex process (Pan et al., 2016), and a novel linear programming (LP) model was then proposed to find the HDMR parameters. Finally, the complexity of a chemical process model can be reduced significantly as its mechanism formulations were replaced with a simple nonlinear HDMR model. The resulting simple nonlinear optimization problem can be solved efficiently by using the iterative linear programming (LP) method proposed in the earlier work (Pan et al., 2013). To validate the proposed approach, a propane dehydrogenation (PDH) process was studied.},
author = {Xie, Qingsong and Liu, Hua and Bo, Di and He, Chang and Pan, Ming},
booktitle = {Computer Aided Chemical Engineering},
doi = {10.1016/B978-0-444-64241-7.50134-8},
issn = {15707946},
keywords = {Complex Chemical Processes,Data-driven Modeling,High Dimensional Model Representation (HDMR),Highly Accurate Prediction,Optimization},
month = {jan},
pages = {835--840},
publisher = {Elsevier B.V.},
title = {{Data-driven Modeling and Optimization of Complex Chemical Processes Using a Novel HDMR Methodology}},
volume = {44},
year = {2018}
}
@inproceedings{Rantzer2009,
author = {Rantzer, Anders},
booktitle = {2009 American Control Conference},
doi = {10.1109/ACC.2009.5160224},
isbn = {978-1-4244-4523-3},
pages = {884--888},
publisher = {IEEE},
title = {{Dynamic dual decomposition for distributed control}},
url = {http://ieeexplore.ieee.org/document/5160224/},
year = {2009}
}
@misc{Darby2011,
abstract = {The practice of implementing real-time optimization (RTO) using a rigorous steady-state model, in conjunction with model predictive control (MPC), dates back to the late 1980s. Since then, numerous projects have been implemented in refinery and chemical plants, and RTO has received significant attention in the industrial and academic literature. This history affords us the opportunity to assess the impact and success of RTO technology in the process industries. We begin with a discussion of the role RTO serves in the hierarchy of control and optimization decision making in the plant, and outline the key steps of the RTO layer and the coordination with MPC. Where appropriate, we point out the different approaches that have been used in practice and discuss the success factors that directly relate to the success of RTO within an organization. We also discuss alternative approaches that have been used to alleviate some of the challenges associated with implementing RTO and which may be appropriate for those unwilling to commit to the traditional RTO approach. Lastly, we provide suggestions for improvement to motivate further research. {\textcopyright} 2011 Elsevier Ltd. All rights reserved.},
author = {Darby, Mark L. and Nikolaou, Michael and Jones, James and Nicholson, Doug},
booktitle = {Journal of Process Control},
doi = {10.1016/j.jprocont.2011.03.009},
issn = {09591524},
keywords = {Model predictive control,Online optimization,Plant decision hierarchy,Real-time optimization},
month = {jul},
number = {6},
pages = {874--884},
publisher = {Elsevier},
title = {{RTO: An overview and assessment of current practice}},
volume = {21},
year = {2011}
}
@book{SuttonRichardS.andBarto1998,
author = {{Sutton, Richard S. and Barto}, Andrew G.},
publisher = {The MIT Press},
title = {{Reinforcement Learning: An Introduction}},
year = {1998}
}
@article{Tang2019,
abstract = {Large-scale and complex process systems are essentially interconnected networks. The automated operation of such process networks requires the solution of control and optimization problems in a distributed manner. In this approach, the network is decomposed into several subsystems, each of which is under the supervision of a corresponding computing agent (controller, optimizer). The agents coordinate their control and optimization decisions based on information communication among them. In recent years, algorithms and methods for distributed control and optimization are undergoing rapid development. In this paper, we provide a comprehensive, up-to-date review with perspectives and discussions on possible future directions.},
author = {Tang, Wentao and Daoutidis, Prodromos},
doi = {10.1016/J.CJCHE.2018.08.027},
issn = {1004-9541},
journal = {Chinese Journal of Chemical Engineering},
month = {jul},
number = {7},
pages = {1461--1473},
publisher = {Elsevier},
title = {{Distributed control and optimization of process system networks: A review and perspective}},
url = {https://www.sciencedirect.com/science/article/abs/pii/S100495411830853X},
volume = {27},
year = {2019}
}
@misc{Bengio2021,
abstract = {This paper surveys the recent attempts, both from the machine learning and operations research communities, at leveraging machine learning to solve combinatorial optimization problems. Given the hard nature of these problems, state-of-the-art algorithms rely on handcrafted heuristics for making decisions that are otherwise too expensive to compute or mathematically not well defined. Thus, machine learning looks like a natural candidate to make such decisions in a more principled and optimized way. We advocate for pushing further the integration of machine learning and combinatorial optimization and detail a methodology to do so. A main point of the paper is seeing generic optimization problems as data points and inquiring what is the relevant distribution of problems to use for learning on a given task.},
archivePrefix = {arXiv},
arxivId = {1811.06128},
author = {Bengio, Yoshua and Lodi, Andrea and Prouvost, Antoine},
booktitle = {European Journal of Operational Research},
doi = {10.1016/j.ejor.2020.07.063},
eprint = {1811.06128},
file = {::},
issn = {03772217},
keywords = {Branch and bound,Combinatorial optimization,Machine learning,Mixed-integer programming solvers},
month = {apr},
number = {2},
pages = {405--421},
publisher = {Elsevier B.V.},
title = {{Machine learning for combinatorial optimization: A methodological tour d'horizon}},
volume = {290},
year = {2021}
}
@article{Li2021,
abstract = {<p>Uncertainties are widespread in the optimization of process systems, such as uncertainties in process technologies, prices, and customer demands. In this paper, we review the basic concepts and recent advances of a risk-neutral mathematical framework called “stochastic programming” and its applications in solving process systems engineering problems under uncertainty. This review intends to provide both a tutorial for beginners without prior experience and a high-level overview of the current state-of-the-art developments for experts in process systems engineering and stochastic programming. The mathematical formulations and algorithms for two-stage and multistage stochastic programming are reviewed with illustrative examples from process industries. The differences between stochastic programming under exogenous uncertainty and endogenous uncertainties are discussed. The concepts and several data-driven methods for generating scenario trees are also reviewed.</p>},
author = {Li, Can and Grossmann, Ignacio E.},
doi = {10.3389/fceng.2020.622241},
file = {::},
issn = {2673-2718},
journal = {Frontiers in Chemical Engineering},
keywords = {Data-driven,Decision-making under uncertainty,Process Systems Engineering,optimization,stochastic programming},
month = {jan},
pages = {34},
publisher = {Frontiers},
title = {{A Review of Stochastic Programming Methods for Optimization of Process Systems Under Uncertainty}},
url = {https://www.frontiersin.org/articles/10.3389/fceng.2020.622241/full},
volume = {2},
year = {2021}
}
@article{Sahinidis1989,
abstract = {In this paper a multiperiod MILP model is presented for the optimal selection and expansion of processes given time varying forecasts for the demands and prices of chemicals over a long range horizon. To reduce the computational expense of solving this long range planning problem, several strategies are investigated, including branch and bound, the use of integer cuts, strong cutting planes, Benders decomposition and heuristics. These procedures, which have been implemented in the program MULPLAN, are illustrated with several example problems. As is shown, the proposed model is especially useful for the study of a variety of different scenarios. {\textcopyright} 1989.},
author = {Sahinidis, N. V. and Grossmann, I. E. and Fornari, R. E. and Chathrathi, M.},
doi = {10.1016/0098-1354(89)87046-2},
issn = {00981354},
journal = {Computers \& Chemical Engineering},
month = {sep},
number = {9},
pages = {1049--1063},
publisher = {Pergamon},
title = {{Optimization model for long range planning in the chemical industry}},
volume = {13},
year = {1989}
}
@article{Kazantzis2000,
abstract = {The present work proposes a new approach to the state feedback regulator synthesis problem for multiple-input nonlinear processes. The problem under consideration is not treated within the context of exact feedback linearization, where restrictive conditions arise, but is conveniently formulated in the context of singular partial differential equations (PDE) theory. In particular, the mathematical formulation of the problem is realized via a system of first-order quasi-linear singular PDEs and a rather general set of necessary and sufficient conditions for solvability is derived. The solution to the above system of singular PDEs can be proven to be locally analytic and this enables the development of a series solution method, that is easily programmable with the aid of a symbolic software package such as MAPLE. Under a simultaneous implementation of a nonlinear coordinate transformation and a nonlinear state feedback control law that is computed through the solution of the above system of singular PDEs, both feedback linearization and pole-placement design objectives can be accomplished in a single step. Finally, the proposed nonlinear state feedback regulator synthesis method is applied to a continuous stirred tank reactor (CSTR) in non-isothermal operation that exhibits steady-state multiplicity. The control objective is to regulate the reactor at the middle unstable steady state by manipulating the dilution rate. Simulation studies have been conducted to evaluate the performance of the proposed nonlinear state feedback regulator, as well as to illustrate the main design aspects of the proposed approach. It is shown that the nonlinear state feedback regulator clearly outperforms the standard linear one, especially in the presence of adverse conditions under which linear regulation at the unstable steady state is not always feasible. (C) 2000 Elsevier Science Ltd. All rights reserved.},
author = {Kazantzis, Nikolaos and Kravaris, Costas},
doi = {10.1016/S0009-2509(00)00006-3},
file = {:C\:/Users/dv516/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Kazantzis, Kravaris - 2000 - Synthesis of state feedback regulators for nonlinear processes.pdf:pdf},
issn = {00092509},
journal = {Chemical Engineering Science},
keywords = {Feedback linearization,Nonlinear dynamics,Process control,Regulation,Simulations,Stability},
month = {sep},
number = {17},
pages = {3437--3449},
publisher = {Pergamon},
title = {{Synthesis of state feedback regulators for nonlinear processes}},
volume = {55},
year = {2000}
}
@techreport{Sui,
abstract = {We consider sequential decision problems under uncertainty, where we seek to optimize an unknown function from noisy samples. This requires balancing exploration (learning about the objective) and exploitation (localizing the maximum), a problem well-studied in the multi-armed bandit literature. In many applications, however, we require that the sampled function values exceed some prespecified "safety" threshold , a requirement that existing algorithms fail to meet. Examples include medical applications where patient comfort must be guaranteed, recommender systems aiming to avoid user dissatisfaction, and robotic control, where one seeks to avoid controls causing physical harm to the platform. We tackle this novel, yet rich, set of problems under the assumption that the unknown function satisfies regularity conditions expressed via a Gaussian process prior. We develop an efficient algorithm called SAFEOPT, and theoretically guarantee its convergence to a natural notion of optimum reachable under safety constraints. We evaluate SAFEOPT on synthetic data, as well as two real applications: movie recommendation, and therapeutic spinal cord stimulation.},
author = {Sui, Yanan and Ch, Alkisg@inf Ethz and Zurich, Eth and Burdick, Joel W and Krause, Andreas and Ch, Krausea@ethz},
file = {::},
title = {{Safe Exploration for Optimization with Gaussian Processes}}
}
@article{Kamthe2017a,
abstract = {Trial-and-error based reinforcement learning (RL) has seen rapid advancements in recent times, especially with the advent of deep neural networks. However, the majority of autonomous RL algorithms require a large number of interactions with the environment. A large number of interactions may be impractical in many real-world applications, such as robotics, and many practical systems have to obey limitations in the form of state space or control constraints. To reduce the number of system interactions while simultaneously handling constraints, we propose a model-based RL framework based on probabilistic Model Predictive Control (MPC). In particular, we propose to learn a probabilistic transition model using Gaussian Processes (GPs) to incorporate model uncertainty into long-term predictions, thereby, reducing the impact of model errors. We then use MPC to find a control sequence that minimises the expected long-term cost. We provide theoretical guarantees for first-order optimality in the GP-based transition models with deterministic approximate inference for long-term planning. We demonstrate that our approach does not only achieve state-of-the-art data efficiency, but also is a principled way for RL in constrained environments.},
archivePrefix = {arXiv},
arxivId = {1706.06491},
author = {Kamthe, Sanket and Deisenroth, Marc Peter},
eprint = {1706.06491},
file = {:C\:/Users/dv516/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Kamthe, Deisenroth - 2017 - Data-Efficient Reinforcement Learning with Probabilistic Model Predictive Control.pdf:pdf},
month = {jun},
title = {{Data-Efficient Reinforcement Learning with Probabilistic Model Predictive Control}},
url = {http://arxiv.org/abs/1706.06491},
year = {2017}
}
@article{Caballero2008,
abstract = {In this work a methodology is presented for the rigorous optimization of nonlinear programming problems in which the objective function and (or) some constraints are represented by noisy implicit black box functions. The special application considered is the optimization of modular process simulators in which the derivatives are not available and some unit operations introduce noise preventing the calculation of accurate derivatives, The black box modules are substituted by metamodels based on a kriging interpolation that assumes that the errors are not independent but a function of the independent variables. A Kriging metamodel uses non-Euclidean measure of distance to avoid sensitivity to the units of measure. It includes adjustable parameters that weigh the importance of each variable for obtaining a good model representation, and it allows calculating errors that can be used to establish stopping criteria and provide a solid base to deal with "possible infeasibility" due to inaccuracies in the metamodel representation of objective function and constraints. The algorithm continues with a refining stage and successive bound contraction in the domain of independent variables with or without kriging recalibration until an acceptable accuracy in the metamodel is obtained. The procedure is illustrated with several examples. {\textcopyright} 2008 American Institute of Chemical Engineers.},
author = {Caballero, Jos{\'{e}} A. and Grossmann, Ignacio E.},
doi = {10.1002/aic.11579},
issn = {00011541},
journal = {AIChE Journal},
keywords = {Design (process simulation),Mathematical modeling,Numerical solutions,Optimization,Process,Simulation},
month = {oct},
number = {10},
pages = {2633--2650},
publisher = {John Wiley & Sons, Ltd},
title = {{An algorithm for the use of surrogate models in modular flowsheet optimization}},
url = {https://aiche.onlinelibrary.wiley.com/doi/full/10.1002/aic.11579 https://aiche.onlinelibrary.wiley.com/doi/abs/10.1002/aic.11579 https://aiche.onlinelibrary.wiley.com/doi/10.1002/aic.11579},
volume = {54},
year = {2008}
}
@article{Sorek2017,
abstract = {The objective of this paper is to introduce a novel paradigm to reduce the computational effort in waterflooding global optimization problems while realizing smooth well control trajectories amenable for practical deployments in the field. In order to overcome the problems of slow convergence and non-smooth impractical control strategies, often associated with gradient-free optimization (GFO) methods, we introduce a generalized approach which represent the controls by smooth polynomial approximations either by a polynomial function or by a piecewise polynomial interpolation, which we denote as function control method (FCM) and interpolation control method (ICM), respectively. Using these approaches, we aim to optimize the coefficients of the selected functions or the interpolation points in order to represent the well-control trajectories along a time horizon. Our results demonstrate significant computational savings, due to a substantial reduction in the number of control parameters, as we seek the optimal polynomial coefficients or the interpolation points to describe the control trajectories as opposed to directly searching for the optimal control values (bottom hole pressure) at each time interval. We demonstrate the efficiency of the method on two and three-dimensional models, where we found the optimal variables using a parallel dynamic-neighborhood particle swarm optimization (PSO). We compared our FCM-PSO and ICM-PSO to the traditional formulation solved by both gradient-free and gradient-based methods. In all comparisons, both FCM and ICM show very good to superior performances.},
author = {Sorek, Nadav and Gildin, Eduardo and Boukouvala, Fani and Beykal, Burcu and Floudas, Christodoulos A.},
doi = {10.1007/s10596-016-9610-3},
file = {::},
issn = {15731499},
journal = {Computational Geosciences},
keywords = {Adjoint method,Control set cardinality reduction,Optimization dimensionality reduction,Parametrization,Particle swarm optimization,Polynomial control method,Production optimization,Smooth well-control,Waterflooding optimization},
month = {apr},
number = {2},
pages = {247--266},
publisher = {Springer International Publishing},
title = {{Dimensionality reduction for production optimization using polynomial approximations}},
url = {https://link.springer.com/article/10.1007/s10596-016-9610-3},
volume = {21},
year = {2017}
}
@article{Chanona2021,
abstract = {This paper investigates a new class of modifier-adaptation schemes to overcome plant-model mismatch in real-time optimization of uncertain processes. The main contribution lies in the integration of concepts from the fields of Bayesian optimization and derivative-free optimization. The proposed schemes embed a physical model and rely on trust-region ideas to minimize risk during the exploration, while employing Gaussian process regression to capture the plant-model mismatch in a non-parametric way and drive the exploration by means of acquisition functions. The benefits of using an acquisition function, knowing the process noise level, or specifying a nominal process model are analyzed on numerical case studies, including a semi-batch photobioreactor optimization problem with a dozen decision variables.},
archivePrefix = {arXiv},
arxivId = {2009.08819},
author = {Chanona, E. A.del Rio and Petsagkourakis, P. and Bradford, E. and Graciano, J. E.Alves and Chachuat, B.},
doi = {10.1016/j.compchemeng.2021.107249},
eprint = {2009.08819},
issn = {00981354},
journal = {Computers \& Chemical Engineering},
keywords = {Acquisition function,Bayesian optimization,Gaussian process regression,Model-free RTO,Modifier adaptation,Real-time optimization,Trust region},
month = {apr},
pages = {107249},
publisher = {Elsevier Ltd},
title = {{Real-time optimization meets Bayesian optimization and derivative-free optimization: A tale of modifier adaptation}},
volume = {147},
year = {2021}
}
@misc{Anderson2020,
abstract = {In this paper, we consider the problem of certifying the robustness of neural networks to perturbed and adversarial input data. Such certification is imperative for the application of neural networks in safety-critical decisionmaking and control systems. Certification techniques using convex optimization have been proposed, but they often suffer from relaxation errors that void the certificate. Our work exploits the structure of ReLU networks to improve relaxation errors through a novel partition-based certification procedure. The proposed method is proven to tighten existing linear programming relaxations, and asymptotically achieves zero relaxation error as the partition is made finer. We develop a finite partition that attains zero relaxation error and use the result to derive a tractable partitioning scheme that minimizes the worst-case relaxation error. Experiments using real data show that the partitioning procedure is able to issue robustness certificates in cases where prior methods fail. Consequently, partition-based certification procedures are found to provide an intuitive, effective, and theoretically justified method for tightening existing convex relaxation techniques.},
archivePrefix = {arXiv},
arxivId = {2004.00570},
author = {Anderson, Brendon G. and Ma, Ziye and Li, Jingqi and Sojoudi, Somayeh},
booktitle = {arXiv},
eprint = {2004.00570},
issn = {23318422},
title = {{Tightened convex relaxations for neural network robustness certification}},
year = {2020}
}

@article{Houska,
author = {Houska, Boris and Frasch, Janick and Diehl, Moritz},
title = {An Augmented Lagrangian Based Algorithm for Distributed NonConvex Optimization},
journal = {SIAM Journal on Optimization},
volume = {26},
number = {2},
pages = {1101-1127},
year = {2016},
doi = {10.1137/140975991},

URL = { 
    
        https://doi.org/10.1137/140975991
    
    

},
eprint = { 
    
        https://doi.org/10.1137/140975991
    
    

}
,
    abstract = { This paper is about distributed derivative-based algorithms for solving optimization problems with a separable (potentially nonconvex) objective function and coupled affine constraints. A parallelizable method is proposed that combines ideas from the fields of sequential quadratic programming and augmented Lagrangian algorithms. The method negotiates shared dual variables that may be interpreted as prices, a concept employed in dual decomposition methods and the alternating direction method of multipliers (ADMM). Here, each agent solves its own small-scale nonlinear programming problem and communicates with other agents by solving coupled quadratic programming problems. These coupled quadratic programming problems have equality constraints for which parallelizable methods are available. The use of techniques associated with standard sequential quadratic programming methods gives a method with superlinear or quadratic convergence rate under suitable conditions. This is in contrast to existing decomposition methods, such as ADMM, which have a linear convergence rate. It is shown how the proposed algorithm may be extended using globalization techniques that guarantee convergence to a local minimizer from any initial starting point. }
}

@article{doi:10.1137/140975991,
author = {Houska, Boris and Frasch, Janick and Diehl, Moritz},
title = {An Augmented Lagrangian Based Algorithm for Distributed NonConvex Optimization},
journal = {SIAM Journal on Optimization},
volume = {26},
number = {2},
pages = {1101-1127},
year = {2016},
doi = {10.1137/140975991},

URL = { 
    
        https://doi.org/10.1137/140975991
    
    

},
eprint = { 
    
        https://doi.org/10.1137/140975991
    
    

}
,
    abstract = { This paper is about distributed derivative-based algorithms for solving optimization problems with a separable (potentially nonconvex) objective function and coupled affine constraints. A parallelizable method is proposed that combines ideas from the fields of sequential quadratic programming and augmented Lagrangian algorithms. The method negotiates shared dual variables that may be interpreted as prices, a concept employed in dual decomposition methods and the alternating direction method of multipliers (ADMM). Here, each agent solves its own small-scale nonlinear programming problem and communicates with other agents by solving coupled quadratic programming problems. These coupled quadratic programming problems have equality constraints for which parallelizable methods are available. The use of techniques associated with standard sequential quadratic programming methods gives a method with superlinear or quadratic convergence rate under suitable conditions. This is in contrast to existing decomposition methods, such as ADMM, which have a linear convergence rate. It is shown how the proposed algorithm may be extended using globalization techniques that guarantee convergence to a local minimizer from any initial starting point. }
}



@article{Wang2017,
abstract = {Simulation optimization (SO) problems can be difficult to solve because of the lack of knowledge of the algebraic model equations and the unknown structure of the noise inherent to the simulation. It is important to investigate approaches capable of handling noise in order to achieve optimal solution with efficiency. In recent years, surrogate-based methods for SO problems have gained increasing attention from different research communities. In this work, we adapted a one-stage adaptive sampling approach to a Kriging-based optimization framework for simulations with heteroscedastic noise. We compared its performance with another Kriging-based approach using expected improvement as the infill criterion. On the basis of the results of several test problems, each with various noise scenarios, we discussed the benefits and limitations of both algorithms. Finally, we show the application of both algorithms to finding the optimal operation conditions of a continuous pharmaceutical manufacturing simulation model. (Graph Presented).},
author = {Wang, Zilong and Ierapetritou, Marianthi},
doi = {10.1021/acs.iecr.7b00867},
issn = {15205045},
journal = {Industrial and Engineering Chemistry Research},
month = {sep},
number = {38},
pages = {10720--10732},
publisher = {American Chemical Society},
title = {{A Novel Surrogate-Based Optimization Method for Black-Box Simulation with Heteroscedastic Noise}},
url = {https://pubs.acs.org/doi/abs/10.1021/acs.iecr.7b00867},
volume = {56},
year = {2017}
}
@article{Balcan2020,
abstract = {Data driven algorithm design is an important aspect of modern data science and algorithm design. Rather than using off the shelf algorithms that only have worst case performance guarantees, practitioners often optimize over large families of parametrized algorithms and tune the parameters of these algorithms using a training set of problem instances from their domain to determine a configuration with high expected performance over future instances. However, most of this work comes with no performance guarantees. The challenge is that for many combinatorial problems of significant importance including partitioning, subset selection, and alignment problems, a small tweak to the parameters can cause a cascade of changes in the algorithm's behavior, so the algorithm's performance is a discontinuous function of its parameters. In this chapter, we survey recent work that helps put data-driven combinatorial algorithm design on firm foundations. We provide strong computational and statistical performance guarantees, both for the batch and online scenarios where a collection of typical problem instances from the given application are presented either all at once or in an online fashion, respectively.},
archivePrefix = {arXiv},
arxivId = {2011.07177},
author = {Balcan, Maria-Florina},
eprint = {2011.07177},
file = {:C\:/Users/dv516/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Balcan - 2020 - Data-driven Algorithm Design.pdf:pdf},
month = {nov},
title = {{Data-driven Algorithm Design}},
url = {http://arxiv.org/abs/2011.07177},
year = {2020}
}
@article{Geoffrion1970a,
abstract = { The problem manipulations and solution strategies of Part I of this paper are now further illustrated by combining them in various ways to yield several known algorithms. The main object is not an exposition of these algorithms, although this is certainly important; rather, we wish to focus on the principal patterns in which manipulations and strategies can be assembled. These patterns constitute the real common denominators in the literature on large-scale programming. See Table 2 in Part I. },
author = {Geoffrion, Arthur M.},
doi = {10.1287/mnsc.16.11.676},
issn = {0025-1909},
journal = {Management Science},
month = {jul},
number = {11},
pages = {676--691},
publisher = {Institute for Operations Research and the Management Sciences (INFORMS)},
title = {{Elements of Large Scale Mathematical Programming Part II: Synthesis of Algorithms and Bibliography}},
url = {https://pubsonline.informs.org/doi/abs/10.1287/mnsc.16.11.676},
volume = {16},
year = {1970}
}
@article{Boukouvala2017,
abstract = {The algorithmic framework ARGONAUT is presented for the global optimization of general constrained grey-box problems. ARGONAUT incorporates variable selection, bounds tightening and constrained sampling techniques, in order to develop accurate surrogate representations of unknown equations, which are globally optimized. ARGONAUT is tested on a large set of test problems for constrained global optimization with a large number of input variables and constraints. The performance of the presented framework is compared to that of existing techniques for constrained derivative-free optimization.},
author = {Boukouvala, Fani and Floudas, Christodoulos A},
doi = {10.1007/s11590-016-1028-2},
file = {::},
keywords = {Derivative-free optimization,General constraints,Grey-box optimization,Nonlinear programming,Surrogate modeling,Variable selection},
pages = {895--913},
title = {{ARGONAUT: AlgoRithms for Global Optimization of coNstrAined grey-box compUTational problems}},
volume = {11},
year = {2017}
}
@article{Sargent2004,
author = {Sargent, R. W.H.},
doi = {10.1016/j.compchemeng.2003.09.032},
issn = {00981354},
journal = {Computers \& Chemical Engineering},
month = {apr},
number = {4},
pages = {437--439},
publisher = {Elsevier Ltd},
title = {{Introduction: 25 years of progress in process systems engineering}},
volume = {28},
year = {2004}
}
@article{Koch,
abstract = {Machine learning applications often require hyperparameter tuning. The hyperparameters usually drive both the efficiency of the model training process and the resulting model quality. For hyperparame-ter tuning, machine learning algorithms are complex black-boxes. This creates a class of challenging optimization problems, whose objective functions tend to be nonsmooth, discontinuous, unpredictably varying in computational expense, and include continuous, categorical, and/or integer variables. Further, function evaluations can fail for a variety of reasons including numerical difficulties or hardware failures. Additionally, not all hyperparameter value combinations are compatible, which creates so called hidden constraints. Robust and efficient optimization algorithms are needed for hyper-parameter tuning. In this paper we present an automated parallel derivative-free optimization framework called Autotune, which combines a number of specialized sampling and search methods that are very effective in tuning machine learning models despite these challenges. Autotune provides significantly improved models over using default hyperparameter settings with minimal user interaction on real-world applications. Given the inherent expense of training numerous candidate models, we demonstrate the effectiveness of Autotune's search methods and the efficient distributed and parallel paradigms for training and tuning models, and also discuss the resource trade-offs associated with the ability to both distribute the training process and parallelize the tuning process.},
archivePrefix = {arXiv},
arxivId = {1804.07824v2},
author = {Koch, Patrick and Golovidov, Oleg and Gardner, Steven and Wujek, Brett and Griffin, Joshua and Xu, Yan},
doi = {10.1145/3219819.3219837},
eprint = {1804.07824v2},
isbn = {9781450355520},
journal = {KDD},
keywords = {Bayesian Optimization,CCS CONCEPTS • Computer systems organization → Dis,Distributed Computing System,Hyperparameters,KEYWORDS Derivative-free Optimization,Stochastic Optimization,• Mathematics of computing → Optimization with ran},
title = {{Autotune: A Derivative-free Optimization Framework for Hyperparameter Tuning}},
url = {https://doi.org/10.1145/3219819.3219837},
volume = {18}
}
@article{Cubillos2007,
abstract = {This paper investigates the feasibility of using grey-box neural models (GNM) in Real Time Optimization (RTO). These models are based on a suitable combination of fundamental conservation laws and neural networks, being used in at least two different ways: to complement available phenomenological knowledge with empirical information, or to reduce dimensionality of complex rigorous physical models. We have observed that the benefits of using these simple adaptable models are counteracted by some difficulties associated with the solution of the optimization problem. Nonlinear Programming (NLP) algorithms failed in finding the global optimum due to the fact that neural networks can introduce multimodal objective functions. One alternative considered to solve this problem was the use of some kind of evolutionary algorithms, like Genetic Algorithms (GA). Although these algorithms produced better results in terms of finding the appropriate region, they took long periods of time to reach the global optimum. It was found that a combination of genetic and nonlinear programming algorithms can be use to fast obtain the optimum solution. The proposed approach was applied to the Williams-Otto reactor, considering three different GNM models of increasing complexity. Results demonstrated that the use of GNM models and mixed GA/NLP optimization algorithms is a promissory approach for solving dynamic RTO problems.},
author = {Cubillos, F. A. and Acu{\~{n}}a, G. and Lima, E. L.},
doi = {10.1590/S0104-66322007000300012},
file = {:C\:/Users/dv516/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Cubillos, Acu{\~{n}}a, Lima - 2007 - Real-time process optimization based on grey-box neural models.pdf:pdf},
issn = {01046632},
journal = {Brazilian Journal of Chemical Engineering},
keywords = {Genetic algorithms,Grey-box neural models,Real time optimization},
number = {3},
pages = {433--443},
publisher = {Assoc. Brasiliera de Eng. Quimica / Braz. Soc. Chem. Eng.},
title = {{Real-time process optimization based on grey-box neural models}},
url = {www.abeq.org.br/bjche},
volume = {24},
year = {2007}
}
@article{Phuyal2020,
abstract = {Smart manufacturing is the technology utilizing the interconnected machines and tools for improving manufacturing performance and optimizing the energy and workforce required by the implementation of bigdata processing, artificial intelligence and advanced robotics technology and interconnectivity of them. This paper defines and discusses the smart manufacturing system and states it current implementation status and analyzes the gap between current manufacturing system and the predicted future smart manufacturing system, discusses the technologies associated with it and their contribution in smart manufacturing technology. Also, to realize this rapidly growing technology and cover its all dimensions a survey of the latest developments in this field and its impacts were analyzed and presented along with the challenges of implementation, opportunities and the future directions for smart manufacturing system.},
author = {Phuyal, Sudip and Bista, Diwakar and Bista, Rabindra},
doi = {10.1016/j.sftr.2020.100023},
file = {:C\:/Users/dv516/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Phuyal, Bista, Bista - 2020 - Challenges, Opportunities and Future Directions of Smart Manufacturing A State of Art Review.pdf:pdf},
issn = {26661888},
journal = {Sustainable Futures},
month = {jan},
pages = {100023},
publisher = {Elsevier BV},
title = {{Challenges, Opportunities and Future Directions of Smart Manufacturing: A State of Art Review}},
volume = {2},
year = {2020}
}
@article{Morinelly2016,
abstract = {An adaptive optimal control algorithm for systems with uncertain dynamics is formulated under a Reinforcement Learning framework. An embedded exploratory component is included explicitly in the objective function of an output feedback receding horizon Model Predictive Control problem. The optimization is formulated as a Quadratically Constrained Quadratic Program and it is solved to e-global optimality. The iterative interaction between the action specified by the optimal solution and the approximation of cost functions balances the exploitation of current knowledge and the need for exploration. The proposed method is shown to converge to the optimal policy for a controllable discrete time linear plant with unknown output parameters.},
author = {Morinelly, Juan E. and Ydstie, B. Erik},
doi = {10.1016/J.IFACOL.2016.07.276},
file = {:C\:/Users/dv516/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Morinelly, Ydstie - 2016 - Dual MPC with Reinforcement Learning.pdf:pdf},
issn = {2405-8963},
journal = {IFAC-PapersOnLine},
month = {jan},
number = {7},
pages = {266--271},
publisher = {Elsevier},
title = {{Dual MPC with Reinforcement Learning}},
url = {https://www.sciencedirect.com/science/article/pii/S2405896316304839},
volume = {49},
year = {2016}
}
@inproceedings{Wilder2019,
abstract = {Creating impact in real-world settings requires artificial intelligence techniques to span the full pipeline from data, to predictive models, to decisions. These components are typically approached separately: a machine learning model is first trained via a measure of predictive accuracy, and then its predictions are used as input into an optimization algorithm which produces a decision. However, the loss function used to train the model may easily be misaligned with the end goal, which is to make the best decisions possible. Hand-tuning the loss function to align with optimization is a difficult and error-prone process (which is often skipped entirely). We focus on combinatorial optimization problems and introduce a general framework for decision-focused learning, where the machine learning model is directly trained in conjunction with the optimization algorithm to produce high-quality decisions. Technically, our contribution is a means of integrating common classes of discrete optimization problems into deep learning or other predictive models, which are typically trained via gradient descent. The main idea is to use a continuous relaxation of the discrete problem to propagate gradients through the optimization procedure. We instantiate this framework for two broad classes of combinatorial problems: linear programs and submodular maximization. Experimental results across a variety of domains show that decision-focused learning often leads to improved optimization performance compared to traditional methods. We find that standard measures of accuracy are not a reliable proxy for a predictive model's utility in optimization, and our method's ability to specify the true goal as the model's training objective yields substantial dividends across a range of decision problems.},
archivePrefix = {arXiv},
arxivId = {1809.05504},
author = {Wilder, Bryan and Dilkina, Bistra and Tambe, Milind},
booktitle = {33rd AAAI Conference on Artificial Intelligence, AAAI 2019, 31st Innovative Applications of Artificial Intelligence Conference, IAAI 2019 and the 9th AAAI Symposium on Educational Advances in Artificial Intelligence, EAAI 2019},
doi = {10.1609/aaai.v33i01.33011658},
eprint = {1809.05504},
file = {::},
isbn = {9781577358091},
issn = {2159-5399},
month = {jul},
number = {01},
pages = {1658--1666},
publisher = {AAAI Press},
title = {{Melding the data-decisions pipeline: Decision-focused learning for combinatorial optimization}},
url = {www.aaai.org},
volume = {33},
year = {2019}
}
@article{Henao2011,
abstract = {In principle, optimization-based "superstructure" methods for process synthesis can be more powerful than sequential-conceptual methods as they account for all complex interactions between design decisions. However, these methods have not been widely adopted because they lead to mixed-integer nonlinear programs that are hard to solve, especially when realistic unit operation models are used. To address this challenge, we develop a superstructure-based strategy where complex unit models are replaced with surrogate models built from data generated via commercial process simulators. In developing this strategy, we study aspects such as the systematic design of process unit surrogate models, the generation of simulation data, the selection of the surrogate's structure, and the required model fitting. We also present how these models can be reformulated and incorporated into mathematical programming superstructure formulations. Finally, we discuss the application of the proposed strategy to a number of applications. Copyright {\textcopyright} 2010 American Institute of Chemical Engineers (AIChE).},
author = {Henao, Carlos A. and Maravelias, Christos T.},
doi = {10.1002/aic.12341},
issn = {00011541},
journal = {AIChE Journal},
keywords = {Process optimization,Process synthesis,Surrogate models},
title = {{Surrogate-based superstructure optimization framework}},
year = {2011}
}
@article{MarchettiMiguelAZamarripaJuanAReyes-LabartaIgnacioEGrossmannWileyBuceyRitaAMajewski2016,
abstract = {Optimal planning and feedstock-mix selection for multiproduct polymer production.Computers \& Chemical Engineering http://dx.},
author = {{Marchetti Miguel A Zamarripa Juan A Reyes-Labarta Ignacio E Grossmann Wiley Bucey Rita A Majewski}, Pablo A},
doi = {10.1016/j.compchemeng.2016.09.002},
file = {::},
journal = {Computers \& Chemical Engineering},
keywords = {Polymer production,continuous processes,plant and process optimization,polymer scheduling},
title = {{Title: Optimal planning and feedstock-mix selection for multiproduct polymer production}},
url = {http://dx.doi.org/doi:10.1016/j.compchemeng.2016.09.002},
year = {2016}
}
@inproceedings{Asprey2000,
abstract = {A general, systematic procedure is presented to support the development and statistical verification of dynamic process models. Within this procedure, methods are presented to address several key aspects, such as structural identifiability and distinguishability testing, as well as optimal design of dynamic experiments for both model discrimination and improving parameter precision. A novel optimisation-based approach is introduced for testing of model structural identifiability and distinguishability, involving semi-infinite programming and max- min problems. The design of dynamic experiments is cast as an optimal control problem within a framework that enables the calculation of optimal sampling points, experiment duration, fixed and variable external control profiles, and initial conditions of a dynamic experiment subject to general constraints on inputs and outputs. Within this framework, methods are presented to provide experiment design robustness, accounting for parameter uncertainty. The procedure is demonstrated through a practical biotechnology example. (C) 2000 Elsevier Science Ltd.},
author = {Asprey, S. P. and Macchietto, S.},
booktitle = {Computers \& Chemical Engineering},
doi = {10.1016/S0098-1354(00)00328-8},
issn = {00981354},
keywords = {Dynamic modelling,Optimal experiment design,Parameter estimation},
month = {jul},
number = {2-7},
pages = {1261--1267},
publisher = {Elsevier Science Ltd},
title = {{Statistical tools for optimal dynamic model building}},
volume = {24},
year = {2000}
}
@incollection{Brunaud2018,
abstract = {Lagrangean decomposition has been used to overcome the difficulties in optimizing large-scale supply chain planning models. Decomposing the problem by time periods has been established as a useful technique. In this paper a novel decomposition scheme by products is presented. The decomposition is based on a reformulation of knapsack constraints in the problem. The new approach also allows for simultaneous decomposition by products and time periods, enabling the generation of a large number of subproblems, with the potential benefit of using parallel computing. The case study shows that product decomposition shows a similar performance than temporal decomposition. Selecting different orders of products and aggregating the linking constraints can improve the efficiency of the algorithm.},
author = {Brunaud, Braulio and {Paz Ochoa}, M. and Grossmann, Ignacio E.},
booktitle = {Computer Aided Chemical Engineering},
doi = {10.1016/B978-0-444-64241-7.50204-4},
issn = {15707946},
keywords = {Lagrange Decomposition,Product Decomposition,Supply Chain Planning},
month = {jan},
pages = {1255--1260},
publisher = {Elsevier B.V.},
title = {{Product Decomposition in Supply Chain Planning}},
volume = {44},
year = {2018}
}
@techreport{Homem-De-Mello2014,
abstract = {This paper surveys the use of Monte Carlo sampling-based methods for stochastic optimization problems. Such methods are required when-as it often happens in practice-the model involves quantities such as expectations and probabilities that cannot be evaluated exactly. While estimation procedures via sampling are well studied in statistics, the use of such methods in an optimization context creates new challenges such as ensuring convergence of optimal solutions and optimal values , testing optimality conditions, choosing appropriate sample sizes to balance the effort between optimization and estimation, and many other issues. Much work has been done in the literature to address these questions. The purpose of this paper is to give an overview of some of that work, with the goal of introducing the topic to students and researchers and providing a practical guide for someone who needs to solve a stochastic optimization problem with sampling.},
author = {Homem-De-Mello, Tito and Bayraksan, G{\"{u}}zin},
file = {::},
title = {{Monte Carlo Sampling-Based Methods for Stochastic Optimization}},
year = {2014}
}
@article{Grossmann2005,
abstract = {Enterprise-wide optimization (EWO) is a new emerging area that lies at the interface of chemical engineering and operations research, and has become a major goal in the process industries due to the increasing pressures for remaining competitive in the global marketplace. EWO involves optimizing the operations of supply, manufacturing and distribution activities of a company to reduce costs and inventories. A major focus in EWO is the optimal operation of manufacturing facilities, which often requires the use of nonlinear process models. Major operational items include planning, scheduling, real-time optimization and inventory control. One of the key features of EWO is integration of the information and the decision-making among the various functions that comprise the supply chain of the company. This can be achieved with modern IT tools, which together with the internet, have promoted e-commerce. However, as will be discussed, to fully realize the potential of transactional IT tools, the development of sophisticated deterministic and stochastic linear/nonlinear optimization models and algorithms (analytical IT tools) is needed to explore and analyze alternatives of the supply chain to yield overall optimum economic performance, as well as high levels of customer satisfaction. An additional challenge is the integrated and coordinated decision-making across the various functions in a company (purchasing, manufacturing, distribution, sales), across various geographically distributed organizations (vendors, facilities and markets), and across various levels of decision-making (strategic, tactical and operational). {\textcopyright} 2005 American Institute of Chemical Engineers.},
author = {Grossmann, Ignacio},
doi = {10.1002/aic.10617},
issn = {0001-1541},
journal = {AIChE Journal},
month = {jul},
number = {7},
pages = {1846--1857},
publisher = {John Wiley & Sons, Ltd},
title = {{Enterprise-wide optimization: A new frontier in process systems engineering}},
url = {http://doi.wiley.com/10.1002/aic.10617},
volume = {51},
year = {2005}
}
@article{Hubbs2020a,
abstract = {This work examines applying deep reinforcement learning to a chemical production scheduling process to account for uncertainty and achieve online, dynamic scheduling, and benchmarks the results with a mixed-integer linear programming (MILP) model that schedules each time interval on a receding horizon basis. An industrial example is used as a case study for comparing the differing approaches. Results show that the reinforcement learning method outperforms the naive MILP approaches and is competitive with a shrinking horizon MILP approach in terms of profitability, inventory levels, and customer service. The speed and flexibility of the reinforcement learning system is promising for achieving real-time optimization of a scheduling system, but there is reason to pursue integration of data-driven deep reinforcement learning methods and model-based mathematical optimization approaches.},
author = {Hubbs, Christian D. and Li, Can and Sahinidis, Nikolaos V. and Grossmann, Ignacio E. and Wassick, John M.},
doi = {10.1016/J.COMPCHEMENG.2020.106982},
file = {:C\:/Users/dv516/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Hubbs et al. - 2020 - A deep reinforcement learning approach for chemical production scheduling.pdf:pdf},
issn = {0098-1354},
journal = {Computers \& Chemical Engineering},
month = {oct},
pages = {106982},
publisher = {Pergamon},
title = {{A deep reinforcement learning approach for chemical production scheduling}},
url = {https://www.sciencedirect.com/science/article/pii/S0098135420301599#!},
volume = {141},
year = {2020}
}
@article{Venkatasubramanian2019,
author = {Venkatasubramanian, Venkat},
doi = {10.1002/aic.16489},
file = {::},
issn = {15475905},
journal = {AIChE Journal},
keywords = {AI,control,data science,design,diagnosis,machine learning,materials science,optimization,predictive analytics,safety},
month = {feb},
number = {2},
pages = {466--478},
publisher = {John Wiley and Sons Inc.},
title = {{The promise of artificial intelligence in chemical engineering: Is it here, finally?}},
url = {https://aiche.onlinelibrary.wiley.com/doi/full/10.1002/aic.16489 https://aiche.onlinelibrary.wiley.com/doi/abs/10.1002/aic.16489 https://aiche.onlinelibrary.wiley.com/doi/10.1002/aic.16489},
volume = {65},
year = {2019}
}
@article{Shah2005a,
abstract = {A large body of work exists in process industry supply chain optimisation. We describe the state of the art of research in infrastructure design, modelling and analysis and planning and scheduling, together with some industrial examples. We draw some conclusions about the degree to which different classes of problem have been solved, and discuss challenges for the future.},
author = {Shah, Nilay},
doi = {10.1016/J.COMPCHEMENG.2005.02.023},
file = {:C\:/Users/dv516/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Shah - 2005 - Process industry supply chains Advances and challenges.pdf:pdf},
issn = {0098-1354},
journal = {Computers \& Chemical Engineering},
month = {may},
number = {6},
pages = {1225--1235},
publisher = {Pergamon},
title = {{Process industry supply chains: Advances and challenges}},
url = {https://www.sciencedirect.com/science/article/pii/S009813540500013X},
volume = {29},
year = {2005}
}

@techreport{Wolpert1997,
abstract = {A framework is developed to explore the connection between effective optimization algorithms and the problems they are solving. A number of "no free lunch" (NFL) theorems are presented which establish that for any algorithm, any elevated performance over one class of problems is offset by performance over another class. These theorems result in a geometric interpretation of what it means for an algorithm to be well suited to an optimization problem. Applications of the NFL theorems to information-theoretic aspects of optimization and benchmark measures of performance are also presented. Other issues addressed include time-varying optimization problems and a priori "head-to-head" minimax distinctions between optimization algorithms, distinctions that result despite the NFL theorems' enforcing of a type of uniformity over all algorithms.},
author = {Wolpert, David H and Macready, William G},
booktitle = {IEEE TRANSACTIONS ON EVOLUTIONARY COMPUTATION},
file = {::},
keywords = {Index Terms-Evolutionary algorithms,information theory,optimization},
number = {1},
pages = {67},
title = {{No Free Lunch Theorems for Optimization}},
volume = {1},
year = {1997}
}
@article{Shin2019b,
abstract = {This paper provides an introduction to Reinforcement Learning (RL) technology, summarizes recent developments in this area, and discusses their potential implications for the field of process control, and more generally, of operational decision-making. The paper begins with an introduction to RL that allows an agent to learn, through trial and error, the best way to accomplish a task. We then highlight new developments in RL that have led to the recent wave of applications and media interest. A comparison of the key features of RL and mathematical programming based methods (e.g., model predictive control) is then presented to clarify their similarities and differences. This is followed by an assessment of several ways that RL technology can potentially be used in process control and operational decision applications. A final section summarizes our conclusions and lists directions for future RL research that may improve its relevance for the process systems engineering field.},
author = {Shin, Joohyun and Badgwell, Thomas A. and Liu, Kuang-Hung and Lee, Jay H.},
doi = {10.1016/J.COMPCHEMENG.2019.05.029},
issn = {0098-1354},
journal = {Computers \& Chemical Engineering},
month = {aug},
pages = {282--294},
publisher = {Pergamon},
title = {{Reinforcement Learning – Overview of recent progress and implications for process control}},
url = {https://www.sciencedirect.com/science/article/pii/S0098135419300754},
volume = {127},
year = {2019}
}
@article{Lucia2015a,
abstract = {We address the problemof controlling interconnected, possibly large-scale systems of systems using distributed model predictive control. We consider the case in which the nonlinear subsystems can be coupled physically and can have shared constraints. The presented approach is based on the transmission of contracts between neighboring subsystems. Contracts are guaranteed sequences of possible future trajectories or trajectory sets of the coupling variables of the subsystems. We derive for the approach sufficient conditions for guaranteeing recursive feasibility and Input-to-State stability. Furthermore, we discuss the case of the so-called Plug & Play operations in which a subsystem in the network is replaced by a new, possibly different, one and when a subsystem is removed or added to the network.},
author = {Lucia, Sergio and K{\"{o}}gel, Markus and Findeisen, Rolf},
doi = {10.1016/J.IFACOL.2015.11.284},
file = {:C\:/Users/dv516/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Lucia, K{\"{o}}gel, Findeisen - 2015 - Contract-based Predictive Control of Distributed Systems with Plug and Play Capabilities.pdf:pdf},
issn = {2405-8963},
journal = {IFAC-PapersOnLine},
month = {jan},
number = {23},
pages = {205--211},
publisher = {Elsevier},
title = {{Contract-based Predictive Control of Distributed Systems with Plug and Play Capabilities}},
url = {https://www.sciencedirect.com/science/article/pii/S2405896315025689},
volume = {48},
year = {2015}
}
@misc{,
title = {{Industrie 4.0: What Does It Mean for Chemical Companies? | Chemical Processing}},
url = {https://www.chemicalprocessing.com/articles/2017/industrie-4-0-what-does-it-mean-for-chemical-companies/},
urldate = {2021-05-01}
}
@article{Costa2005,
abstract = {Network design problems concern the selection of arcs in a graph in order to satisfy, at minimum cost, some flow requirements, usually expressed in the form of origin-destination pair demands. Benders decomposition methods, based on the idea of partition and delayed constraint generation, have been successfully applied to many of these problems. This article presents a review of these applications. {\textcopyright} 2003 Elsevier Ltd. All rights reserved.},
author = {Costa, Alysson M.},
doi = {10.1016/j.cor.2003.11.012},
issn = {03050548},
journal = {Computers and Operations Research},
keywords = {Benders decomposition,Fixed charge,Network design},
month = {jun},
number = {6},
pages = {1429--1450},
publisher = {Elsevier Ltd},
title = {{A survey on benders decomposition applied to fixed-charge network design problems}},
volume = {32},
year = {2005}
}
@incollection{Nocedal2006,
author = {Nocedal, Jorge and Wright, Stephen J.},
booktitle = {Springer Series in Operations Research and Financial Engineering},
doi = {10.1201/b19115-11},
issn = {21971773},
title = {{Numerical optimization}},
year = {2006}
}
@article{Bradford2020,
abstract = {Nonlinear model predictive control (NMPC) is one of the few control methods that can handle multivariable nonlinear control systems with constraints. Gaussian processes (GPs) present a powerful tool to identify the required plant model and quantify the residual uncertainty of the plant-model mismatch. It is crucial to consider this uncertainty, since it may lead to worse control performance and constraint violations. In this paper we propose a new method to design a GP-based NMPC algorithm for finite horizon control problems. The method generates Monte Carlo samples of the GP offline for constraint tightening using back-offs. The tightened constraints then guarantee the satisfaction of chance constraints online. Advantages of our proposed approach over existing methods include fast online evaluation, consideration of closed-loop behaviour, and the possibility to alleviate conservativeness by considering both online learning and state dependency of the uncertainty. The algorithm is verified on a challenging semi-batch bioprocess case study.},
archivePrefix = {arXiv},
arxivId = {1908.01786},
author = {Bradford, Eric and Imsland, Lars and Zhang, Dongda and {del Rio Chanona}, Ehecatl Antonio},
doi = {10.1016/j.compchemeng.2020.106844},
eprint = {1908.01786},
file = {::},
issn = {00981354},
journal = {Computers \& Chemical Engineering},
keywords = {Machine learning,Model-based nonlinear control,Probabilistic constraints,Robust control,State space,Uncertain dynamic systems},
month = {aug},
pages = {106844},
publisher = {Elsevier Ltd},
title = {{Stochastic data-driven model predictive control using gaussian processes}},
volume = {139},
year = {2020}
}

@article{Ning2019a,
abstract = {This paper reviews recent advances in the field of optimization under uncertainty via a modern data lens, highlights key research challenges and promise of data-driven optimization that organically integrates machine learning and mathematical programming for decision-making under uncertainty, and identifies potential research opportunities. A brief review of classical mathematical programming techniques for hedging against uncertainty is first presented, along with their wide spectrum of applications in Process Systems Engineering. A comprehensive review and classification of the relevant publications on data-driven distributionally robust optimization, data-driven chance constrained program, data-driven robust optimization, and data-driven scenario-based optimization is then presented. This paper also identifies fertile avenues for future research that focuses on a closed-loop data-driven optimization framework, which allows the feedback from mathematical programming to machine learning, as well as scenario-based optimization leveraging the power of deep learning techniques. Perspectives on online learning-based data-driven multistage optimization with a learning-while-optimizing scheme is presented.},
archivePrefix = {arXiv},
arxivId = {1904.01934},
author = {Ning, Chao and You, Fengqi},
doi = {10.1016/j.compchemeng.2019.03.034},
eprint = {1904.01934},
file = {::},
journal = {Computers \& Chemical Engineering},
keywords = {Big data,Data-driven optimization,Decision making under uncertainty,Deep learning,Machine learning},
month = {apr},
pages = {434--448},
publisher = {Elsevier Ltd},
title = {{Optimization under Uncertainty in the Era of Big Data and Deep Learning: When Machine Learning Meets Mathematical Programming}},
url = {http://arxiv.org/abs/1904.01934 http://dx.doi.org/10.1016/j.compchemeng.2019.03.034},
volume = {125},
year = {2019}
}
@article{Coulson2018,
abstract = {We consider the problem of optimal trajectory tracking for unknown systems. A novel data-enabled predictive control (DeePC) algorithm is presented that computes optimal and safe control policies using real-time feedback driving the unknown system along a desired trajectory while satisfying system constraints. Using a finite number of data samples from the unknown system, our proposed algorithm uses a behavioural systems theory approach to learn a non-parametric system model used to predict future trajectories. The DeePC algorithm is shown to be equivalent to the classical and widely adopted Model Predictive Control (MPC) algorithm in the case of deterministic linear time-invariant systems. In the case of nonlinear stochastic systems, we propose regularizations to the DeePC algorithm. Simulations are provided to illustrate performance and compare the algorithm with other methods.},
archivePrefix = {arXiv},
arxivId = {1811.05890},
author = {Coulson, Jeremy and Lygeros, John and D{\"{o}}rfler, Florian},
eprint = {1811.05890},
file = {:C\:/Users/dv516/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Coulson, Lygeros, D{\"{o}}rfler - 2018 - Data-Enabled Predictive Control In the Shallows of the DeePC.pdf:pdf},
month = {nov},
title = {{Data-Enabled Predictive Control: In the Shallows of the DeePC}},
url = {http://arxiv.org/abs/1811.05890},
year = {2018}
}
@article{Hullen2020,
abstract = {Optimization using data from complex simulations has become an attractive decision-making option, due to ability to embed high-fidelity, non-linear understanding of processes within the search for optimal values. Due to lack of tractable algebraic equations, the link between simulations and optimization is oftentimes a surrogate metamodel. However, several forms of uncertainty exist within the cycle that links simulation data, to metamodels, to optimization. Uncertainty may originate from parameters of the simulation, or the form and fitted parameters of the metamodel. This paper reviews different literatures that are relevant to surrogate-based optimization and proposes different strategies for handling uncertainty, by combining machine learning with stochastic programming, robust optimization, and discrepancy modeling. We show that incorporating uncertainty management within simulation-based optimization leads to more robust solutions, which protect the decision-maker from infeasible solutions. We present the results of our proposed approaches through a case study for direct-air capture through temperature swing adsorption.},
author = {H{\"{u}}llen, Gordon and Zhai, Jianyuan and Kim, Sun Hye and Sinha, Anshuman and Realff, Matthew J. and Boukouvala, Fani},
doi = {10.1016/j.compchemeng.2019.106519},
file = {:C\:/Users/dv516/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/H{\"{u}}llen et al. - 2020 - Managing uncertainty in data-driven simulation-based optimization(2).pdf:pdf},
issn = {00981354},
journal = {Computers \& Chemical Engineering},
keywords = {Direct air capture,Neural networks,Polynomial interpolation,Simulation optimization,Surrogate modeling},
month = {may},
pages = {106519},
publisher = {Elsevier Ltd},
title = {{Managing uncertainty in data-driven simulation-based optimization}},
volume = {136},
year = {2020}
}
@article{Silver2017,
abstract = {A long-standing goal of artificial intelligence is an algorithm that learns, tabula rasa, superhuman proficiency in challenging domains. Recently, AlphaGo became the first program to defeat a world champion in the game of Go. The tree search in AlphaGo evaluated positions and selected moves using deep neural networks. These neural networks were trained by supervised learning from human expert moves, and by reinforcement learning from self-play. Here we introduce an algorithm based solely on reinforcement learning, without human data, guidance or domain knowledge beyond game rules. AlphaGo becomes its own teacher: a neural network is trained to predict AlphaGo's own move selections and also the winner of AlphaGo's games. This neural network improves the strength of the tree search, resulting in higher quality move selection and stronger self-play in the next iteration. Starting tabula rasa, our new program AlphaGo Zero achieved superhuman performance, winning 100-0 against the previously published, champion-defeating AlphaGo.},
author = {Silver, David and Schrittwieser, Julian and Simonyan, Karen and Antonoglou, Ioannis and Huang, Aja and Guez, Arthur and Hubert, Thomas and Baker, Lucas and Lai, Matthew and Bolton, Adrian and Chen, Yutian and Lillicrap, Timothy and Hui, Fan and Sifre, Laurent and {Van Den Driessche}, George and Graepel, Thore and Hassabis, Demis},
doi = {10.1038/nature24270},
file = {::},
issn = {14764687},
journal = {Nature},
keywords = {Computational science,Computer science,Reward},
month = {oct},
number = {7676},
pages = {354--359},
pmid = {29052630},
publisher = {Nature Publishing Group},
title = {{Mastering the game of Go without human knowledge}},
url = {https://www.nature.com/articles/nature24270},
volume = {550},
year = {2017}
}
@article{Garcia1989,
abstract = {We refer to Model Predictive Control (MPC) as that family of controllers in which there is a direct use of an explicit and separately identifiable model. Control design methods based on the MPC concept have found wide acceptance in industrial applications and have been studied by academia. The reason for such popularity is the ability of MPC designs to yield high performance control systems capable of operating without expert intervention for long periods of time. In this paper the issues of importance that any control system should address are stated. MPC techniques are then reviewed in the light of these issues in order to point out their advantages in design and implementation. A number of design techniques emanating from MPC, namely Dynamic Matrix Control, Model Algorithmic Control, Inferential Control and Internal Model Control, are put in perspective with respect to each other and the relation to more traditional methods like Linear Quadratic Control is examined. The flexible constraint handling capabilities of MPC are shown to be a significant advantage in the context of the overall operating objectives of the process industries and the 1-, 2-, and ∞-norm formulations of the performance objective are discussed. The application of MPC to non-linear systems is examined and it is shown that its main attractions carry over. Finally, it is explained that though MPC is not inherently more or less robust than classical feedback, it can be adjusted more easily for robustness. {\textcopyright} 1989.},
author = {Garc{\'{i}}a, Carlos E. and Prett, David M. and Morari, Manfred},
doi = {10.1016/0005-1098(89)90002-2},
issn = {00051098},
journal = {Automatica},
keywords = {(constrained control),Computer control,predictive control,process control,quadratic programming},
month = {may},
number = {3},
pages = {335--348},
publisher = {Pergamon},
title = {{Model predictive control: Theory and practice-A survey}},
volume = {25},
year = {1989}
}



@article{Moharir2018a,
abstract = {This paper addresses the plant-wide control of the amine gas sweetening plant using distributed model predictive control. The plant is fed natural gas containing sour gases (hydrogen sulfide and carbon dioxide), which are removed by absorption in monoethanolamine solution. A plant decomposition algorithm based on modularity maximization for distributed parameter systems is used to obtain the optimal decomposition for distributed model predictive control. Comparisons are drawn among the performance and computational requirements of distributed, decentralized, and centralized model predictive controls.},
author = {Moharir, Manjiri and Pourkargar, Davood B. and Almansoori, Ali and Daoutidis, Prodromos},
doi = {10.1021/acs.iecr.8b01291},
issn = {15205045},
journal = {Industrial and Engineering Chemistry Research},
month = {oct},
number = {39},
pages = {13103--13115},
publisher = {American Chemical Society},
title = {{Distributed Model Predictive Control of an Amine Gas Sweetening Plant}},
url = {https://pubs.acs.org/doi/abs/10.1021/acs.iecr.8b01291},
volume = {57},
year = {2018}
}
@inproceedings{Ferreira2018,
abstract = {In the context of static real-time optimization, the use of measurements allows dealing with uncertainty in the form of plant-model mismatch and disturbances. Modifier adaptation (MA) is a measurement-based scheme that uses first- order corrections to the model cost and constraint functions so as to achieve plant optimality upon convergence. However, first-order corrections rely crucially on the estimation of plant gradients, which typically requires costly plant experiments. The present paper proposes to implement real-time optimization via MA but use recursive Gaussian processes to represent the plant-model mismatch and estimate the plant gradients. This way, one can (i) attenuate the effect of measurement noise, and (ii) avoid plant-gradient estimation by means finite- difference schemes and, often, additional plant experiments. We use steady-state optimization data to build Gaussian-process regression functions. The efficiency of the proposed scheme is illustrated via a constrained variant of the Williams-Otto reactor problem.},
author = {Ferreira, Tafarel De Avila and Shukla, Harsh A. and Faulwasser, Timm and Jones, Colin N. and Bonvin, Dominique},
booktitle = {2018 European Control Conference, ECC 2018},
doi = {10.23919/ECC.2018.8550397},
isbn = {9783952426982},
month = {nov},
pages = {465--470},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{Real-Time optimization of Uncertain Process Systems via Modifier Adaptation and Gaussian Processes}},
year = {2018}
}
@misc{Boukouvala2016a,
abstract = {This manuscript reviews recent advances in deterministic global optimization for Mixed-Integer Nonlinear Programming (MINLP), as well as Constrained Derivative-Free Optimization (CDFO). This work provides a comprehensive and detailed literature review in terms of significant theoretical contributions, algorithmic developments, software implementations and applications for both MINLP and CDFO. Both research areas have experienced rapid growth, with a common aim to solve a wide range of real-world problems. We show their individual prerequisites, formulations and applicability, but also point out possible points of interaction in problems which contain hybrid characteristics. Finally, an inclusive and complete test suite is provided for both MINLP and CDFO algorithms, which is useful for future benchmarking.},
author = {Boukouvala, Fani and Misener, Ruth and Floudas, Christodoulos A.},
booktitle = {European Journal of Operational Research},
doi = {10.1016/j.ejor.2015.12.018},
file = {:C\:/Users/dv516/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Boukouvala, Misener, Floudas - 2016 - Global optimization advances in Mixed-Integer Nonlinear Programming, MINLP, and Constrained Deriva.pdf:pdf},
issn = {03772217},
keywords = {Constraints,Derivative-free,Deterministic global optimization,Grey-/Black-box,MINLP},
month = {aug},
number = {3},
pages = {701--727},
publisher = {Elsevier B.V.},
title = {{Global optimization advances in Mixed-Integer Nonlinear Programming, MINLP, and Constrained Derivative-Free Optimization, CDFO}},
volume = {252},
year = {2016}
}
@article{Beykal2018b,
abstract = {This work presents recent advances within the AlgoRithms for Global Optimization of coNstrAined grey-box compUTational problems (ARGONAUT) framework, developed for optimization of systems which lack analytical forms and derivatives. A new parallel version of ARGONAUT (p-ARGONAUT) is introduced to solve high dimensional problems with a large number of constraints. This development is motivated by a challenging case study, namely the operation of an oilfield using water-flooding. The objective of this case study is the maximization of the Net Present Value over a five-year time horizon by manipulating the well pressures, while satisfying a set of complicating constraints related to water-cut limitations and water handling and storage. Dimensionality reduction is performed via the parametrization of the pressure control domain, which is then followed by global optimization of the constrained grey-box system. Results are presented for multiple case studies and the performance of p-ARGONAUT is compared to existing derivative-free optimization methods.},
author = {Beykal, Burcu and Boukouvala, Fani and Floudas, Christodoulos A. and Sorek, Nadav and Zalavadia, Hardikkumar and Gildin, Eduardo},
doi = {10.1016/j.compchemeng.2018.01.005},
issn = {00981354},
journal = {Computers \& Chemical Engineering},
keywords = {Derivative-free optimization,Grey/black-box optimization,Oil-well control,Oilfield operations,Waterflooding},
month = {jun},
pages = {99--110},
publisher = {Elsevier Ltd},
title = {{Global optimization of grey-box computational systems using surrogate functions and application to highly constrained oil-field operations}},
volume = {114},
year = {2018}
}
@inproceedings{Raghunathan2018,
abstract = {Despite their impressive performance on diverse tasks, neural networks fail catastrophically in the presence of adversarial inputs-imperceptibly but adversarially perturbed versions of natural inputs. We have witnessed an arms race between defenders who attempt to train robust networks and attackers who try to construct adversarial examples. One promise of ending the arms race is developing certified defenses, ones which are provably robust against all attackers in some family. These certified defenses are based on convex relaxations which construct an upper bound on the worst case loss over all attackers in the family. Previous relaxations are loose on networks that are not trained against the respective relaxation. In this paper, we propose a new semidefinite relaxation for certifying robustness that applies to arbitrary ReLU networks. We show that our proposed relaxation is tighter than previous relaxations and produces meaningful robustness guarantees on three different foreign networks whose training objectives are agnostic to our proposed relaxation.},
archivePrefix = {arXiv},
arxivId = {1811.01057},
author = {Raghunathan, Aditi and Steinhardt, Jacob and Liang, Percy},
booktitle = {Advances in Neural Information Processing Systems},
eprint = {1811.01057},
issn = {10495258},
title = {{Semidefinite relaxations for certifying robustness to adversarial examples}},
year = {2018}
}
@techreport{Cartis2018,
abstract = {We present DFO-LS, a software package for derivative-free optimization (DFO) for nonlinear Least-Squares (LS) problems, with optional bound constraints. Inspired by the Gauss-Newton method, DFO-LS constructs simplified linear regression models for the residuals. DFO-LS allows flexible initialization for expensive problems, whereby it can begin making progress from as few as two objective evaluations. Numerical results show DFO-LS can gain reasonable progress on some medium-scale problems with fewer objective evaluations than is needed for one gradient evaluation. DFO-LS has improved robustness to noise, allowing sample averaging, the construction of regression-based models, and multiple restart strategies together with an auto-detection mechanism. Our extensive numerical experimentation shows that restarting the solver when stagnation is detected is a cheap and effective mechanism for achieving robustness, with superior performance over both sampling and regression techniques. We also present our package Py-BOBYQA, a Python implementation of BOBYQA (Powell, 2009), which also implements robustness to noise strategies. Our numerical experiments show that Py-BOBYQA is comparable to or better than existing general DFO solvers for noisy problems. In our comparisons, we introduce a new adaptive measure of accuracy for the data profiles of noisy functions that strikes a balance between measuring the true and the noisy objective improvement.},
archivePrefix = {arXiv},
arxivId = {1804.00154v2},
author = {Cartis, Coralia and Fiala, Jan and Marteau, Benjamin and Roberts, Lindon},
eprint = {1804.00154v2},
file = {:C\:/Users/dv516/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Cartis et al. - 2018 - Improving the Flexibility and Robustness of Model-Based Derivative-Free Optimization Solvers.pdf:pdf},
keywords = {90C15,90C30,90C56,derivative-free optimization,least-squares,mathematical software,performance evaluation Mathematics Subject Classif,stochastic optimization,trust region methods},
title = {{Improving the Flexibility and Robustness of Model-Based Derivative-Free Optimization Solvers}},
url = {https://github.com/numericalalgorithmsgroup/dfols},
year = {2018}
}
@article{Bogle2017,
abstract = {The challenges posed by smart manufacturing for the process industries and for process systems engineering (PSE) researchers are discussed in this article. Much progress has been made in achieving plant- and site-wide optimization, but benchmarking would give greater confidence. Technical challenges confronting process systems engineers in developing enabling tools and techniques are discussed regarding flexibility and uncertainty, responsiveness and agility, robustness and security, the prediction of mixture properties and function, and new modeling and mathematics paradigms. Exploiting intelligence from big data to drive agility will require tackling new challenges, such as how to ensure the consistency and confidentiality of data through long and complex supply chains. Modeling challenges also exist, and involve ensuring that all key aspects are properly modeled, particularly where health, safety, and environmental concerns require accurate predictions of small but critical amounts at specific locations. Environmental concerns will require us to keep a closer track on all molecular species so that they are optimally used to create sustainable solutions. Disruptive business models may result, particularly from new personalized products, but that is difficult to predict.},
author = {Bogle, Ian David Lockhart},
doi = {10.1016/J.ENG.2017.02.003},
file = {:C\:/Users/dv516/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Bogle - 2017 - A Perspective on Smart Process Manufacturing Research Challenges for Process Systems Engineers.pdf:pdf},
issn = {20958099},
journal = {Engineering},
keywords = {Flexibility,Model-based control,Optimization,Process systems engineering,Smart manufacturing,Uncertainty},
month = {apr},
number = {2},
pages = {161--165},
publisher = {Elsevier Ltd},
title = {{A Perspective on Smart Process Manufacturing Research Challenges for Process Systems Engineers}},
volume = {3},
year = {2017}
}
@article{Herrera2020,
abstract = {<p>Systems engineering is an ubiquitous discipline of Engineering overlapping industrial, chemical, mechanical, manufacturing, control, software, electrical, and civil engineering. It provides tools for dealing with the complexity and dynamics related to the optimisation of physical, natural, and virtual systems management. This paper presents a review of how multi-agent systems and complex networks theory are brought together to address systems engineering and management problems. The review also encompasses current and future research directions both for theoretical fundamentals and applications in the industry. This is made by considering trends such as mesoscale, multiscale, and multilayer networks along with the state-of-art analysis on network dynamics and intelligent networks. Critical and smart infrastructure, manufacturing processes, and supply chain networks are instances of research topics for which this literature review is highly relevant.</p>},
author = {Herrera, Manuel and P{\'{e}}rez-Hern{\'{a}}ndez, Marco and {Kumar Parlikad}, Ajith and Izquierdo, Joaqu{\'{i}}n},
doi = {10.3390/pr8030312},
file = {:C\:/Users/dv516/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Herrera et al. - 2020 - Multi-Agent Systems and Complex Networks Review and Applications in Systems Engineering.pdf:pdf},
issn = {2227-9717},
journal = {Processes},
keywords = {agent,agent systems,based control,complex networks,multi,optimisation,processes systems engineering,systems engineering},
month = {mar},
number = {3},
pages = {312},
publisher = {Multidisciplinary Digital Publishing Institute},
title = {{Multi-Agent Systems and Complex Networks: Review and Applications in Systems Engineering}},
url = {https://www.mdpi.com/2227-9717/8/3/312},
volume = {8},
year = {2020}
}
@article{Shah2005,
abstract = {A large body of work exists in process industry supply chain optimisation. We describe the state of the art of research in infrastructure design, modelling and analysis and planning and scheduling, together with some industrial examples. We draw some conclusions about the degree to which different classes of problem have been solved, and discuss challenges for the future.},
author = {Shah, Nilay},
doi = {10.1016/J.COMPCHEMENG.2005.02.023},
file = {:C\:/Users/dv516/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Shah - 2005 - Process industry supply chains Advances and challenges.pdf:pdf},
issn = {0098-1354},
journal = {Computers \& Chemical Engineering},
month = {may},
number = {6},
pages = {1225--1235},
publisher = {Pergamon},
title = {{Process industry supply chains: Advances and challenges}},
url = {https://www.sciencedirect.com/science/article/pii/S009813540500013X},
volume = {29},
year = {2005}
}
@article{Everett1963,
abstract = {The usefulness of Lagrange multipliers for optimization in the presence of constraints is not limited to differentiable functions. They can be applied to problems of maximizing an arbitrary real valued objective function over any set whatever, subject to bounds on the values of any other finite collection of real valued functions denned on the same set. While the use of the Lagrange multipliers does not guarantee that a solution will necessarily be found for all problems, it is ?fail-safe? in the sense that any solution found by their use is a true solution. Since the method is so simple compared to other available methods it is often worth trying first, and succeeds in a surprising fraction of cases. They are particularly well suited to the solution of problems of allocating limited resources among a set of independent activities.},
author = {Everett, Hugh},
doi = {10.1287/opre.11.3.399},
issn = {0030-364X},
journal = {Operations Research},
title = {{Generalized Lagrange Multiplier Method for Solving Problems of Optimum Allocation of Resources}},
year = {1963}
}
@techreport{DelRioChanona,
abstract = {This paper investigates a new class of modifier-adaptation schemes to overcome plant-model mismatch in real-time optimization of uncertain processes. The main contribution lies in the integration of concepts from the fields of Bayesian optimization and derivative-free optimization. The proposed schemes embed a physical model and rely on trust-region ideas to minimize risk during the exploration, while employing Gaussian process regression to capture the plant-model mismatch in a non-parametric way and drive the exploration by means of acquisition functions. The benefits of using an acquisition function, knowing the process noise level, or specifying a nominal process model are analyzed on numerical case studies, including a semi-batch photo-bioreactor optimization problem with a dozen decision variables.},
archivePrefix = {arXiv},
arxivId = {2009.08819v2},
author = {{Del Rio Chanona}, E A and Petsagkourakis, P and Bradford, E and {Alves Graciano}, J E and Chachuat, B},
eprint = {2009.08819v2},
file = {:C\:/Users/dv516/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Del Rio Chanona et al. - Unknown - Real-Time Optimization Meets Bayesian Optimization and Derivative-Free Optimization A Tale of Modi(2).pdf:pdf},
keywords = {Bayesian optimization,Gaussian process regression,acquisition function,model-free RTO,modifier adaptation,real-time optimization,trust region},
title = {{Real-Time Optimization Meets Bayesian Optimization and Derivative-Free Optimization: A Tale of Modifier Adaptation}}
}
@article{Boukouvala2017b,
abstract = {The algorithmic framework ARGONAUT is presented for the global optimization of general constrained grey-box problems. ARGONAUT incorporates variable selection, bounds tightening and constrained sampling techniques, in order to develop accurate surrogate representations of unknown equations, which are globally optimized. ARGONAUT is tested on a large set of test problems for constrained global optimization with a large number of input variables and constraints. The performance of the presented framework is compared to that of existing techniques for constrained derivative-free optimization.},
author = {Boukouvala, Fani and Floudas, Christodoulos A},
doi = {10.1007/s11590-016-1028-2},
file = {:C\:/Users/dv516/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Boukouvala, Floudas - 2017 - ARGONAUT AlgoRithms for Global Optimization of coNstrAined grey-box compUTational problems.pdf:pdf},
keywords = {Derivative-free optimization,General constraints,Grey-box optimization,Nonlinear programming,Surrogate modeling,Variable selection},
pages = {895--913},
title = {{ARGONAUT: AlgoRithms for Global Optimization of coNstrAined grey-box compUTational problems}},
volume = {11},
year = {2017}
}
@techreport{Kazempour2015,
author = {Kazempour, Jalal},
file = {::},
title = {{Distributed Optimization Lecture 1: Optimization problems with decomposable structure}},
year = {2015}
}
@article{Bangi2020,
abstract = {Process modeling began with the use of first principles resulting in ‘white-box' models which are complex but accurately explain the dynamics of the process. Recently, there has been tremendous interest towards data-based modeling as the resultant ‘black-box' models are simple, and easy to construct, but their accuracy is highly dependent on the nature and amount of training data used. In order to balance the advantages and disadvantages of ‘white-box' and ‘black-box' models, we propose a hybrid model that integrates first principles with a deep neural network, and applied it to hydraulic fracturing process. The unknown process parameters in the hydraulic fracturing process are predicted by the deep neural network and then utilized by the first principles model in order to calculate the hybrid model outputs. This hybrid model is easier to analyze, interpret, and extrapolate compared to a ‘black-box' model, and has higher accuracy compared to the first principles model.},
author = {Bangi, Mohammed Saad Faizan and Kwon, Joseph Sang Il},
doi = {10.1016/j.compchemeng.2019.106696},
file = {::},
issn = {00981354},
journal = {Computers \& Chemical Engineering},
keywords = {Deep learning,First principles,Hybrid modeling,Hydraulic fracturing,Levenberg–Marquardt algorithm},
month = {mar},
pages = {106696},
publisher = {Elsevier Ltd},
title = {{Deep hybrid modeling of chemical process: Application to hydraulic fracturing}},
volume = {134},
year = {2020}
}
@article{Bozarth2009,
abstract = {This paper puts forth a model of supply chain complexity and empirically tests it using plant-level data from 209 plants across seven countries. The results show that upstream complexity, internal manufacturing complexity, and downstream complexity all have a negative impact on manufacturing plant performance. Furthermore, supply chain characteristics that drive dynamic complexity are shown to have a greater impact on performance than those that drive only detail complexity. In addition to providing a definition and empirical test of supply chain complexity, the study serves to link the systems complexity literature to the prescriptions found in the flexibility and lean production literatures. Finally, this research establishes a base from which to extend previous work linking operations strategy to organization design [Flynn, B.B., Flynn, E.J., 1999. Information-processing alternatives for coping with manufacturing environment complexity. Decision Sciences 30 (4), 1021-1052]. {\textcopyright} 2008 Elsevier B.V. All rights reserved.},
author = {Bozarth, Cecil C. and Warsing, Donald P. and Flynn, Barbara B. and Flynn, E. James},
doi = {10.1016/j.jom.2008.07.003},
issn = {02726963},
journal = {Journal of Operations Management},
keywords = {Empirical research methods,Manufacturing strategy,Supply chain complexity,Supply chain management,Supply management},
month = {jan},
number = {1},
pages = {78--93},
publisher = {John Wiley & Sons, Ltd},
title = {{The impact of supply chain complexity on manufacturing plant performance}},
url = {https://onlinelibrary.wiley.com/doi/full/10.1016/j.jom.2008.07.003 https://onlinelibrary.wiley.com/doi/abs/10.1016/j.jom.2008.07.003 https://onlinelibrary.wiley.com/doi/10.1016/j.jom.2008.07.003},
volume = {27},
year = {2009}
}
@article{Ning2019,
abstract = {This paper reviews recent advances in the field of optimization under uncertainty via a modern data lens, highlights key research challenges and promise of data-driven optimization that organically integrates machine learning and mathematical programming for decision-making under uncertainty, and identifies potential research opportunities. A brief review of classical mathematical programming techniques for hedging against uncertainty is first presented, along with their wide spectrum of applications in Process Systems Engineering. A comprehensive review and classification of the relevant publications on data-driven distributionally robust optimization, data-driven chance constrained program, data-driven robust optimization, and data-driven scenario-based optimization is then presented. This paper also identifies fertile avenues for future research that focuses on a closed-loop data-driven optimization framework, which allows the feedback from mathematical programming to machine learning, as well as scenario-based optimization leveraging the power of deep learning techniques. Perspectives on online learning-based data-driven multistage optimization with a learning-while-optimizing scheme are presented.},
author = {Ning, Chao and You, Fengqi},
doi = {10.1016/j.compchemeng.2019.03.034},
issn = {00981354},
journal = {Computers \& Chemical Engineering},
keywords = {Big data,Data-driven optimization,Decision making under uncertainty,Deep learning,Machine learning},
title = {{Optimization under uncertainty in the era of big data and deep learning: When machine learning meets mathematical programming}},
year = {2019}
}
@article{Pattison2016,
abstract = {Today's fast-changing markets often require the granularity of production schedules to be refined to time scales comparable to the time constants of a chemical process. Consequently, the process dynamics must be considered explicitly in production scheduling. High dimensionality, nonlinearity, and the associated computational complexity make incorporating dynamic models in scheduling calculations challenging. We propose a novel scheduling approach based on scheduling-oriented low-order dynamic models identified from historical process operating data. We introduce a methodology for selecting scheduling-relevant variables and identify empirical models that capture their dynamic response to production target changes imposed at the scheduling level. The optimal scheduling calculation is then formulated as a dynamic optimization aimed at minimizing operating cost. We apply these concepts to an industrial-size model of an air separation unit operating under time-sensitive electricity prices. Our approach reduces computational effort considerably while preserving essential information required for the optimal schedule to be feasible from a dynamic point of view. Extensive simulations show that significant savings can be derived from operating in a transient regime, where the production rate is increased when energy prices are low, and reduced during peak price periods, while taking advantage of available storage capacity. ■ INTRODUCTION Fast-changing markets and the emergence of responsive, on-demand manufacturing require that production schedule changes occur over time scales comparable to the time constants of process systems. In turn, this requires that the dynamic characteristics and performance of the process and its control system be accounted for at the production scheduling stage. 1−3 However, embedding dynamics and control information in scheduling calculations has proven to be a difficult task. 3 Production scheduling and process control are typically carried out by separate entities of a company, and the coordination of interactions between the two functions is often challenging. 4 Significant challenges also arise from the need to account for the wide range of time scales involved in making scheduling and control decisions, and the corresponding requirement to balance long-term predictions with real-time execution. 3 Intuitively, optimal scheduling decisions should consider process dynamics in markets where prices (and therefore operating costs and profit margins) change at a high frequency, i.e., over time intervals that are comparable to the dominant time constant of the process. A typical example is the electricity market, where, owing to deregulation, prices change over short time spans (typically hours or even minutes). Participation in a real-time electricity market is often voluntary for industrial sites, who also have the option of entering fixed contracts with their utility suppliers. Variable pricing options become attractive when a site can quickly modulate its production rate by (i) increasing production and storing excess product when energy prices are low and (ii) using stored product to meet customer demand when prices are high and production rates are reduced. Conventional methods for calculating optimal production schedules rely on tabulated transition information between (a set of discrete) operating points, coupled with steady state process models or production recipes. 5 It is implicitly assumed that the process is at a steady state prior to a production target change and that it reaches steady state again before a new change is made. However, in the case where market fluctuations are rapid and occur at a frequency comparable to the (slowest) dynamic},
author = {Pattison, Richard C and Touretzky, Cara R and Johansson, Ted and Harjunkoski, Iiro and Baldea, Michael},
doi = {10.1021/acs.iecr.5b03499},
file = {:C\:/Users/dv516/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Pattison et al. - 2016 - Optimal Process Operations in Fast-Changing Electricity Markets Framework for Scheduling with Low-Order Dynamic.pdf:pdf},
journal = {Ind. Eng. Chem. Res},
pages = {52},
publisher = {UTC},
title = {{Optimal Process Operations in Fast-Changing Electricity Markets: Framework for Scheduling with Low-Order Dynamic Models and an Air Separation Application}},
url = {https://pubs.acs.org/sharingguidelines},
volume = {55},
year = {2016}
}
@article{Chachuat2009,
abstract = {Challenges in real-time process optimization mainly arise from the inability to build and adapt accurate models for complex physico-chemical processes. This paper surveys different ways of using measurements to compensate for model uncertainty in the context of process optimization. Three approaches can be distinguished according to the quantities that are adapted: model-parameter adaptation updates the parameters of the process model and repeats the optimization, modifier adaptation modifies the constraints and gradients of the optimization problem and repeats the optimization, while direct input adaptation turns the optimization problem into a feedback control problem and implements optimality via tracking of appropriate controlled variables. This paper argues in favor of modifier adaptation, since it uses a model parameterization and an update criterion that are well tailored to meeting the KKT conditions of optimality. These considerations are illustrated with the real-time optimization of a semi-batch reactor system. {\textcopyright} 2009 Elsevier Ltd. All rights reserved.},
author = {Chachuat, B. and Srinivasan, B. and Bonvin, D.},
doi = {10.1016/j.compchemeng.2009.04.014},
issn = {00981354},
journal = {Computers \& Chemical Engineering},
keywords = {Batch-to-batch optimization,Measurement-based optimization,Model adaptation,Model parameterization,Plant-model mismatch,Real-time optimization},
month = {oct},
number = {10},
pages = {1557--1567},
publisher = {Pergamon},
title = {{Adaptation strategies for real-time optimization}},
volume = {33},
year = {2009}
}
@article{Kohler2017b,
abstract = {In this work, we propose a sequential distributed MPC algorithm for control of a linear supply chain. The algorithm is developed by closely taking into account supply chain specifics and requirements from practice, e.g., orders and leavings are both treated as decision variables at each stage and communication between stages is kept low. We present the rather surprising result that terminal equality constraints employed in the local MPC formulations are inherently satisfied for the overall system, despite the presence of bilateral dynamic couplings and solving the local MPC problems sequentially. This is due to the stock and flow nature of the problem. The proposed algorithm is shown to be recursively feasible, to asymptotically satisfy a constant customer demand and to achieve asymptotic convergence of the local stock and backlog to the desired levels. This is illustrated by numerical simulations.},
author = {K{\"{o}}hler, Philipp N. and M{\"{u}}ller, Matthias A. and Pannek, J{\"{u}}rgen and Allg{\"{o}}wer, Frank},
doi = {10.1016/J.IFACOL.2017.08.706},
file = {:C\:/Users/dv516/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/K{\"{o}}hler et al. - 2017 - On Exploitation of Supply Chain Properties by Sequential Distributed MPC.pdf:pdf},
issn = {2405-8963},
journal = {IFAC-PapersOnLine},
month = {jul},
number = {1},
pages = {7947--7952},
publisher = {Elsevier},
title = {{On Exploitation of Supply Chain Properties by Sequential Distributed MPC}},
url = {https://www.sciencedirect.com/science/article/pii/S2405896317311473},
volume = {50},
year = {2017}
}
@article{Sargent1967,
abstract = {Although we are in sight of a truly i ntegrated approach to the design of complete processes, a great deal of work remains to be done. With the need for more sophisticated analysis of larger complexes, it is more than ever necessary to join hands with those working in the fields of control engineering, operational research, numerical analysis, and computer science. DESIGN IS A MUCH OVERWORKED word, pressed into service to cover anything from patterns on curtain fabrics to mass and energy balances on chemical processes. In engineering it is too often associated with the work of the drawing office, and in chemical engineering there is a tendency to regard design as the use of crude, rather simple methods to obtain ad hoc solutions to specific problems. As a result, engineering design has usually been considered to be an activity not worthy of higher minds, and it has not received the attention it deserves. In the past, many designers have relied heavily on "engineering judgment," which has often meant that techniques have never been explicitly formulated and objectives never precisely defined. With the advent of computers, the inadequacies of traditional methods have been revealed, and there has been a gradual realization that better techniques and a more systematic approach are necessary if the computer is to be exploited to the full. As computing speed and power steadily mount, it becomes feasible, and indeed necessary , to envisage the complete design of quite complex processes entirely by computer. Furthermore, it is likely that the computer, either online or offline, will play an increasing part in the operation of the process, and it therefore seems opportune to reexamine the entire design process in the light of these new requirements and new possibilities. Critical-path planning had a good effect on the plant contracting industry when it became normal to demand its use as a condition of contract, and if it became customary to request a mathematical model of the process to be handed over at the same time as the commissioned plant, there could be an even greater stimulation to efficient design. Process design may be generally defined as the determination of the fixed parameters for a process such that it will deliver the required quantities of products in accordance with specifications under all foreseeable conditions and such that the overall operation will be optimum in some sense. The fixed parameters are of course the sizes of all plant items and the factors which determine the plant layout. Many parameters are left available for adjustment during plant operation , such as flow rates, tank levels, operating pressures, etc., but here also the design places limits on the range of variation possible. These limits-and the basic desi gn-should be determined by the range of foreseeable conditions, and this in turn involves general predictions of changes in the plant environment over its useful life. The definitions of the optimum and the specifications form a general statement of objectives, desiderata, and absolute constraints. The foreseeable conditions In general, the variable conditions to which the plant will be subject in service receive summary treatment in the design specification. Usually, mean conditions and upper and lower limits are specified for feed streams, steam supplies, etc., and, if they are mentioned at all, only rough qualitative indications of rates of variation are given. The plant contractor often has to look up for himself weather conditions , variability of water temperatures or supplies, etc., and to rely on previous experience with the particular industry to gauge the},
author = {Sargent, R W H},
file = {:C\:/Users/dv516/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Sargent - 1967 - CEP Integrated Design review , and Optimization of Processes.pdf:pdf},
journal = {Chemical Engineering Progress},
number = {9},
pages = {71--78},
title = {{Integrated Design and Optimization of Processes}},
volume = {63},
year = {1967}
}
@article{Krishnamoorthy2019,
abstract = {This paper proposes a primal decomposition algorithm for efficient computation of multistage scenario model predictive control, where the future evolution of uncertainty is represented by a scenario tree. This often results in large-scale optimization problems. Since the different scenarios are only coupled via the so-called non-anticipativity constraints, which ensures that the first control input is the same for all the scenarios, the different scenarios can be decomposed into smaller subproblems, and solved iteratively using a master problem to co-ordinate the subproblems. We review the most common scenario decomposition methods, and argue in favour of primal decomposition algorithms, since it ensures feasibility of the non-anticipativity constraints throughout the iterations, which is crucial for closed-loop implementation. We also propose a novel backtracking algorithm to determine a suitable step length in the master problem that ensures feasibility of the nonlinear constraints. The performance of the proposed approach, and the backtracking algorithm is demonstrated using a CSTR case study.},
author = {Krishnamoorthy, Dinesh and Foss, Bjarne and Skogestad, Sigurd},
doi = {10.1016/j.jprocont.2019.02.003},
file = {::},
issn = {09591524},
journal = {Journal of Process Control},
keywords = {Distributed optimization,Model predictive control,Primal decomposition,Uncertainty},
month = {sep},
pages = {162--171},
publisher = {Elsevier Ltd},
title = {{A Primal decomposition algorithm for distributed multistage scenario model predictive control}},
volume = {81},
year = {2019}
}
@techreport{Boyd2003,
author = {Boyd, Stephen and Xiao, Lin and Mutapcic, Almir},
file = {::},
title = {{Notes on Decomposition Methods}},
year = {2003}
}
@article{Grossmann2019,
abstract = {In this paper, we present both academic and industrial perspectives on the research and applications of Process Systems Engineering (PSE). After a brief introduction on the history of PSE, we describe the major research accomplishments in the areas of process simulation, conceptual design and synthesis, process control, process operations and optimization. This is followed by a discussion on the industrial impact and benefits of this work, which have made it to be industrially relevant. Next, we address the issue of the current standing of PSE both in academia and in industry, and for which we present results of a survey conducted by the authors. Finally, we close with a discussion on future challenges in PSE from both the industrial and academic perspectives.},
author = {Grossmann, Ignacio E. and Harjunkoski, Iiro},
doi = {10.1016/j.compchemeng.2019.04.028},
issn = {00981354},
journal = {Computers \& Chemical Engineering},
keywords = {Mathematical programming,Process control,Process simulation,Process synthesis,Process systems engineering,Scheduling and planning},
month = {jul},
pages = {474--484},
publisher = {Elsevier Ltd},
title = {{Process systems Engineering: Academic and industrial perspectives}},
volume = {126},
year = {2019}
}
@article{Biegler2017a,
author = {Biegler, Lorenz T.},
doi = {10.1002/aic.15674},
issn = {00011541},
journal = {AIChE Journal},
keywords = {complementarity conditions,model reduction,multilevel optimization,nonlinear programming,process optimization},
month = {apr},
number = {4},
pages = {1178--1193},
publisher = {John Wiley and Sons Inc.},
title = {{New nonlinear programming paradigms for the future of process optimization}},
url = {http://doi.wiley.com/10.1002/aic.15674},
volume = {63},
year = {2017}
}
@article{Schweidtmann2018,
abstract = {Automated development of chemical processes requires access to sophisticated algorithms for multi-objective optimization, since single-objective optimization fails to identify the trade-offs between conflicting performance criteria. Herein we report the implementation of a new multi-objective machine learning optimization algorithm for self-optimization, and demonstrate it in two exemplar chemical reactions performed in continuous flow. The algorithm successfully identified a set of optimal conditions corresponding to the trade-off curve (Pareto front) between environmental and economic objectives in both cases. Thus, it reveals the complete underlying trade-off and is not limited to one compromise as is the case in many other studies. The machine learning algorithm proved to be extremely data efficient, identifying the optimal conditions for the objectives in a lower number of experiments compared to single-objective optimizations. The complete underlying trade-off between multiple objectives is identified without arbitrary weighting factors, but via true multi-objective optimization.},
author = {Schweidtmann, Artur M. and Clayton, Adam D. and Holmes, Nicholas and Bradford, Eric and Bourne, Richard A. and Lapkin, Alexei A.},
doi = {10.1016/j.cej.2018.07.031},
file = {::},
issn = {13858947},
journal = {Chemical Engineering Journal},
keywords = {Automated flow reactor,Environmental chemistry,Machine learning,Reaction engineering,Sustainable chemistry},
month = {nov},
pages = {277--282},
publisher = {Elsevier B.V.},
title = {{Machine learning meets continuous flow chemistry: Automated optimization towards the Pareto front of multiple objectives}},
volume = {352},
year = {2018}
}
@article{Houska2016,
abstract = {This paper is about distributed derivative-based algorithms for solving optimization problems with a separable (potentially nonconvex) objective function and coupled affine constraints. A parallelizable method is proposed that combines ideas from the fields of sequential quadratic programming and augmented Lagrangian algorithms. The method negotiates shared dual variables that may be interpreted as prices, a concept employed in dual decomposition methods and the alternating direction method of multipliers (ADMM). Here, each agent solves its own small-scale nonlinear programming problem and communicates with other agents by solving coupled quadratic programming problems. These coupled quadratic programming problems have equality constraints for which parallelizable methods are available. The use of techniques associated with standard sequential quadratic programming methods gives a method with superlinear or quadratic convergence rate under suitable conditions. This is in contrast to existing decomposition methods, such as ADMM, which have a linear convergence rate. It is shown how the proposed algorithm may be extended using globalization techniques that guarantee convergence to a local minimizer from any initial starting point.},
author = {Houska, Boris and Frasch, Janick and Diehl, Moritz},
doi = {10.1137/140975991},
issn = {10526234},
journal = {SIAM Journal on Optimization},
keywords = {Distributed algorithms,Large-scale problems,Nonconvex optimization},
title = {{An augmented Lagrangian based algorithm for distributed nonconvex optimization}},
year = {2016}
}
@article{Newton2013,
abstract = {This paper examines the early phases of a 21st century energy transition that involves distributed generation technologies employing low or zero carbon emission power sources and their take-up within Australia, with particular reference to the major cities and solar photovoltaics (PV). This transition is occurring in a nation with significant path dependency to overcome in relation to fossil fuel use. Tracking the diffusion of solar PV technology within Australia over the past decade provides a basis for assessing those factors underpinning its exponential growth and its associated geography of diffusion. Positive evidence that there are pathways for cities to decarbonise is apparent but there appear to be different pathways for different city forms with lower density suburban areas showing the biggest take-up of household-based energy technologies. This suggests a model for the low carbon urban transition involving combinations of simple technological changes and harder structural changes, depending upon which parts of the urban fabric are in focus. This is being called a New Low Carbon Urban Transition Theory. {\textcopyright}2013 by the authors.},
author = {Newton, Peter and Newman, Peter},
doi = {10.3390/su5062537},
file = {::},
issn = {20711050},
journal = {Sustainability (Switzerland)},
keywords = {Decarbonising cities,Distributed energy generation,Green technology for suburbs,Renewable energy,Solar photovoltaics,Urban energy transitions},
number = {6},
pages = {2537--2556},
publisher = {MDPI AG},
title = {{The geography of solar photovoltaics (pv) and a new low carbon urban transition theory}},
volume = {5},
year = {2013}
}
@article{Christofides2013b,
abstract = {In this paper, we provide a tutorial review of recent results in the design of distributed model predictive control systems. Our goal is to not only conceptually review the results in this area but also to provide enough algorithmic details so that the advantages and disadvantages of the various approaches can become quite clear. In this sense, our hope is that this paper would complement a series of recent review papers and catalyze future research in this rapidly evolving area. We conclude discussing our viewpoint on future research directions in this area.},
author = {Christofides, Panagiotis D. and Scattolini, Riccardo and {Mu{\~{n}}oz de la Pe{\~{n}}a}, David and Liu, Jinfeng},
doi = {10.1016/J.COMPCHEMENG.2012.05.011},
file = {:C\:/Users/dv516/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Christofides et al. - 2013 - Distributed model predictive control A tutorial review and future research directions(2).pdf:pdf},
issn = {0098-1354},
journal = {Computers \& Chemical Engineering},
month = {apr},
pages = {21--41},
publisher = {Pergamon},
title = {{Distributed model predictive control: A tutorial review and future research directions}},
url = {https://www.sciencedirect.com/science/article/pii/S0098135412001573},
volume = {51},
year = {2013}
}
@article{Bertsekas1979,
abstract = {In order for primal-dual methods to be applicable to a constrained minimization problem, it is necessary that restrictive convexity conditions are satisfied. In this paper, we consider a procedure by means of which a nonconvex problem is convexified and transformed into one which can be solved with the aid of primal-dual methods. Under this transformation, separability of the type necessary for application of decomposition algorithms is preserved. This feature extends the range of applicability of such algorithms to nonconvex problems. Relations with multiplier methods are explored with the aid of a local version of the notion of a conjugate convex function.},
author = {Bertsekas, D. P.},
doi = {10.1007/BF00937167},
file = {:C\:/Users/dv516/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Bertsekas - 1979 - Convexification procedures and decomposition methods for nonconvex optimization problems.pdf:pdf},
issn = {0022-3239},
journal = {Journal of Optimization Theory and Applications},
keywords = {Applications of Mathematics,Calculus of Variations and Optimal Control,Engineering,Operations Research/Decision Theory,Optimization,Theory of Computation,general},
month = {oct},
number = {2},
pages = {169--197},
publisher = {Springer},
title = {{Convexification procedures and decomposition methods for nonconvex optimization problems}},
url = {http://link.springer.com/10.1007/BF00937167},
volume = {29},
year = {1979}
}
@article{Heo2016,
abstract = {A systematic method is proposed for control-relevant decomposition of complex process networks. Specifically, hierarchical clustering methods are adopted to identify constituent subnetworks such that the components of each subnetwork are strongly interacting while different subnetworks are loosely coupled. Optimal clustering is determined through the solution of integer optimization problems. The concept of relative degree is used to measure distance between subnetworks and compactness of subnetworks. The application of the proposed method is illustrated using an example process network. {\textcopyright} 2016 American Institute of Chemical Engineers AIChE J, 62: 3177–3188, 2016.},
author = {Heo, Seongmin and Daoutidis, Prodromos},
doi = {10.1002/aic.15323},
issn = {15475905},
journal = {AIChE Journal},
keywords = {community detection,control,hierarchical clustering,networks,optimization,process control},
month = {sep},
number = {9},
pages = {3177--3188},
publisher = {John Wiley and Sons Inc},
title = {{Control-relevant decomposition of process networks via optimization-based hierarchical clustering}},
url = {https://aiche.onlinelibrary.wiley.com/doi/full/10.1002/aic.15323 https://aiche.onlinelibrary.wiley.com/doi/abs/10.1002/aic.15323 https://aiche.onlinelibrary.wiley.com/doi/10.1002/aic.15323},
volume = {62},
year = {2016}
}
@article{Guignard1987,
abstract = {Given a mixed-integer programming problem with two matrix constraints, it is possible to define a Lagrangean relaxation such that the relaxed problem decomposes additively into two subproblems, each having one of the two matrices of the original problem as its constraints. There is one Lagrangean multiplier per variable. We prove that the optimal value of this new Lagrangean dual dominates the optimal value of the Lagrangean dual obtained by relaxing one set of constraints and give a necessary condition for a strict improvement. We show on an example that the resulting bound improvement can be substantial. We show on a complex practical problem how Lagrangean decomposition may help uncover hidden special structures and thus yield better solution methodology. {\textcopyright} 1987 The Mathematical Programming Society, Inc.},
author = {Guignard, Monique and Kim, Siwhan},
doi = {10.1007/BF02592954},
file = {::},
issn = {00255610},
journal = {Mathematical Programming},
keywords = {Integrality Property,Lagrangean decomposition,Lagrangean relaxation,Mixed-integer programming,Y-convexity,block-angularization,bound improvement},
month = {jun},
number = {2},
pages = {215--228},
publisher = {Springer-Verlag},
title = {{Lagrangean decomposition: A model yielding stronger lagrangean bounds}},
volume = {39},
year = {1987}
}
@article{Camara2016,
abstract = {The proper design of RTO systems' structure and critical diagnosis tools is neglected in commercial RTO software and poorly discussed in the literature. In a previous article, Quelhas et al. (Can J Chem Eng., 2013, 91, 652-668) have reviewed the concepts behind the two-step RTO approach and discussed the vulnerabilities of intuitive, experience-based RTO design choices. This work evaluates and analyzes the performance of industrial RTO implementations in the face of real settings regarding the choice of steady-state detection methods and parameters, the choice of adjustable model parameters and selected variables in the model adaptation problem, the convergence determination of optimization techniques, among other aspects, in the presence of real noisy data. Results clearly show the importance of a robust and careful consideration of all aspects of a two-step RTO structure, as well as of the performance evaluation, in order to have a real and undoubted improvement of process operation.},
author = {C{\^{a}}mara, Maur{\'{i}}cio M. and Quelhas, Andr{\'{e}} D. and Pinto, Jos{\'{e}} Carlos},
doi = {10.3390/pr4040044},
file = {::},
issn = {22279717},
journal = {Processes},
keywords = {Industrial RTO systems,Numerical methods,On-line optimization,Optimizing control,Repeated identification and optimization,Static real-time optimization (RTO)},
month = {dec},
number = {4},
pages = {44},
publisher = {MDPI AG},
title = {{Performance evaluation of real industrial RTO systems}},
url = {www.mdpi.com/journal/processes},
volume = {4},
year = {2016}
}
@article{Tosserams2010,
abstract = {This paper presents an empirical study of the convergence characteristics of augmented Lagrangian coordination (ALC) for solving multi-modal optimization problems in a distributed fashion. A number of test problems that do not satisfy all assumptions of the convergence proof for ALC are selected to demonstrate the convergence characteristics of ALC algorithms. When only a local search is employed at the subproblems, local solutions to the original problem are often attained. When a global search is performed at subproblems, global solutions to the original, non-decomposed problem are found for many of the examples. Although these findings are promising, ALC with a global subproblem search may yield only local solutions in the case of non-convex coupling functions or disconnected feasible domains. Results indicate that for these examples both the starting point and the sequence in which subproblems are solved determines which solution is obtained. We illustrate that the main cause for this behavior lies in the alternating minimization inner loop, which is inherently of a local nature.},
author = {Tosserams, S. and Etman, L. F.P. and Rooda, J. E.},
doi = {10.1007/s00158-009-0371-7},
file = {::},
issn = {1615147X},
journal = {Structural and Multidisciplinary Optimization},
keywords = {Augmented Lagrangian coordination,Decomposition,Global optimization,Multi-modal,Multidisciplinary design optimization,Non-convex,Test problems},
month = {jan},
number = {1-6},
pages = {329--352},
publisher = {Springer},
title = {{Multi-modality in augmented Lagrangian coordination for distributed optimal design}},
url = {https://link.springer.com/article/10.1007/s00158-009-0371-7},
volume = {40},
year = {2010}
}
@article{Schweidtmann2019,
abstract = {Global deterministic process optimization problems have recently been solved efficiently in a reduced-space by automatic propagation of McCormick relaxations (Bongartz and Mitsos, J. Global Optim, 2017). However, the previous optimizations have been limited to simplified thermodynamic property models. Herein, we propose a method that learns accurate thermodynamic properties via artificial neural networks (ANNs) and integrates those in deterministic global process optimization. The resulting hybrid process model is solved using the recently developed method for deterministic global optimization problems with ANNs embedded (Schweidtmann and Mitsos, J. Optim. Theory Appl., 2018). The optimal operation of a validated steady state model of an organic Rankine cycle is solved as a case study. It is especially challenging as the thermodynamic properties are given by the implicit Helmholtz equation of state. The results show that modeling of thermodynamic properties via ANNs performs favorable in deterministic optimization. This method can rapidly be extended to include properties from existing thermodynamic libraries, based on models or data.},
author = {Schweidtmann, Artur M. and Huster, Wolfgang R. and L{\"{u}}thje, Jannik T. and Mitsos, Alexander},
doi = {10.1016/j.compchemeng.2018.10.007},
file = {::},
issn = {00981354},
journal = {Computers \& Chemical Engineering},
keywords = {MAiNGO,McCormick relaxations,Organic Rankine cycle,Reduced-space formulation,Surrogate-based global optimization,Thermodynamic properties},
month = {feb},
pages = {67--74},
publisher = {Elsevier Ltd},
title = {{Deterministic global process optimization: Accurate (single-species) properties via artificial neural networks}},
volume = {121},
year = {2019}
}
@article{Moharir2018,
abstract = {This paper addresses the plant-wide control of the amine gas sweetening plant using distributed model predictive control. The plant is fed natural gas containing sour gases (hydrogen sulfide and carbon dioxide), which are removed by absorption in monoethanolamine solution. A plant decomposition algorithm based on modularity maximization for distributed parameter systems is used to obtain the optimal decomposition for distributed model predictive control. Comparisons are drawn among the performance and computational requirements of distributed, decentralized, and centralized model predictive controls.},
author = {Moharir, Manjiri and Pourkargar, Davood B. and Almansoori, Ali and Daoutidis, Prodromos},
doi = {10.1021/acs.iecr.8b01291},
issn = {15205045},
journal = {Industrial and Engineering Chemistry Research},
month = {oct},
number = {39},
pages = {13103--13115},
publisher = {American Chemical Society},
title = {{Distributed Model Predictive Control of an Amine Gas Sweetening Plant}},
url = {https://pubs.acs.org/doi/abs/10.1021/acs.iecr.8b01291},
volume = {57},
year = {2018}
}
@misc{Floudas2004,
abstract = {An overview of developments in the scheduling of multiproduct/multipurpose batch and continuous processes is presented. Existing approaches are classified based on the time representation and important characteristics of chemical processes that pose challenges to the scheduling problem are discussed. In contrast to the discrete-time approaches, various continuous-time models have been proposed in the literature and their strengths and limitations are examined. Computational studies and applications are presented. The important issues of incorporating scheduling at the design stage and scheduling under uncertainty are also reviewed. {\textcopyright} 2004 Elsevier Ltd. All rights reserved.},
author = {Floudas, Christodoulos A. and Lin, Xiaoxia},
booktitle = {Computers \& Chemical Engineering},
doi = {10.1016/j.compchemeng.2004.05.002},
file = {::},
issn = {00981354},
keywords = {Continuous-time model,Design and scheduling,Discrete-time model,Mixed-integer linear programming (MILP),Mixed-integer nonlinear programming (MINLP),Multiproduct plants,Multipurpose plants,Process scheduling,Reactive scheduling,Uncertainty},
month = {oct},
number = {11},
pages = {2109--2129},
publisher = {Pergamon},
title = {{Continuous-time versus discrete-time approaches for scheduling of chemical processes: A review}},
volume = {28},
year = {2004}
}

@article{Rodriguez2018,
abstract = {We study connections between the alternating direction method of multipliers (ADMM), the classical method of multipliers (MM), and progressive hedging (PH). The connections are used to derive benchmark metrics and strategies to monitor and accelerate convergence and to help explain why ADMM and PH are capable of solving complex nonconvex NLPs. Specifically, we observe that ADMM is an inexact version of MM and approaches its performance when multiple coordination steps are performed. In addition, we use the observation that PH is a specialization of ADMM and borrow Lyapunov function and primal-dual feasibility metrics used in ADMM to explain why PH is capable of solving nonconvex NLPs. This analysis also highlights that specialized PH schemes can be derived to tackle a wider range of stochastic programs and even other problem classes. Our exposition is tutorial in nature and seeks to to motivate algorithmic improvements and new decomposition strategies},
author = {Rodriguez, Jose S. and Nicholson, Bethany and Laird, Carl and Zavala, Victor M.},
doi = {10.1016/J.COMPCHEMENG.2018.08.036},
issn = {0098-1354},
journal = {Computers \& Chemical Engineering},
keywords = {ADMM,Augmented Lagrangian,Coordination,Decomposition,Large-scale,NLP},
month = {nov},
pages = {315--325},
publisher = {Pergamon},
title = {{Benchmarking ADMM in nonconvex NLPs}},
volume = {119},
year = {2018}
}
@article{Terrazas-Moreno2011,
abstract = {We address in this paper the optimization of a multi-site, multi-period, and multi-product planning problem with sequence-dependent changeovers, which is modeled as a mixed-integer linear programming (MILP) problem. Industrial instances of this problem require the planning of a number of production and distribution sites over a time span of several months. Temporal and spatial Lagrangean decomposition schemes can be useful for solving these types of large-scale production planning problems. In this paper we present a theoretical result on the relative size of the duality gap of the two decomposition alternatives. We also propose a methodology for exploiting the economic interpretation of the Lagrange multipliers to speed the convergence of numerical algorithms for solving the temporal and spatial Lagrangean duals. The proposed methods are applied to the multi-site multi-period planning problem in order to illustrate their computational effectiveness. {\textcopyright} 2011 Elsevier Ltd.},
author = {Terrazas-Moreno, Sebastian and Trotter, Philipp A. and Grossmann, Ignacio E.},
doi = {10.1016/j.compchemeng.2011.01.004},
file = {::},
issn = {00981354},
journal = {Computers \& Chemical Engineering},
keywords = {Lagrangean decomposition,Production planning,Spatial decomposition,Temporal decomposition},
month = {dec},
number = {12},
pages = {2913--2928},
publisher = {Pergamon},
title = {{Temporal and spatial Lagrangean decompositions in multi-site, multi-period production planning problems with sequence-dependent changeovers}},
volume = {35},
year = {2011}
}
@techreport{Powell2009,
abstract = {BOBYQA is an iterative algorithm for finding a minimum of a function F (x), x ∈ R n , subject to bounds a ≤ x ≤ b on the variables, F being specified by a "black box" that returns the value F (x) for any feasible x. Each iteration employs a quadratic approximation Q to F that satisfies Q(y j) = F (y j), j = 1, 2,. .. , m, the interpolation points y j being chosen and adjusted automatically, but m is a prescribed constant, the value m = 2n+1 being typical. These conditions leave much freedom in Q, taken up when the model is updated by the highly successful technique of minimizing the Frobenius norm of the change to the second derivative matrix of Q. Thus no first derivatives of F are required explicitly. Most changes to the variables are an approximate solution to a trust region subproblem, using the current quadratic model, with a lower bound on the trust region radius that is reduced cautiously, in order to keep the interpolation points well separated until late in the calculation, which lessens damage from computer rounding errors. Some other changes to the variables are designed to improve the model without reducing F. These techniques are described. Other topics include the starting procedure that is given an initial vector of variables, the value of m and the initial trust region radius. There is also a new device called RESCUE that tries to restore normality if severe loss of accuracy occurs in the matrix calculations of the updating of the model. Numerical results are reported and discussed for two test problems, the numbers of variables being between 10 and 320.},
author = {Powell, M J D},
file = {::},
title = {{The BOBYQA algorithm for bound constrained optimization without derivatives}},
year = {2009}
}
@techreport{Thebelt2021a,
abstract = {Gradient boosted trees and other regression tree models perform well in a wide range of real-world, industrial applications. These tree models (i) offer insight into important prediction features, (ii) effectively manage sparse data, and (iii) have excellent prediction capabilities. Despite their advantages, they are generally unpopular for decision-making tasks and black-box optimization, which is due to their difficult-to-optimize structure and the lack of a reliable uncertainty measure. ENTMOOT is our new framework for integrating (already trained) tree models into larger optimization problems. The contributions of ENTMOOT include: (i) explicitly introducing a reliable uncertainty measure that is compatible with tree models, (ii) solving the larger optimization problems that incorporate these uncertainty aware tree models, (iii) proving that the solutions are globally optimal, i.e. no better solution exists. In particular, we show how the ENTMOOT approach allows a simple integration of tree models into decision-making and black-box optimization, where it proves as a strong competitor to commonly-used frameworks.},
archivePrefix = {arXiv},
arxivId = {2003.04774v2},
author = {Thebelt, Alexander and Kronqvist, Jan and Mistry, Miten and Lee, Robert M and Sudermann-Merx, Nathan and Misener, Ruth},
eprint = {2003.04774v2},
file = {::},
keywords = {Corresponding author},
title = {{ENTMOOT: A FRAMEWORK FOR OPTIMIZATION OVER ENSEMBLE TREE MODELS A PREPRINT}},
year = {2021}
}
@article{Blasi2018a,
abstract = {To achieve a common goal in an optimal way systems are becoming increasingly interconnected. While operating as autonomous as possible, the subsystems should exploit the capabilities and desires of neighboring systems in a cooperative way to avoid conflicts and optimize overall performance. Increasing interconnections, together with autonomous behavior, however, challenge the system design and control. Distributed model predictive control strategies allow to break the complexity of interconnected systems, as each subsystem employs its own controller, taking information obtained or provided by the neighboring systems into account. We propose a distributed model predictive control strategy, in which the subsystems provide multiple options of possible future behaviors to their neighbors. The options are provided in form of contracts - outer bounds of the variables of the coupling variables. The neighboring systems take these options in their predictions into account and choose the most suitable one. By this they exploit the capabilities and influences of the neighbors in a cooperative way. We outline conditions which guarantee repeated feasibility and illustrate the approach considering autonomously driving vehicles entering a highway.},
author = {Blasi, Svenja and K{\"{o}}gel, Markus},
doi = {10.1016/J.IFACOL.2018.11.048},
file = {:C\:/Users/dv516/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Blasi, K{\"{o}}gel - 2018 - Distributed Model Predictive Control Using Cooperative Contract Options.pdf:pdf},
issn = {2405-8963},
journal = {IFAC-PapersOnLine},
month = {jan},
number = {20},
pages = {448--454},
publisher = {Elsevier},
title = {{Distributed Model Predictive Control Using Cooperative Contract Options}},
url = {https://www.sciencedirect.com/science/article/pii/S240589631832706X#!},
volume = {51},
year = {2018}
}
@article{Velarde2018,
abstract = {In this paper, we present an analysis of the vulnerability of a distributed model predictive control scheme. A distributed system can be easily attacked by a malicious agent that modifies the reliable information exchange. We consider different types of so-called insider attacks. In particular, we analyze a controller that is part of the control architecture that sends false information to others to manipulate costs for its own advantage. We propose a mechanism to protect or, at least, relieve the consequences of the attack in a typical distributed model predictive control negotiation procedure. More specifically, a consensus approach that dismisses the extreme control actions is presented as a way to protect the distributed system from potential threats. Two applications are considered as case studies, ie, an academic example involving the control of a distributed system with a single coupled input and a distributed local electricity grid of households. The results are presented via simulations to illustrate both the consequences of the attacks and the defense mechanisms.},
author = {Velarde, Pablo and Maestre, Jos{\'{e}} M. and Ishii, Hideaki and Negenborn, Rudy R.},
doi = {10.1002/oca.2368},
issn = {10991514},
journal = {Optimal Control Applications and Methods},
keywords = {optimal control applications,predictive control,robust control},
title = {{Vulnerabilities in Lagrange-based distributed model predictive control}},
year = {2018}
}
@article{Shin2019b,
abstract = {This paper provides an introduction to Reinforcement Learning (RL) technology, summarizes recent developments in this area, and discusses their potential implications for the field of process control, and more generally, of operational decision-making. The paper begins with an introduction to RL that allows an agent to learn, through trial and error, the best way to accomplish a task. We then highlight new developments in RL that have led to the recent wave of applications and media interest. A comparison of the key features of RL and mathematical programming based methods (e.g., model predictive control) is then presented to clarify their similarities and differences. This is followed by an assessment of several ways that RL technology can potentially be used in process control and operational decision applications. A final section summarizes our conclusions and lists directions for future RL research that may improve its relevance for the process systems engineering field.},
author = {Shin, Joohyun and Badgwell, Thomas A. and Liu, Kuang-Hung and Lee, Jay H.},
doi = {10.1016/J.COMPCHEMENG.2019.05.029},
issn = {0098-1354},
journal = {Computers \& Chemical Engineering},
month = {aug},
pages = {282--294},
publisher = {Pergamon},
title = {{Reinforcement Learning – Overview of recent progress and implications for process control}},
url = {https://www.sciencedirect.com/science/article/pii/S0098135419300754},
volume = {127},
year = {2019}
}
@article{Beaumont1980,
abstract = {(1980). Connectivity, Complexity, and Catastrophe in Large-Scale Systems. Journal of the Operational Research Society: Vol. 31, No. 9, pp. 863-864.},
author = {Beaumont, John R.},
doi = {10.1057/jors.1980.158},
issn = {0160-5682},
journal = {Journal of the Operational Research Society},
month = {sep},
number = {9},
pages = {863--864},
publisher = {Informa UK Limited},
title = {{Connectivity, Complexity, and Catastrophe in Large-Scale Systems}},
url = {https://www.tandfonline.com/doi/abs/10.1057/jors.1980.158},
volume = {31},
year = {1980}
}
@article{Tatara2007,
abstract = {Control of spatially distributed systems is a challenging problem because of their complex nature, nonlinearity, and generally high order. The lack of accurate and computationally efficient model-based techniques for large, spatially distributed systems leads to challenges in controlling the system. Agent-based control structures provide a powerful tool to manage distributed systems by utilizing (organizing) local and global information obtained from the system. A hierarchical, agent-based system with local and global controller agents is developed to control networks of interconnected chemical reactors (CSTRs). The global controller agent dynamically updates local controller agent's objectives as the reactor network conditions change. One challenge posed is control of the spatial distribution of autocatalytic species in a network of reactors hosting multiple species. The multi-agent control system is able to intelligently manipulate the network flow rates such that the desired spatial distribution of species is achieved. Furthermore, the robustness and flexibility of the agent-based control system is illustrated through examples of disturbance rejection and scalability with respect to the size of the network.},
author = {Tatara, Eric and {\c{C}}ınar, Ali and Teymour, Fouad},
doi = {10.1016/J.JPROCONT.2006.06.008},
file = {:C\:/Users/dv516/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Tatara, {\c{C}}ınar, Teymour - 2007 - Control of complex distributed systems with distributed intelligent agents(2).pdf:pdf},
issn = {0959-1524},
journal = {Journal of Process Control},
month = {jun},
number = {5},
pages = {415--427},
publisher = {Elsevier},
title = {{Control of complex distributed systems with distributed intelligent agents}},
url = {https://www.sciencedirect.com/science/article/pii/S0959152406000771},
volume = {17},
year = {2007}
}
@book{Boyd2004,
abstract = {We are developing a dual panel breast-dedicated PET system using LSO scintillators coupled to position sensitive avalanche photodiodes (PSAPD). The charge output is amplified and read using NOVA RENA-3 ASICs. This paper shows that the coincidence timing resolution of the RENA-3 ASIC can be improved using certain list-mode calibrations. We treat the calibration problem as a convex optimization problem and use the RENA-3s analog-based timing system to correct the measured data for time dispersion effects from correlated noise, PSAPD signal delays and varying signal amplitudes. The direct solution to the optimization problem involves a matrix inversion that grows order (n3) with the number of parameters. An iterative method using single-coordinate descent to approximate the inversion grows order (n). The inversion does not need to run to convergence, since any gains at high iteration number will be low compared to noise amplification. The system calibration method is demonstrated with measured pulser data as well as with two LSO-PSAPD detectors in electronic coincidence. After applying the algorithm, the 511keV photopeak paired coincidence time resolution from the LSO-PSAPD detectors under study improved by 57%, from the raw value of 16.30.07 ns FWHM to 6.920.02 ns FWHM (11.520.05 ns to 4.890.02 ns for unpaired photons).},
author = {Boyd, Stephen and Vandenberghe, Lieven},
booktitle = {Convex Optimization},
doi = {10.1017/cbo9780511804441},
month = {mar},
publisher = {Cambridge University Press},
title = {{Convex Optimization}},
url = {https://www.cambridge.org/core/books/convex-optimization/17D2FAA54F641A2F62C7CCD01DFA97C4},
year = {2004}
}
@article{VandeBerg2021,
abstract = {Rapid-response vaccine production platform technologies, including RNA vaccines, are being developed to combat viral epidemics and pandemics. A key enabler of rapid response is having quality-oriented disease-agnostic manufacturing protocols ready ahead of outbreaks. We are the first to apply the Quality by Design (QbD) framework to enhance rapid-response RNA vaccine manufacturing against known and future viral pathogens. This QbD framework aims to support the development and consistent production of safe and efficacious RNA vaccines, integrating a novel qualitative methodology and a quantitative bioprocess model. The qualitative methodology identifies and assesses the direction, magnitude and shape of the impact of critical process parameters (CPPs) on critical quality attributes (CQAs). The mechanistic bioprocess model quantifies and maps the effect of four CPPs on the CQA of effective yield of RNA drug substance. Consequently, the first design space of an RNA vaccine synthesis bioreactor is obtained. The cost-yield optimization together with the probabilistic design space contribute towards automation of rapid-response, high-quality RNA vaccine production.},
author = {van de Berg, Damien and Kis, Zolt{\'{a}}n and Behmer, Carl Fredrik and Samnuan, Karnyart and Blakney, Anna K. and Kontoravdi, Cleo and Shattock, Robin and Shah, Nilay},
doi = {10.1038/s41541-021-00322-7},
file = {::},
issn = {20590105},
journal = {npj Vaccines},
keywords = {Drug development,RNA vaccines},
month = {dec},
number = {1},
pages = {1--10},
pmid = {33927197},
publisher = {Nature Research},
title = {{Quality by design modelling to support rapid RNA vaccine production against emerging infectious diseases}},
url = {https://doi.org/10.1038/s41541-021-00322-7},
volume = {6},
year = {2021}
}
@article{Petsagkourakis2020,
abstract = {Chemical process optimization and control are affected by 1) plant-model mismatch, 2) process disturbances, and 3) constraints for safe operation. Reinforcement learning by policy optimization would be a natural way to solve this due to its ability to address stochasticity, plant-model mismatch, and directly account for the effect of future uncertainty and its feedback in a proper closed-loop manner; all without the need of an inner optimization loop. One of the main reasons why reinforcement learning has not been considered for industrial processes (or almost any engineering application) is that it lacks a framework to deal with safety critical constraints. Present algorithms for policy optimization use difficult-to-tune penalty parameters, fail to reliably satisfy state constraints or present guarantees only in expectation. We propose a chance constrained policy optimization (CCPO) algorithm which guarantees the satisfaction of joint chance constraints with a high probability - which is crucial for safety critical tasks. This is achieved by the introduction of constraint tightening (backoffs), which are computed simultaneously with the feedback policy. Backoffs are adjusted with Bayesian optimization using the empirical cumulative distribution function of the probabilistic constraints, and are therefore self-tuned. This results in a general methodology that can be imbued into present policy optimization algorithms to enable them to satisfy joint chance constraints with high probability. We present case studies that analyze the performance of the proposed approach.},
archivePrefix = {arXiv},
arxivId = {2008.00030},
author = {Petsagkourakis, Panagiotis and Sandoval, Ilya Orson and Bradford, Eric and Galvanin, Federico and Zhang, Dongda and del Rio-Chanona, Ehecatl Antonio},
eprint = {2008.00030},
file = {:C\:/Users/dv516/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Petsagkourakis et al. - 2020 - Chance Constrained Policy Optimization for Process Control and Optimization.pdf:pdf},
journal = {arXiv},
keywords = {Batch optimization,Bioprocesses,Data-Driven Optimization,Machine Learning,Policy Gradient,Process Control,Uncertain dynamic systems},
month = {jul},
publisher = {arXiv},
title = {{Chance Constrained Policy Optimization for Process Control and Optimization}},
url = {http://arxiv.org/abs/2008.00030},
year = {2020}
}
@article{Hubbs2020,
abstract = {This work examines applying deep reinforcement learning to a chemical production scheduling process to account for uncertainty and achieve online, dynamic scheduling, and benchmarks the results with a mixed-integer linear programming (MILP) model that schedules each time interval on a receding horizon basis. An industrial example is used as a case study for comparing the differing approaches. Results show that the reinforcement learning method outperforms the naive MILP approaches and is competitive with a shrinking horizon MILP approach in terms of profitability, inventory levels, and customer service. The speed and flexibility of the reinforcement learning system is promising for achieving real-time optimization of a scheduling system, but there is reason to pursue integration of data-driven deep reinforcement learning methods and model-based mathematical optimization approaches.},
author = {Hubbs, Christian D. and Li, Can and Sahinidis, Nikolaos V. and Grossmann, Ignacio E. and Wassick, John M.},
doi = {10.1016/J.COMPCHEMENG.2020.106982},
file = {:C\:/Users/dv516/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Hubbs et al. - 2020 - A deep reinforcement learning approach for chemical production scheduling.pdf:pdf},
issn = {0098-1354},
journal = {Computers \& Chemical Engineering},
month = {oct},
pages = {106982},
publisher = {Pergamon},
title = {{A deep reinforcement learning approach for chemical production scheduling}},
url = {https://www.sciencedirect.com/science/article/pii/S0098135420301599#!},
volume = {141},
year = {2020}
}
@article{Busoniu2018a,
abstract = {Reinforcement learning (RL) offers powerful algorithms to search for optimal controllers of systems with nonlinear, possibly stochastic dynamics that are unknown or highly uncertain. This review mainly covers artificial-intelligence approaches to RL, from the viewpoint of the control engineer. We explain how approximate representations of the solution make RL feasible for problems with continuous states and control actions. Stability is a central concern in control, and we argue that while the control-theoretic RL subfield called adaptive dynamic programming is dedicated to it, stability of RL largely remains an open question. We also cover in detail the case where deep neural networks are used for approximation, leading to the field of deep RL, which has shown great success in recent years. With the control practitioner in mind, we outline opportunities and pitfalls of deep RL; and we close the survey with an outlook that – among other things – points out some avenues for bridging the gap between control and artificial-intelligence RL techniques.},
author = {Buşoniu, Lucian and de Bruin, Tim and Toli{\'{c}}, Domagoj and Kober, Jens and Palunko, Ivana},
doi = {10.1016/J.ARCONTROL.2018.09.005},
issn = {1367-5788},
journal = {Annual Reviews in Control},
month = {jan},
pages = {8--28},
publisher = {Pergamon},
title = {{Reinforcement learning for control: Performance, stability, and deep approximators}},
url = {https://www.sciencedirect.com/science/article/abs/pii/S1367578818301184},
volume = {46},
year = {2018}
}
@article{Wilson2017,
abstract = {ALAMO is a computational methodology for learning algebraic functions from data. Given a data set, the approach begins by building a low-complexity, linear model composed of explicit non-linear transformations of the independent variables. Linear combinations of these non-linear transformations allow a linear model to better approximate complex behavior observed in real processes. The model is refined, as additional data are obtained in an adaptive fashion through error maximization sampling using derivative-free optimization. Models built using ALAMO can enforce constraints on the response variables to incorporate first-principles knowledge. The ability of ALAMO to generate simple and accurate models for a number of reaction problems is demonstrated. The error maximization sampling is compared with Latin hypercube designs to demonstrate its sampling efficiency. ALAMO's constrained regression methodology is used to further refine concentration models, resulting in models that perform better on validation data and satisfy upper and lower bounds placed on model outputs.},
archivePrefix = {arXiv},
arxivId = {1705.10918},
author = {Wilson, Zachary T. and Sahinidis, Nikolaos V.},
doi = {10.1016/j.compchemeng.2017.02.010},
eprint = {1705.10918},
file = {:C\:/Users/dv516/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Wilson, Sahinidis - 2017 - The ALAMO approach to machine learning.pdf:pdf},
issn = {00981354},
journal = {Computers \& Chemical Engineering},
keywords = {Feature selection,Mixed-integer optimization,Model selection,Parametric regression},
month = {nov},
pages = {785--795},
publisher = {Elsevier Ltd},
title = {{The ALAMO approach to machine learning}},
volume = {106},
year = {2017}
}
@techreport{Kingma,
abstract = {We introduce Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments. The method is straightforward to implement, is computationally efficient, has little memory requirements, is invariant to diagonal rescaling of the gradients, and is well suited for problems that are large in terms of data and/or parameters. The method is also appropriate for non-stationary objectives and problems with very noisy and/or sparse gradients. The hyper-parameters have intuitive interpretations and typically require little tuning. Some connections to related algorithms, on which Adam was inspired, are discussed. We also analyze the theoretical convergence properties of the algorithm and provide a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework. Empirical results demonstrate that Adam works well in practice and compares favorably to other stochastic optimization methods. Finally, we discuss AdaMax, a variant of Adam based on the infinity norm.},
archivePrefix = {arXiv},
arxivId = {1412.6980v9},
author = {Kingma, Diederik P and {Lei Ba}, Jimmy},
eprint = {1412.6980v9},
file = {::},
title = {{ADAM: A METHOD FOR STOCHASTIC OPTIMIZATION}}
}
@techreport{You,
abstract = {An important challenge for most chemical companies is to simultaneously consider inventory optimization and supply chain network design under demand uncertainty. This leads to a problem that requires integrating a stochastic inventory model with the supply chain network design model. This problem can be formulated as a large scale combinatorial optimization model that includes nonlinear terms. Since these models are very difficult to solve, they require exploiting their properties and developing special solution techniques to reduce the computational effort. In this work, we analyze the properties of the basic model and develop solution techniques for a joint supply chain network design and inventory management model for a given product. The model is formulated as a nonlinear integer programming problem. By reformulating it as a mixed-integer nonlinear programming (MINLP) problem and using an associated convex relaxation model for initialization, we first propose a heuristic method to quickly obtain good quality solutions. Further, a decomposition algorithm based on Lagrangean relaxation is developed for obtaining global or near-global optimal solutions. Extensive computational examples with up to 150 distribution centers and 150 retailers are presented to illustrate the performance of the algorithms and to compare them with the full-space solution.},
author = {You, Fengqi and Grossmann, Ignacio E},
file = {::},
title = {{Mixed-Integer Nonlinear Programming Models and Algorithms for Large-Scale Supply Chain Design with Stochastic Inventory Management}},
url = {http://egon.cheme.cmu.edu/Papers/StochInvDaskin.pdf}
}
@article{Pattison2016a,
abstract = {Today's fast-changing markets often require the granularity of production schedules to be refined to time scales comparable to the time constants of a chemical process. Consequently, the process dynamics must be considered explicitly in production scheduling. High dimensionality, nonlinearity, and the associated computational complexity make incorporating dynamic models in scheduling calculations challenging. We propose a novel scheduling approach based on scheduling-oriented low-order dynamic models identified from historical process operating data. We introduce a methodology for selecting scheduling-relevant variables and identify empirical models that capture their dynamic response to production target changes imposed at the scheduling level. The optimal scheduling calculation is then formulated as a dynamic optimization aimed at minimizing operating cost. We apply these concepts to an industrial-size model of an air separation unit operating under time-sensitive electricity prices. Our approach reduces computational effort considerably while preserving essential information required for the optimal schedule to be feasible from a dynamic point of view. Extensive simulations show that significant savings can be derived from operating in a transient regime, where the production rate is increased when energy prices are low, and reduced during peak price periods, while taking advantage of available storage capacity. ■ INTRODUCTION Fast-changing markets and the emergence of responsive, on-demand manufacturing require that production schedule changes occur over time scales comparable to the time constants of process systems. In turn, this requires that the dynamic characteristics and performance of the process and its control system be accounted for at the production scheduling stage. 1−3 However, embedding dynamics and control information in scheduling calculations has proven to be a difficult task. 3 Production scheduling and process control are typically carried out by separate entities of a company, and the coordination of interactions between the two functions is often challenging. 4 Significant challenges also arise from the need to account for the wide range of time scales involved in making scheduling and control decisions, and the corresponding requirement to balance long-term predictions with real-time execution. 3 Intuitively, optimal scheduling decisions should consider process dynamics in markets where prices (and therefore operating costs and profit margins) change at a high frequency, i.e., over time intervals that are comparable to the dominant time constant of the process. A typical example is the electricity market, where, owing to deregulation, prices change over short time spans (typically hours or even minutes). Participation in a real-time electricity market is often voluntary for industrial sites, who also have the option of entering fixed contracts with their utility suppliers. Variable pricing options become attractive when a site can quickly modulate its production rate by (i) increasing production and storing excess product when energy prices are low and (ii) using stored product to meet customer demand when prices are high and production rates are reduced. Conventional methods for calculating optimal production schedules rely on tabulated transition information between (a set of discrete) operating points, coupled with steady state process models or production recipes. 5 It is implicitly assumed that the process is at a steady state prior to a production target change and that it reaches steady state again before a new change is made. However, in the case where market fluctuations are rapid and occur at a frequency comparable to the (slowest) dynamic},
author = {Pattison, Richard C and Touretzky, Cara R and Johansson, Ted and Harjunkoski, Iiro and Baldea, Michael},
doi = {10.1021/acs.iecr.5b03499},
file = {:C\:/Users/dv516/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Pattison et al. - 2016 - Optimal Process Operations in Fast-Changing Electricity Markets Framework for Scheduling with Low-Order Dynamic.pdf:pdf},
journal = {Ind. Eng. Chem. Res},
pages = {52},
publisher = {UTC},
title = {{Optimal Process Operations in Fast-Changing Electricity Markets: Framework for Scheduling with Low-Order Dynamic Models and an Air Separation Application}},
url = {https://pubs.acs.org/sharingguidelines},
volume = {55},
year = {2016}
}
@article{Li2021a,
abstract = {This paper considers distributed optimisation problems with black-box functions using surrogate-assisted methods. Since the cost functions and their derivatives are usually impossible to be expressed by explicit functions due to the complexity of modern systems, function calls have to be performed to obtain those values. Moreover, the cost functions are often expensive to evaluate, and therefore designers prefer to reduce the number of evaluations. In this paper, surrogate-based methods are utilised to approximate the true functions, and conditions for constructing smooth and convex surrogates are established, by which the requirements for explicit functions are eliminated. To improve the quality of surrogate models, a distance-based infill strategy is proposed to balance the exploitation and exploration, which guarantees the density of the decision sequence in a compact set. Then, a distributed optimisation algorithm is developed to solve the reformulated auxiliary sub-problems, and the convergence of the proposed algorithm is established via Lyapunov theory. Simulation examples are provided to validate the effectiveness of the theoretical development and demonstrate the potential significance of the framework.},
author = {Li, Zhongguo and Dong, Zhen and Liang, Zhongchao and Ding, Zhengtao},
doi = {10.1016/J.AUTOMATICA.2020.109407},
issn = {0005-1098},
journal = {Automatica},
keywords = {Black-box functions,Distributed algorithms,Expensive optimisation methods,Multi-agent systems,Surrogate models},
month = {mar},
pages = {109407},
publisher = {Pergamon},
title = {{Surrogate-based distributed optimisation for expensive black-box functions}},
volume = {125},
year = {2021}
}
@misc{Boukouvala2016,
abstract = {This manuscript reviews recent advances in deterministic global optimization for Mixed-Integer Nonlinear Programming (MINLP), as well as Constrained Derivative-Free Optimization (CDFO). This work provides a comprehensive and detailed literature review in terms of significant theoretical contributions, algorithmic developments, software implementations and applications for both MINLP and CDFO. Both research areas have experienced rapid growth, with a common aim to solve a wide range of real-world problems. We show their individual prerequisites, formulations and applicability, but also point out possible points of interaction in problems which contain hybrid characteristics. Finally, an inclusive and complete test suite is provided for both MINLP and CDFO algorithms, which is useful for future benchmarking.},
author = {Boukouvala, Fani and Misener, Ruth and Floudas, Christodoulos A.},
booktitle = {European Journal of Operational Research},
doi = {10.1016/j.ejor.2015.12.018},
issn = {03772217},
keywords = {Constraints,Derivative-free,Deterministic global optimization,Grey-/Black-box,MINLP},
title = {{Global optimization advances in Mixed-Integer Nonlinear Programming, MINLP, and Constrained Derivative-Free Optimization, CDFO}},
year = {2016}
}
@inproceedings{Raghunathan2018a,
abstract = {Despite their impressive performance on diverse tasks, neural networks fail catastrophically in the presence of adversarial inputs-imperceptibly but adversarially perturbed versions of natural inputs. We have witnessed an arms race between defenders who attempt to train robust networks and attackers who try to construct adversarial examples. One promise of ending the arms race is developing certified defenses, ones which are provably robust against all attackers in some family. These certified defenses are based on convex relaxations which construct an upper bound on the worst case loss over all attackers in the family. Previous relaxations are loose on networks that are not trained against the respective relaxation. In this paper, we propose a new semidefinite relaxation for certifying robustness that applies to arbitrary ReLU networks. We show that our proposed relaxation is tighter than previous relaxations and produces meaningful robustness guarantees on three different foreign networks whose training objectives are agnostic to our proposed relaxation.},
archivePrefix = {arXiv},
arxivId = {1811.01057},
author = {Raghunathan, Aditi and Steinhardt, Jacob and Liang, Percy},
booktitle = {Advances in Neural Information Processing Systems},
eprint = {1811.01057},
issn = {10495258},
title = {{Semidefinite relaxations for certifying robustness to adversarial examples}},
year = {2018}
}
@article{Georghiou2019a,
abstract = {Dynamic decision-making under uncertainty has a long and distinguished history in operations research. Due to the curse of dimensionality, solution schemes that na{\"{i}}vely partition or discretize the support of the random problem parameters are limited to small and medium-sized problems, or they require restrictive modeling assumptions (e.g., absence of recourse actions). In the last few decades, several solution techniques have been proposed that aim to alleviate the curse of dimensionality. Amongst these is the decision rule approach, which faithfully models the random process and instead approximates the feasible region of the decision problem. In this paper, we survey the major theoretical findings relating to this approach, and we investigate its potential in two applications areas.},
author = {Georghiou, Angelos and Kuhn, Daniel and Wiesemann, Wolfram},
doi = {10.1007/s10287-018-0338-5},
file = {:C\:/Users/dv516/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Georghiou, Kuhn, Wiesemann - 2019 - The decision rule approach to optimization under uncertainty methodology and applications.pdf:pdf},
issn = {1619-697X},
journal = {Computational Management Science},
keywords = {Operations Research/Decision Theory,Optimization},
month = {oct},
number = {4},
pages = {545--576},
publisher = {Springer},
title = {{The decision rule approach to optimization under uncertainty: methodology and applications}},
url = {http://link.springer.com/10.1007/s10287-018-0338-5},
volume = {16},
year = {2019}
}
@article{Mendoza2016,
abstract = {There is not a consensus about the benefits of implementing Real-Time Optimization (RTO) technologies to increase the profit of process plants. A lack of experimental and theoretical works which evaluate the scope and limitations of different RTO approaches makes it more difficult to have a sensible opinion about this topic. Most works available in the open literature that study different RTO approaches use few (often one) operation conditions to draw general conclusions about the virtues of a particular methodology. In the present work, we compare the performance of the classical two-step method with more recently proposed derivative-based methods (modifier adaptation, Integrated System Optimization Parameter Estimation (ISOPE), and an algorithm based on the Sufficient Conditions of Feasibility and Optimality (SCFO)) under different measurement noise, model mismatch, and disturbance using a Monte Carlo methodology. The results show that the classical RTO method can be reasonably reliable if provided with a model flexible enough to mimic the local process topology, a parameter estimation method suitable for handling measurement noise characteristics, and a method to improve the sample information quality. Implementing a derivative-based RTO method, in cases of evident model mismatch, should be considered only if the gap between the predicted and the real optimum is large enough and the level of measurement noise is low.},
author = {Mendoza, Diego Fernando and Graciano, Jos{\'{e}} Eduardo Alves and {dos Santos Liporace}, Fabio and {Le Roux}, Galo Antonio Carrillo},
doi = {10.1002/cjce.22402},
issn = {1939019X},
journal = {Canadian Journal of Chemical Engineering},
keywords = {Model parameter adaptation,Modifier adaptation,Parameter estimation,Real-time optimization (RTO)},
month = {mar},
number = {3},
pages = {485--497},
publisher = {Wiley-Liss Inc.},
title = {{Assessing the reliability of different real-time optimization methodologies}},
url = {https://onlinelibrary.wiley.com/doi/full/10.1002/cjce.22402 https://onlinelibrary.wiley.com/doi/abs/10.1002/cjce.22402 https://onlinelibrary.wiley.com/doi/10.1002/cjce.22402},
volume = {94},
year = {2016}
}
@article{Biegler2017,
author = {Biegler, Lorenz T.},
doi = {10.1002/aic.15674},
issn = {15475905},
journal = {AIChE Journal},
keywords = {complementarity conditions,model reduction,multilevel optimization,nonlinear programming,process optimization},
month = {apr},
number = {4},
pages = {1178--1193},
publisher = {John Wiley and Sons Inc.},
title = {{New nonlinear programming paradigms for the future of process optimization}},
volume = {63},
year = {2017}
}
@article{Blasi2018,
abstract = {To achieve a common goal in an optimal way systems are becoming increasingly interconnected. While operating as autonomous as possible, the subsystems should exploit the capabilities and desires of neighboring systems in a cooperative way to avoid conflicts and optimize overall performance. Increasing interconnections, together with autonomous behavior, however, challenge the system design and control. Distributed model predictive control strategies allow to break the complexity of interconnected systems, as each subsystem employs its own controller, taking information obtained or provided by the neighboring systems into account. We propose a distributed model predictive control strategy, in which the subsystems provide multiple options of possible future behaviors to their neighbors. The options are provided in form of contracts - outer bounds of the variables of the coupling variables. The neighboring systems take these options in their predictions into account and choose the most suitable one. By this they exploit the capabilities and influences of the neighbors in a cooperative way. We outline conditions which guarantee repeated feasibility and illustrate the approach considering autonomously driving vehicles entering a highway.},
author = {Blasi, Svenja and K{\"{o}}gel, Markus},
doi = {10.1016/J.IFACOL.2018.11.048},
file = {:C\:/Users/dv516/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Blasi, K{\"{o}}gel - 2018 - Distributed Model Predictive Control Using Cooperative Contract Options.pdf:pdf},
issn = {2405-8963},
journal = {IFAC-PapersOnLine},
month = {jan},
number = {20},
pages = {448--454},
publisher = {Elsevier},
title = {{Distributed Model Predictive Control Using Cooperative Contract Options}},
url = {https://www.sciencedirect.com/science/article/pii/S240589631832706X#!},
volume = {51},
year = {2018}
}
@misc{Sun2020,
abstract = {This paper motivates and guides the use of derivative-free optimization methods to solve chemical product design problems. The proposed methodology incorporates derivative-free optimization into computer-aided molecular design frameworks. Doing so facilitates the exploitation of property prediction simulators to generate accurate property models and search the complete design space to increase solution diversity. We assess derivative-free optimization algorithms and demonstrate the viability of the proposed framework using a polymer configuration design example. Our computational results suggest that a collection of derivative-free algorithms can successfully search the chemical design space and identify good solutions with high computational efficiency.},
author = {Sun, Yijia and Sahinidis, Nikolaos V. and Sundaram, Anantha and Cheon, Myun Seok},
booktitle = {Current Opinion in Chemical Engineering},
doi = {10.1016/j.coche.2019.11.006},
file = {:C\:/Users/dv516/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Sun et al. - 2020 - Derivative-free optimization for chemical product design.pdf:pdf},
issn = {22113398},
month = {mar},
pages = {98--106},
publisher = {Elsevier Ltd},
title = {{Derivative-free optimization for chemical product design}},
url = {https://doi.org/10.1016/j.coche.2019.11.006},
volume = {27},
year = {2020}
}
@article{Berahas2019,
abstract = {In this paper, we analyze several methods for approximating gradients of noisy functions using only function values. These methods include finite differences, linear interpolation, Gaussian smoothing and smoothing on a sphere. The methods differ in the number of functions sampled, the choice of the sample points, and the way in which the gradient approximations are derived. For each method, we derive bounds on the number of samples and the sampling radius which guarantee favorable convergence properties for a line search or fixed step size descent method. To this end, we use the results in [Berahas et al., 2019] and show how each method can satisfy the sufficient conditions, possibly only with some sufficiently large probability at each iteration, as happens to be the case with Gaussian smoothing and smoothing on a sphere. Finally, we present numerical results evaluating the quality of the gradient approximations as well as their performance in conjunction with a line search derivative-free optimization algorithm.},
archivePrefix = {arXiv},
arxivId = {1905.01332},
author = {Berahas, Albert S. and Cao, Liyuan and Choromanski, Krzysztof and Scheinberg, Katya},
eprint = {1905.01332},
file = {::},
journal = {arXiv},
month = {may},
publisher = {arXiv},
title = {{A Theoretical and Empirical Comparison of Gradient Approximations in Derivative-Free Optimization}},
url = {http://arxiv.org/abs/1905.01332},
year = {2019}
}
@article{Eason2018,
abstract = {We present an improved trust region filter (TRF) method for optimization of combined glass box/black box systems. Glass box systems refer to models that are easily expressed in an algebraic modeling language, providing cheap and accurate derivative information. By contrast, black box systems may be computationally expensive and derivatives are unavailable. The TRF method, as first introduced in our previous work (Eason and Biegler, AIChE J. 2016; 62:3124–3136), is able to handle hybrid systems containing both glass and black box components, which can frequently arise in chemical engineering, for example, when a multiphase reactor model is included in a flow sheet optimization problem. We discuss several recent modifications in the algorithm such as the sampling region, which maintains the algorithm's global convergence properties without requiring the trust region to shrink to zero in the limit. To benchmark the development of this optimization method, a test set of problems is generated based on modified problems from the CUTEr and COPS sets. The modified algorithm demonstrates improved performance using the test problem set. Finally, the algorithm is implemented within the Pyomo environment and demonstrated on a rigorous process optimization case study for carbon capture. {\textcopyright} 2018 American Institute of Chemical Engineers AIChE J, 64: 3934–3943, 2018.},
author = {Eason, John P. and Biegler, Lorenz T.},
doi = {10.1002/aic.16364},
issn = {00011541},
journal = {AIChE Journal},
keywords = {Simulation,adsorption/gas,mathematical modeling,optimization,process},
month = {nov},
number = {11},
pages = {3934--3943},
publisher = {John Wiley and Sons Inc.},
title = {{Advanced trust region optimization strategies for glass box <b>/</b> black box models}},
url = {http://doi.wiley.com/10.1002/aic.16364},
volume = {64},
year = {2018}
}
@article{Busoniu2018,
abstract = {Reinforcement learning (RL) offers powerful algorithms to search for optimal controllers of systems with nonlinear, possibly stochastic dynamics that are unknown or highly uncertain. This review mainly covers artificial-intelligence approaches to RL, from the viewpoint of the control engineer. We explain how approximate representations of the solution make RL feasible for problems with continuous states and control actions. Stability is a central concern in control, and we argue that while the control-theoretic RL subfield called adaptive dynamic programming is dedicated to it, stability of RL largely remains an open question. We also cover in detail the case where deep neural networks are used for approximation, leading to the field of deep RL, which has shown great success in recent years. With the control practitioner in mind, we outline opportunities and pitfalls of deep RL; and we close the survey with an outlook that – among other things – points out some avenues for bridging the gap between control and artificial-intelligence RL techniques.},
author = {Buşoniu, Lucian and de Bruin, Tim and Toli{\'{c}}, Domagoj and Kober, Jens and Palunko, Ivana},
doi = {10.1016/J.ARCONTROL.2018.09.005},
issn = {1367-5788},
journal = {Annual Reviews in Control},
month = {jan},
pages = {8--28},
publisher = {Pergamon},
title = {{Reinforcement learning for control: Performance, stability, and deep approximators}},
url = {https://www.sciencedirect.com/science/article/abs/pii/S1367578818301184},
volume = {46},
year = {2018}
}
@techreport{Li2004,
abstract = {This paper attempts to set a unified scene for various linear time-invariant (LTI) control system design schemes, by transforming the existing concept of "computer-aided control system design" (CACSD) to novel "computer-automated control system design" (CAutoCSD). The first step towards this goal is to accommodate, under practical constraints, various design objectives that are desirable in both time and frequency domains. Such performance-prioritised unification is aimed at relieving practising engineers from having to select a particular control scheme and from sacrificing certain performance goals resulting from pre-commitment to such schemes. With recent progress in evolutionary computing based extra-numeric, multi-criterion search and optimisation techniques, such unification of LTI control schemes becomes feasible, analytical and practical, and the resultant designs can be creative. The techniques developed are applied to, and illustrated by, three design problems. The unified approach automatically provides an integrator for zero-steady state error in velocity control of a DC motor, and meets multiple objectives in the design of an LTI controller for a non-minimum phase plant and offers a high-performance LTI controller network for a non-linear chemical process.},
author = {Li, Yun and {Heong Ang}, Kiam and Chong, Gregory CY and Feng, Wenyuan and {Chen Tan}, Kay and Kashiwagi, Hiroshi},
booktitle = {International Journal of Automation and Computing},
file = {::},
keywords = {Linear time-invariant (LTI),computer-aided control system design (CACSD),control system design (CSD),evolutionary computation (EC),genetic algorithms (GA),performance index,process control,proportional plus integral plus derivative (PID),robust control},
pages = {76--88},
title = {{CAutoCSD-Evolutionary Search and Optimisation Enabled Computer Automated Control System Design}},
volume = {1},
year = {2004}
}
@article{Velarde2018a,
abstract = {In this paper, we present an analysis of the vulnerability of a distributed model predictive control scheme. A distributed system can be easily attacked by a malicious agent that modifies the reliable information exchange. We consider different types of so-called insider attacks. In particular, we analyze a controller that is part of the control architecture that sends false information to others to manipulate costs for its own advantage. We propose a mechanism to protect or, at least, relieve the consequences of the attack in a typical distributed model predictive control negotiation procedure. More specifically, a consensus approach that dismisses the extreme control actions is presented as a way to protect the distributed system from potential threats. Two applications are considered as case studies, ie, an academic example involving the control of a distributed system with a single coupled input and a distributed local electricity grid of households. The results are presented via simulations to illustrate both the consequences of the attacks and the defense mechanisms.},
author = {Velarde, Pablo and Maestre, Jos{\'{e}} M. and Ishii, Hideaki and Negenborn, Rudy R.},
doi = {10.1002/oca.2368},
issn = {10991514},
journal = {Optimal Control Applications and Methods},
keywords = {optimal control applications,predictive control,robust control},
title = {{Vulnerabilities in Lagrange-based distributed model predictive control}},
year = {2018}
}
@misc{,
title = {{(No Title)}},
url = {https://www.elsevier.com/__data/assets/pdf_file/0006/278133/Industry-4.0-How-Chemical-Manufacturers-Can-Rise-to-the-Challenges.pdf},
urldate = {2021-05-01}
}
@article{Pourkargar2017,
abstract = {This paper addresses the impact of decomposition on the closed-loop performance and computational efficiency of model predictive control (MPC) of nonlinear process networks. Distributed MPC structures with different communication strategies are designed for regulation of an integrated reactor-separator process. Different system decompositions are also considered, including decompositions into local controllers with minimum interactions obtained via community detection methods. The closed-loop performance and computational effort of the different MPC designs are analyzed. Through such a comprehensive comparison, tradeoffs between performance and computation effort, and the importance of systematic choice of the system decomposition, are documented. (Graph Presented).},
author = {Pourkargar, Davood Babaei and Almansoori, Ali and Daoutidis, Prodromos},
doi = {10.1021/acs.iecr.7b00644},
issn = {15205045},
journal = {Industrial and Engineering Chemistry Research},
month = {aug},
number = {34},
pages = {9606--9616},
publisher = {American Chemical Society},
title = {{Impact of Decomposition on Distributed Model Predictive Control: A Process Network Case Study}},
url = {https://pubs.acs.org/doi/pdf/10.1021/acs.iecr.7b00644},
volume = {56},
year = {2017}
}

@article{Stephanopoulos1986,
abstract = {The author shows that artificial intelligence is expanding the scope of our problems and is enriching our capabilities to deliver viable solutions to otherwise hard and resistant problems. At the same time it is introducing new educational challenges that the research program at the MIT-LISPE is attempting to address and which are related to the computer-aided character of chemical process engineering, the rationalization of the man-machine interaction, and the role of fundamental science in engineering. A discussion is presented of the MIT-LISPE (Laboratory for Intelligent System for Process Engineering); hardware facilities and software support; and research projects and the new prototype of an intelligent system.},
author = {Stephanopoulos, George},
issn = {00092479},
journal = {Chemical Engineering Education},
month = {sep},
number = {4},
pages = {182--185, 192},
title = {{RESEARCH PROGRAM ON ARTIFICIAL INTELLIGENCE IN PROCESS ENGINEERING.}},
volume = {20},
year = {1986}
}
@article{Drag2016,
abstract = {In the article the main features of direct and indirect approaches for solving optimal control problems were presented. The mentioned methods can be effectively applied in the Model Predictive Control of the complex technological systems in electrical, chemical and aerospace engineering, often described by nonlinear differential-algebraic equations. Among the direct and indirect methods for solving optimal control problems one can mention Euler-Lagrange equations, direct optimization methods and indirect gradients methods.},
author = {Dr{\c{a}}g, Pawe{\l} and Stycze{\'{n}}, Krystyn and Kwiatkowska, Marlena and Szczurek, Andrzej},
doi = {10.1007/978-3-319-21133-6_6},
issn = {1860949X},
journal = {Studies in Computational Intelligence},
keywords = {Differential-algebraic systems,Direct and indirect methods,Multiple shooting method,Optimal control},
pages = {91--105},
publisher = {Springer Verlag},
title = {{A review on the direct and indirect methods for solving optimal control problems with differential-algebraic constraints}},
url = {https://link.springer.com/chapter/10.1007/978-3-319-21133-6_6},
volume = {610},
year = {2016}
}
@article{Ploskas2018,
abstract = {Optimization of the refrigerant circuitry can improve a heat exchanger's performance. Design engineers currently choose the refrigerant circuitry according to their experience and heat exchanger simulations. However, the design of an optimized refrigerant circuitry is difficult. The number of refrigerant circuitry candidates is enormous. Therefore, exhaustive search algorithms cannot be used and intelligent techniques must be developed to explore the solution space efficiently. In this paper, we formulate refrigerant circuitry design as a binary constrained optimization problem. We use CoilDesigner, a simulation and design tool of air to refrigerant heat exchangers, in order to simulate the performance of different refrigerant circuitry designs. We treat CoilDesigner as a black-box system since the exact relationship of the objective function with the decision variables is not explicit. Derivative-free optimization (DFO) algorithms are suitable for solving this black-box model since they do not require explicit functional representations of the objective function and the constraints. The aim of this paper is twofold. First, we compare four mixed-integer constrained DFO solvers and one box-bounded DFO solver and evaluate their ability to solve a difficult industrially relevant problem. Second, we demonstrate that the proposed formulation is suitable for optimizing the circuitry configuration of heat exchangers. We apply the DFO solvers to 17 heat exchanger design problems. Results show that TOMLAB/glcDirect and TOMLAB/glcSolve can find optimal or near-optimal refrigerant circuitry designs after a relatively small number of circuit simulations.},
archivePrefix = {arXiv},
arxivId = {1705.10437},
author = {Ploskas, Nikolaos and Laughman, Christopher and Raghunathan, Arvind U. and Sahinidis, Nikolaos V.},
doi = {10.1016/j.cherd.2017.05.015},
eprint = {1705.10437},
issn = {02638762},
journal = {Chemical Engineering Research and Design},
keywords = {Derivative-free algorithms,Heat exchanger design,Optimization,Refrigerant circuitry},
month = {mar},
pages = {16--28},
publisher = {Institution of Chemical Engineers},
title = {{Optimization of circuitry arrangements for heat exchangers using derivative-free optimization}},
volume = {131},
year = {2018}
}
@article{Dominguez2020,
abstract = {In this paper, we review relevant literature on the development of multi-agent systems applications for supply chain management. We give a general picture of the state of the art, showing the main applications developed using this novel methodology for analyzing diverse problems in industry. We also analyze generic frameworks for supply chain modelling, showing their main characteristics. We discuss the main topics addressed with this technique and the degree of development of the contributions.},
author = {Dominguez, Roberto and Cannella, Salvatore},
doi = {10.3390/su12051935},
file = {:C\:/Users/dv516/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Dominguez, Cannella - 2020 - Insights on multi-agent systems applications for supply chain management.pdf:pdf},
issn = {20711050},
journal = {Sustainability (Switzerland)},
keywords = {Multi-agent systems,Simulation,Supply chain management},
month = {mar},
number = {5},
pages = {1--13},
publisher = {MDPI AG},
title = {{Insights on multi-agent systems applications for supply chain management}},
url = {www.mdpi.com/journal/sustainability},
volume = {12},
year = {2020}
}
@article{Georghiou2019,
abstract = {Dynamic decision-making under uncertainty has a long and distinguished history in operations research. Due to the curse of dimensionality, solution schemes that na{\"{i}}vely partition or discretize the support of the random problem parameters are limited to small and medium-sized problems, or they require restrictive modeling assumptions (e.g., absence of recourse actions). In the last few decades, several solution techniques have been proposed that aim to alleviate the curse of dimensionality. Amongst these is the decision rule approach, which faithfully models the random process and instead approximates the feasible region of the decision problem. In this paper, we survey the major theoretical findings relating to this approach, and we investigate its potential in two applications areas.},
author = {Georghiou, Angelos and Kuhn, Daniel and Wiesemann, Wolfram},
doi = {10.1007/s10287-018-0338-5},
file = {:C\:/Users/dv516/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Georghiou, Kuhn, Wiesemann - 2019 - The decision rule approach to optimization under uncertainty methodology and applications.pdf:pdf},
issn = {1619-697X},
journal = {Computational Management Science},
keywords = {Operations Research/Decision Theory,Optimization},
month = {oct},
number = {4},
pages = {545--576},
publisher = {Springer},
title = {{The decision rule approach to optimization under uncertainty: methodology and applications}},
url = {http://link.springer.com/10.1007/s10287-018-0338-5},
volume = {16},
year = {2019}
}
@techreport{Snoek,
abstract = {The use of machine learning algorithms frequently involves careful tuning of learning parameters and model hyperparameters. Unfortunately, this tuning is often a "black art" requiring expert experience, rules of thumb, or sometimes brute-force search. There is therefore great appeal for automatic approaches that can optimize the performance of any given learning algorithm to the problem at hand. In this work, we consider this problem through the framework of Bayesian optimization , in which a learning algorithm's generalization performance is modeled as a sample from a Gaussian process (GP). We show that certain choices for the nature of the GP, such as the type of kernel and the treatment of its hyperparame-ters, can play a crucial role in obtaining a good optimizer that can achieve expert-level performance. We describe new algorithms that take into account the variable cost (duration) of learning algorithm experiments and that can leverage the presence of multiple cores for parallel experimentation. We show that these proposed algorithms improve on previous automatic procedures and can reach or surpass human expert-level optimization for many algorithms including latent Dirichlet allocation, structured SVMs and convolutional neural networks.},
author = {Snoek, Jasper and Larochelle, Hugo and Adams, Ryan P},
file = {::},
title = {{Practical Bayesian Optimization of Machine Learning Algorithms}}
}
@article{Kamthe2017,
abstract = {Trial-and-error based reinforcement learning (RL) has seen rapid advancements in recent times, especially with the advent of deep neural networks. However, the majority of autonomous RL algorithms require a large number of interactions with the environment. A large number of interactions may be impractical in many real-world applications, such as robotics, and many practical systems have to obey limitations in the form of state space or control constraints. To reduce the number of system interactions while simultaneously handling constraints, we propose a model-based RL framework based on probabilistic Model Predictive Control (MPC). In particular, we propose to learn a probabilistic transition model using Gaussian Processes (GPs) to incorporate model uncertainty into long-term predictions, thereby, reducing the impact of model errors. We then use MPC to find a control sequence that minimises the expected long-term cost. We provide theoretical guarantees for first-order optimality in the GP-based transition models with deterministic approximate inference for long-term planning. We demonstrate that our approach does not only achieve state-of-the-art data efficiency, but also is a principled way for RL in constrained environments.},
archivePrefix = {arXiv},
arxivId = {1706.06491},
author = {Kamthe, Sanket and Deisenroth, Marc Peter},
eprint = {1706.06491},
file = {:C\:/Users/dv516/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Kamthe, Deisenroth - 2017 - Data-Efficient Reinforcement Learning with Probabilistic Model Predictive Control.pdf:pdf},
month = {jun},
title = {{Data-Efficient Reinforcement Learning with Probabilistic Model Predictive Control}},
url = {http://arxiv.org/abs/1706.06491},
year = {2017}
}
@misc{Anderson2020a,
abstract = {In this paper, we consider the problem of certifying the robustness of neural networks to perturbed and adversarial input data. Such certification is imperative for the application of neural networks in safety-critical decisionmaking and control systems. Certification techniques using convex optimization have been proposed, but they often suffer from relaxation errors that void the certificate. Our work exploits the structure of ReLU networks to improve relaxation errors through a novel partition-based certification procedure. The proposed method is proven to tighten existing linear programming relaxations, and asymptotically achieves zero relaxation error as the partition is made finer. We develop a finite partition that attains zero relaxation error and use the result to derive a tractable partitioning scheme that minimizes the worst-case relaxation error. Experiments using real data show that the partitioning procedure is able to issue robustness certificates in cases where prior methods fail. Consequently, partition-based certification procedures are found to provide an intuitive, effective, and theoretically justified method for tightening existing convex relaxation techniques.},
archivePrefix = {arXiv},
arxivId = {2004.00570},
author = {Anderson, Brendon G. and Ma, Ziye and Li, Jingqi and Sojoudi, Somayeh},
booktitle = {arXiv},
eprint = {2004.00570},
issn = {23318422},
title = {{Tightened convex relaxations for neural network robustness certification}},
year = {2020}
}
@misc{,
title = {{Trust Region Methods - Andrew R. Conn, Nicholas I. M. Gould, Philippe L. Toint - Google Books}},
url = {https://books.google.co.uk/books/about/Trust_Region_Methods.html?id=5kNC4fqssYQC},
urldate = {2021-05-04}
}
@inproceedings{Maestre2019,
abstract = {A tube-based distributed model predictive control (DMPC) scheme is proposed for dynamically coupled linear systems. The control scheme is designed to guarantee local performance even when neighboring controllers are not complying with the requirements of the algorithm (e.g., they are malicious or faulty). The resulting conservativeness is minimized, for controllers aim to minimize their state and input constraint sets to reduce mutual disturbances. Also, sufficient conditions for feasibility and exponential stability are given. Finally, these ideas are illustrated and assessed with respect to other robust DMPC via a simulated example.},
author = {Maestre, Jose M. and Trodden, Paul A. and Ishii, Hideaki},
booktitle = {Proceedings of the IEEE Conference on Decision and Control},
doi = {10.1109/CDC.2018.8619079},
isbn = {9781538613955},
issn = {07431546},
title = {{A Distributed Model Predictive Control Scheme with Robustness Against Noncompliant Controllers}},
year = {2019}
}
@article{Larson2019b,
abstract = {In many optimization problems arising from scientific, engineering and artificial intelligence applications, objective and constraint functions are available only as the output of a black-box or simulation oracle that does not provide derivative information. Such settings necessitate the use of methods for derivative-free, or zeroth-order, optimization. We provide a review and perspectives on developments in these methods, with an emphasis on highlighting recent developments and on unifying treatment of such problems in the non-linear optimization and machine learning literature. We categorize methods based on assumed properties of the black-box functions, as well as features of the methods. We first overview the primary setting of deterministic methods applied to unconstrained, non-convex optimization problems where the objective function is defined by a deterministic black-box oracle. We then discuss developments in randomized methods, methods that assume some additional structure about the objective (including convexity, separability and general non-smooth compositions), methods for problems where the output of the black-box oracle is stochastic, and methods for handling different types of constraints.},
archivePrefix = {arXiv},
arxivId = {1904.11585},
author = {Larson, Jeffrey and Menickelly, Matt and Wild, Stefan M.},
doi = {10.1017/S0962492919000060},
eprint = {1904.11585},
issn = {14740508},
journal = {Acta Numerica},
title = {{Derivative-free optimization methods}},
year = {2019}
}
@inproceedings{Burk2020a,
abstract = {This paper extends the recently introduced ALADIN algorithm to non-convex continuous-time optimal control problems with nonlinear dynamics and linear coupling constraints. The algorithm alternates between solving a convexified local problem in a distributed manner and a linearized quadratic problem on a centralized entity while using the solution of both for an update step. This paper presents an analysis of the local convergence of the algorithm and shows a quadratic convergence rate. Furthermore, a globalization strategy is presented that ensures global convergence. The paper closes with a numerical evaluation of the algorithm.},
author = {Burk, Daniel and Volz, Andreas and Graichen, Knut},
booktitle = {Proceedings of the IEEE Conference on Decision and Control},
doi = {10.1109/CDC42340.2020.9304459},
isbn = {9781728174471},
issn = {07431546},
month = {dec},
pages = {4387--4392},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{Distributed Optimization with ALADIN for Non-convex Optimal Control Problems}},
volume = {2020-Decem},
year = {2020}
}
@article{Li2021b,
abstract = {This paper considers distributed optimisation problems with black-box functions using surrogate-assisted methods. Since the cost functions and their derivatives are usually impossible to be expressed by explicit functions due to the complexity of modern systems, function calls have to be performed to obtain those values. Moreover, the cost functions are often expensive to evaluate, and therefore designers prefer to reduce the number of evaluations. In this paper, surrogate-based methods are utilised to approximate the true functions, and conditions for constructing smooth and convex surrogates are established, by which the requirements for explicit functions are eliminated. To improve the quality of surrogate models, a distance-based infill strategy is proposed to balance the exploitation and exploration, which guarantees the density of the decision sequence in a compact set. Then, a distributed optimisation algorithm is developed to solve the reformulated auxiliary sub-problems, and the convergence of the proposed algorithm is established via Lyapunov theory. Simulation examples are provided to validate the effectiveness of the theoretical development and demonstrate the potential significance of the framework.},
author = {Li, Zhongguo and Dong, Zhen and Liang, Zhongchao and Ding, Zhengtao},
doi = {10.1016/j.automatica.2020.109407},
issn = {00051098},
journal = {Automatica},
keywords = {Black-box functions,Distributed algorithms,Expensive optimisation methods,Multi-agent systems,Surrogate models},
month = {mar},
pages = {109407},
publisher = {Elsevier Ltd},
title = {{Surrogate-based distributed optimisation for expensive black-box functions}},
volume = {125},
year = {2021}
}
@techreport{Hite,
author = {Hite, -W and Per, P A},
file = {:C\:/Users/dv516/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Hite, Per - Unknown - Digitalization and the Chemical Plant of the Future.pdf:pdf},
title = {{Digitalization and the Chemical Plant of the Future}}
}
@article{Powell2009a,
abstract = {Approximate dynamic programming (ADP) is a broad umbrella for a modeling and algorithmic strategy for solving problems that are sometimes large and complex, and are usually (but not always) stochastic. It is most often presented as a method for overcoming the classic curse of dimensionality that is well-known to plague the use of Bellman's equation. For many problems, there are actually up to three curses of dimensionality. But the richer message of approximate dynamic programming is learning what to learn, and how to learn it, to make better decisions over time. This article provides a brief review of approximate dynamic programming, without intending to be a complete tutorial. Instead, our goal is to provide a broader perspective of ADP and how it should be approached from the perspective of different problem classes.},
author = {Powell, Warren B},
doi = {10.1002/nav.20347},
keywords = {Monte Carlo simulation,approximate dynamic programming,neuro-dynamic programming,reinforcement learning,stochastic optimization},
title = {{What You Should Know About Approximate Dynamic Programming}},
url = {www.interscience.wiley.com},
year = {2009}
}



@techreport{Tsay,
abstract = {This paper introduces a class of mixed-integer formulations for trained ReLU neural networks. The approach balances model size and tightness by partitioning node inputs into a number of groups and forming the convex hull over the partitions via disjunctive programming. At one extreme, one partition per input recovers the convex hull of a node, i.e., the tightest possible formulation for each node. For fewer partitions, we develop smaller relaxations that approximate the convex hull, and show that they outperform existing formulations. Specifically, we propose strategies for partitioning variables based on theoretical motivations and validate these strategies using extensive computational experiments. Furthermore, the proposed scheme complements known algorithmic approaches, e.g., optimization-based bound tightening captures dependencies within a partition.},
archivePrefix = {arXiv},
arxivId = {2102.04373v1},
author = {Tsay, Calvin and Kronqvist, Jan and Thebelt, Alexander and Misener, Ruth},
eprint = {2102.04373v1},
file = {::},
title = {{Partition-Based Formulations for Mixed-Integer Optimization of Trained ReLU Neural Networks}}
}
@article{Hewing2017,
abstract = {Gaussian process (GP) regression has been widely used in supervised machine learning due to its flexibility and inherent ability to describe uncertainty in function estimation. In the context of control, it is seeing increasing use for modeling of nonlinear dynamical systems from data, as it allows the direct assessment of residual model uncertainty. We present a model predictive control (MPC) approach that integrates a nominal system with an additive nonlinear part of the dynamics modeled as a GP. Approximation techniques for propagating the state distribution are reviewed and we describe a principled way of formulating the chance constrained MPC problem, which takes into account residual uncertainties provided by the GP model to enable cautious control. Using additional approximations for efficient computation, we finally demonstrate the approach in a simulation example, as well as in a hardware implementation for autonomous racing of remote controlled race cars, highlighting improvements with regard to both performance and safety over a nominal controller.},
archivePrefix = {arXiv},
arxivId = {1705.10702},
author = {Hewing, Lukas and Kabzan, Juraj and Zeilinger, Melanie N.},
doi = {10.1109/TCST.2019.2949757},
eprint = {1705.10702},
file = {::},
journal = {IEEE Transactions on Control Systems Technology},
keywords = {Autonomous racing,Gaussian processes (GPs),learning-based control,model learning,model predictive control (MPC)},
month = {may},
number = {6},
pages = {2736--2743},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{Cautious Model Predictive Control using Gaussian Process Regression}},
url = {http://arxiv.org/abs/1705.10702 http://dx.doi.org/10.1109/TCST.2019.2949757},
volume = {28},
year = {2017}
}
@article{Berahas2019a,
abstract = {In this paper, we analyze several methods for approximating gradients of noisy functions using only function values. These methods include finite differences, linear interpolation, Gaussian smoothing and smoothing on a sphere. The methods differ in the number of functions sampled, the choice of the sample points, and the way in which the gradient approximations are derived. For each method, we derive bounds on the number of samples and the sampling radius which guarantee favorable convergence properties for a line search or fixed step size descent method. To this end, we use the results in [Berahas et al., 2019] and show how each method can satisfy the sufficient conditions, possibly only with some sufficiently large probability at each iteration, as happens to be the case with Gaussian smoothing and smoothing on a sphere. Finally, we present numerical results evaluating the quality of the gradient approximations as well as their performance in conjunction with a line search derivative-free optimization algorithm.},
archivePrefix = {arXiv},
arxivId = {1905.01332},
author = {Berahas, Albert S. and Cao, Liyuan and Choromanski, Krzysztof and Scheinberg, Katya},
eprint = {1905.01332},
file = {::},
journal = {arXiv},
month = {may},
publisher = {arXiv},
title = {{A Theoretical and Empirical Comparison of Gradient Approximations in Derivative-Free Optimization}},
url = {http://arxiv.org/abs/1905.01332},
year = {2019}
}

@article{Wang2021,
	doi = {10.1109/tsp.2021.3097211},
  
	url = {https://doi.org/10.1109%2Ftsp.2021.3097211},
  
	year = 2021,
	publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
  
	volume = {69},
  
	pages = {4486--4501},
  
	author = {Zhiguo Wang and Jiawei Zhang and Tsung-Hui Chang and Jian Li and Zhi-Quan Luo},
  
	title = {Distributed Stochastic Consensus Optimization With Momentum for Nonconvex Nonsmooth Problems},
  
	journal = {{IEEE} Transactions on Signal Processing}
}

@article{Amaran2016a,
abstract = {Simulation optimization (SO) refers to the optimization of an objective function subject to constraints, both of which can be evaluated through a stochastic simulation. To address specific features of a particular simulation—discrete or continuous decisions, expensive or cheap simulations, single or multiple outputs, homogeneous or heterogeneous noise—various algorithms have been proposed in the literature. As one can imagine, there exist several competing algorithms for each of these classes of problems. This document emphasizes the difficulties in SO as compared to algebraic model-based mathematical programming, makes reference to state-of-the-art algorithms in the field, examines and contrasts the different approaches used, reviews some of the diverse applications that have been tackled by these methods, and speculates on future directions in the field.},
archivePrefix = {arXiv},
arxivId = {1706.08591},
author = {Amaran, Satyajith and Sahinidis, Nikolaos V. and Sharda, Bikram and Bury, Scott J.},
doi = {10.1007/s10479-015-2019-x},
eprint = {1706.08591},
file = {:C\:/Users/dv516/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Amaran et al. - 2016 - Simulation optimization a review of algorithms and applications.pdf:pdf},
issn = {15729338},
journal = {Annals of Operations Research},
keywords = {Derivative-free optimization,Optimization via simulation,Simulation optimization},
month = {may},
number = {1},
pages = {351--380},
publisher = {Springer New York LLC},
title = {{Simulation optimization: a review of algorithms and applications}},
url = {https://link.springer.com/article/10.1007/s10479-015-2019-x},
volume = {240},
year = {2016}
}
@article{Costa2018,
abstract = {We consider the problem of optimizing an unknown function given as an oracle over a mixed-integer box-constrained set. We assume that the oracle is expensive to evaluate, so that estimating partial derivatives by finite differences is impractical. In the literature, this is typically called a black-box optimization problem with costly evaluation. This paper describes the solution methodology implemented in the open-source library RBFOpt, available on COIN-OR. The algorithm is based on the Radial Basis Function method originally proposed by Gutmann (J Glob Optim 19:201–227, 2001. https://doi.org/10.1023/A:1011255519438), which builds and iteratively refines a surrogate model of the unknown objective function. The two main methodological contributions of this paper are an approach to exploit a noisy but less expensive oracle to accelerate convergence to the optimum of the exact oracle, and the introduction of an automatic model selection phase during the optimization process. Numerical experiments show that RBFOpt is highly competitive on a test set of continuous and mixed-integer nonlinear unconstrained problems taken from the literature: it outperforms the open-source solvers included in our comparison by a large amount, and performs slightly better than a commercial solver. Our empirical evaluation provides insight on which parameterizations of the algorithm are the most effective in practice. The software reviewed as part of this submission was given the Digital Object Identifier (DOI) https://doi.org/10.5281/zenodo.597767.},
author = {Costa, Alberto and Nannicini, Giacomo},
doi = {10.1007/s12532-018-0144-7},
file = {::},
issn = {18672957},
journal = {Mathematical Programming Computation},
keywords = {Black-box optimization,Derivative-free optimization,Global optimization,Mixed-integer nonlinear programming,Open-source software,Radial basis function},
month = {dec},
number = {4},
pages = {597--629},
publisher = {Springer Verlag},
title = {{RBFOpt: an open-source library for black-box optimization with costly function evaluations}},
url = {https://doi.org/10.1007/s12532-018-0144-7},
volume = {10},
year = {2018}
}
@article{Houska2016a,
abstract = {This paper is about distributed derivative-based algorithms for solving optimization problems with a separable (potentially nonconvex) objective function and coupled affine constraints. A parallelizable method is proposed that combines ideas from the fields of sequential quadratic programming and augmented Lagrangian algorithms. The method negotiates shared dual variables that may be interpreted as prices, a concept employed in dual decomposition methods and the alternating direction method of multipliers (ADMM). Here, each agent solves its own small-scale nonlinear programming problem and communicates with other agents by solving coupled quadratic programming problems. These coupled quadratic programming problems have equality constraints for which parallelizable methods are available. The use of techniques associated with standard sequential quadratic programming methods gives a method with superlinear or quadratic convergence rate under suitable conditions. This is in contrast to existing decomposition methods, such as ADMM, which have a linear convergence rate. It is shown how the proposed algorithm may be extended using globalization techniques that guarantee convergence to a local minimizer from any initial starting point.},
author = {Houska, Boris and Frasch, Janick and Diehl, Moritz},
doi = {10.1137/140975991},
issn = {10526234},
journal = {SIAM Journal on Optimization},
keywords = {Distributed algorithms,Large-scale problems,Nonconvex optimization},
title = {{An augmented Lagrangian based algorithm for distributed nonconvex optimization}},
year = {2016}
}
@techreport{MichaelShi2021,
abstract = {The goal of this paper is to investigate an approach for derivative-free optimization that has not received sufficient attention in the literature and is yet one of the simplest to implement and parallelize. It consists of computing gradients of a smoothed approximation of the objective function (and constraints), and employing them within established codes. These gradient approximations are calculated by finite differences, with a differencing interval determined by the noise level in the functions and a bound on the second or third derivatives. It is assumed that noise level is known or can be estimated by means of difference tables or sampling. The use of finite differences has been largely dismissed in the derivative-free optimization literature as too expensive in terms of function evaluations and/or as impractical when the objective function contains noise. The test results presented in this paper suggest that such views should be reexamined and that the finite-difference approach has much to be recommended. The tests compared newuoa, dfo-ls and cobyla against the finite-difference approach on three classes of problems: general unconstrained problems, nonlinear least squares, and general nonlinear programs with equality constraints.},
archivePrefix = {arXiv},
arxivId = {2102.09762v1},
author = {{Michael Shi}, Hao-Jun and {Qiming Xuan}, Melody and Oztoprak, Figen and Nocedal, Jorge},
eprint = {2102.09762v1},
file = {::},
keywords = {derivative-free optimization,noisy optimization,nonlinear optimization *,zeroth-order optimiza-tion},
title = {{On the Numerical Performance of Derivative-Free Optimization Methods Based on Finite-Difference Approximations}},
year = {2021}
}
@article{Bertsekas1979a,
abstract = {In order for primal-dual methods to be applicable to a constrained minimization problem, it is necessary that restrictive convexity conditions are satisfied. In this paper, we consider a procedure by means of which a nonconvex problem is convexified and transformed into one which can be solved with the aid of primal-dual methods. Under this transformation, separability of the type necessary for application of decomposition algorithms is preserved. This feature extends the range of applicability of such algorithms to nonconvex problems. Relations with multiplier methods are explored with the aid of a local version of the notion of a conjugate convex function.},
author = {Bertsekas, D. P.},
doi = {10.1007/BF00937167},
file = {:C\:/Users/dv516/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Bertsekas - 1979 - Convexification procedures and decomposition methods for nonconvex optimization problems.pdf:pdf},
issn = {0022-3239},
journal = {Journal of Optimization Theory and Applications},
keywords = {Applications of Mathematics,Calculus of Variations and Optimal Control,Engineering,Operations Research/Decision Theory,Optimization,Theory of Computation,general},
month = {oct},
number = {2},
pages = {169--197},
publisher = {Springer},
title = {{Convexification procedures and decomposition methods for nonconvex optimization problems}},
url = {http://link.springer.com/10.1007/BF00937167},
volume = {29},
year = {1979}
}
@article{Morinelly2016a,
abstract = {An adaptive optimal control algorithm for systems with uncertain dynamics is formulated under a Reinforcement Learning framework. An embedded exploratory component is included explicitly in the objective function of an output feedback receding horizon Model Predictive Control problem. The optimization is formulated as a Quadratically Constrained Quadratic Program and it is solved to e-global optimality. The iterative interaction between the action specified by the optimal solution and the approximation of cost functions balances the exploitation of current knowledge and the need for exploration. The proposed method is shown to converge to the optimal policy for a controllable discrete time linear plant with unknown output parameters.},
author = {Morinelly, Juan E. and Ydstie, B. Erik},
doi = {10.1016/J.IFACOL.2016.07.276},
file = {:C\:/Users/dv516/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Morinelly, Ydstie - 2016 - Dual MPC with Reinforcement Learning.pdf:pdf},
issn = {2405-8963},
journal = {IFAC-PapersOnLine},
month = {jan},
number = {7},
pages = {266--271},
publisher = {Elsevier},
title = {{Dual MPC with Reinforcement Learning}},
url = {https://www.sciencedirect.com/science/article/pii/S2405896316304839},
volume = {49},
year = {2016}
}
@article{Boukouvala2017a,
abstract = {The algorithmic framework ARGONAUT is presented for the global optimization of general constrained grey-box problems. ARGONAUT incorporates variable selection, bounds tightening and constrained sampling techniques, in order to develop accurate surrogate representations of unknown equations, which are globally optimized. ARGONAUT is tested on a large set of test problems for constrained global optimization with a large number of input variables and constraints. The performance of the presented framework is compared to that of existing techniques for constrained derivative-free optimization.},
author = {Boukouvala, Fani and Floudas, Christodoulos A},
doi = {10.1007/s11590-016-1028-2},
file = {::},
keywords = {Derivative-free optimization,General constraints,Grey-box optimization,Nonlinear programming,Surrogate modeling,Variable selection},
pages = {895--913},
title = {{ARGONAUT: AlgoRithms for Global Optimization of coNstrAined grey-box compUTational problems}},
volume = {11},
year = {2017}
}
@techreport{Leung2009,
author = {Leung, Michelle},
file = {::},
title = {{Production Scheduling Optimization of a Plastics Compounding Plant with Quality Constraints}},
url = {https://uwspace.uwaterloo.ca/bitstream/handle/10012/4210/Leung_Michelle.pdf;sequence=1},
year = {2009}
}
@article{VanElzakker2014,
abstract = {In this paper we propose an MILP model to address the optimization of the tactical planning for the Fast Moving Consumer Goods (FMCG) industry. This model is demonstrated for a case containing 10 Stock-Keeping Units (SKUs), but is intractable for realistically sized problems. Therefore, we propose a decomposition based on single-SKU submodels. To account for the interaction between SKUs, slack variables are introduced into the capacity constraints. In an iterative procedure the cost of violating the capacity is slowly increased, and eventually a feasible solution is obtained. Even for the relatively small 10-SKU case, the required CPU time could be reduced from 1144. s to 175. s using the algorithm. Moreover, the algorithm was used to optimize cases of up to 1000 SKUs, whereas the full model is intractable for cases of 25 or more SKUs. The solutions obtained with the algorithm are typically within a few percent of the global optimum. {\textcopyright} 2013 Elsevier Ltd.},
author = {van Elzakker, M. A.H. and Zondervan, E. and Raikar, N. B. and Hoogland, H. and Grossmann, I. E.},
doi = {10.1016/j.compchemeng.2013.11.008},
issn = {00981354},
journal = {Computers \& Chemical Engineering},
keywords = {Decomposition algorithm,Enterprise-Wide Optimization,Fast Moving Consumer Goods,MILP,Optimization,Tactical planning},
month = {mar},
pages = {80--95},
publisher = {Pergamon},
title = {{An SKU decomposition algorithm for the tactical planning in the FMCG industry}},
volume = {62},
year = {2014}
}
@article{DelRio-Chanona2016,
abstract = {The design and control of large-scale engineering systems, consisting of a number of interacting subsystems, is a heavily researched topic with relevance both for industry and academia. This paper presents two methodologies for optimal model-based decomposition, where an optimization problem is decomposed into several smaller sub-problems and subsequently solved by augmented Lagrangian decomposition methods. Large-scale and highly nonlinear problems commonly arise in process optimization, and could greatly benefit from these approaches, as they reduce the storage requirements and computational costs for global optimization. The strategy presented translates the problem into a constraint graph. The first approach uses a heuristic community detection algorithm to identify highly connected clusters in the optimization problem graph representation. The second approach uses a multilevel graph bisection algorithm to find the optimal partition, given a desired number of sub-problems. The partitioned graphs are translated back into decomposed sets of sub-problems with a minimal number of coupling constraints. Results show both of these methods can be used as efficient frameworks to decompose optimization problems in linear time, in comparison to traditional methods which require polynomial time.},
author = {del Rio-Chanona, Ehecatl Antonio and Fiorelli, Fabio and Vassiliadis, Vassilios S.},
doi = {10.1016/J.COMPCHEMENG.2016.03.014},
issn = {0098-1354},
journal = {Computers \& Chemical Engineering},
month = {jun},
pages = {135--148},
publisher = {Pergamon},
title = {{Automated structure detection for distributed process optimization}},
url = {https://www.sciencedirect.com/science/article/abs/pii/S0098135416300758},
volume = {89},
year = {2016}
}
@inproceedings{Zhao2005,
abstract = {The performance of the PID controller may deteriorate when the operating condition of a process fluctuates. A robust parameter tuning method to improve the PID controller performance under bounded model uncertainty is presented. First an enhanced performance criterion is proposed to reduce the overshoot and large control move. Then the robust tuning problem is formulated as a Min-Max optimization. Particle Swarm Optimization (PSO) is applied to solve the nonlinear, non-differentiable problem. Examples are given to demonstrate the effectiveness of the proposed method. Compared with other PID tuning methods, the result shows that better performance can be achieved with the model parameter fluctuation. {\textcopyright} Springer-Verlag Berlin Heidelberg 2005.},
author = {Zhao, Jun and Li, Tianpeng and Qian, Jixin},
booktitle = {Lecture Notes in Computer Science},
doi = {10.1007/11539902_118},
issn = {03029743},
number = {PART III},
pages = {948--957},
publisher = {Springer Verlag},
title = {{Application of particle swarm optimization algorithm on robust PID controller tuning}},
url = {https://link.springer.com/chapter/10.1007/11539902_118},
volume = {3612},
year = {2005}
}
@techreport{Gani2007,
author = {Gani, Rafiqul and Grossmann, Ignacio E},
file = {::},
title = {{Process Systems Engineering and CAPE-What Next?}},
year = {2007}
}
@article{Grossmann2012,
abstract = {Enterprise-wide Optimization (EWO) has become a major goal in the process industries due to the increasing pressures for remaining competitive in the global marketplace. EWO involves optimizing the supply, manufacturing and distribution activities of a company to reduce costs, inventories and environmental impact, and to maximize profits and responsiveness. Major operational items include planning, scheduling, real-time optimization and control. We provide an overview of EWO in terms of a mathematical programming framework. We first provide a brief overview of mathematical programming techniques (mixed-integer linear and nonlinear optimization methods), as well as decomposition methods, stochastic programming and modeling systems. We then address some of the major issues involved in the modeling and solution of these problems. Finally, based on the EWO program at the Center of Advanced Process Decision-making at Carnegie Mellon, we describe several applications to show the potential of this area.},
author = {Grossmann, Ignacio E.},
doi = {10.1016/J.COMPCHEMENG.2012.06.038},
file = {:C\:/Users/dv516/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Grossmann - 2012 - Advances in mathematical programming models for enterprise-wide optimization(2).pdf:pdf},
issn = {0098-1354},
journal = {Computers \& Chemical Engineering},
month = {dec},
pages = {2--18},
publisher = {Pergamon},
title = {{Advances in mathematical programming models for enterprise-wide optimization}},
url = {https://www.sciencedirect.com/science/article/abs/pii/S0098135412002220},
volume = {47},
year = {2012}
}
@article{Nelder1965,
abstract = {A method is descipted for minimization of a function of n variables, which depends on the comparison of function values at the (n+1) vertices of the general simplex, followed by the replacement of the vertex with the highest value by another point. The simplex adapts itself to the local landscape, and contracts on the final minimum. The method is shown to be effective and computationally compact. A procedure is given for the estimation of the hessian matrix on the neighbourhood of the minimum, needed in statistical estimation problems.},
author = {Nelder, J. A. and Mead, R.},
doi = {10.1093/comjnl/7.4.308},
issn = {0010-4620},
journal = {The Computer Journal},
month = {jan},
number = {4},
pages = {308--313},
publisher = {Oxford University Press (OUP)},
title = {{A Simplex Method for Function Minimization}},
url = {https://academic.oup.com/comjnl/article-lookup/doi/10.1093/comjnl/7.4.308},
volume = {7},
year = {1965}
}
@techreport{Gonzaleza,
abstract = {The popularity of Bayesian optimization methods for efficient exploration of parameter spaces has lead to a series of papers applying Gaussian processes as surrogates in the optimization of functions. However, most proposed approaches only allow the exploration of the parameter space to occur sequentially. Often, it is desirable to simultaneously propose batches of parameter values to explore. This is particularly the case when large parallel processing facilities are available. These could either be computational or physical facets of the process being optimized. Batch methods, however, require the modeling of the interaction between the different evaluations in the batch, which can be expensive in complex scenarios. We investigate this issue and propose a highly effective heuristic based on an estimate of the func-tion's Lipschitz constant that captures the most important aspect of this interaction-local repulsion-at negligible computational overhead. A penalized acquisition function is used to collect batches of points minimizing the non-parallelizable computational effort. The resulting algorithm compares very well, in run-time, with much more elaborate alternatives.},
author = {Gonz{\'{a}}lez, Javier and Dai, Zhenwen and Hennig, Philipp and Lawrence, Neil},
file = {::},
title = {{Batch Bayesian Optimization via Local Penalization}},
url = {http://sheffieldml.github.io/GPyOpt/.}
}
@article{Boukouvala2014,
abstract = {In this work, an algorithm for the optimization of costly constrained systems is introduced. The proposed method combines advantages of global- and local-search algorithms with new concepts of feasibility space mapping, within a framework that aims to find global solutions with minimum sampling. A global search is initially performed, during which kriging surrogate models of the objective and the feasible region are developed. A novel search criterion for locating feasibility boundaries is introduced, which does not require any assumptions regarding the convexity and nonlinearity of the feasible space. Finally, local search is performed starting from multiple locations identified by clustering of previously obtained samples. The performance of the proposed approach is evaluated through both benchmark examples and a case study from the pharmaceutical industry. A comparison of the method with commercially available software reveals that the proposed method has a competitive performance in terms of sampling requirements and quality of solution. {\textcopyright} 2014 American Institute of Chemical Engineers.},
author = {Boukouvala, Fani and Ierapetritou, Marianthi G.},
doi = {10.1002/aic.14442},
issn = {00011541},
journal = {AIChE Journal},
keywords = {Black-box feasibility,Constraints,Derivative-free optimization,Kriging,Surrogate-based optimization},
month = {jul},
number = {7},
pages = {2462--2474},
publisher = {John Wiley and Sons Inc.},
title = {{Derivative-free optimization for expensive constrained problems using a novel expected improvement objective function}},
url = {http://doi.wiley.com/10.1002/aic.14442},
volume = {60},
year = {2014}
}

@article{Engelmann2020,
abstract = {Decentralized optimization algorithms are of interest in different contexts, e.g., optimal power flow or distributed model predictive control, as they avoid central coordination and enable decomposition of large-scale problems. In case of constrained nonconvex problems, only a few algorithms are currently available - often with limited performance or lacking convergence guarantee. This article proposes a framework for decentralized nonconvex optimization via bi-level distribution of the augmented Lagrangian alternating direction inexact Newton (ALADIN) algorithm. Bi-level distribution means that the outer ALADIN structure is combined with an inner distribution/decentralization level solving a condensed variant of ALADIN's convex coordination quadratic program (QP) by decentralized algorithms. We provide sufficient conditions for local convergence while allowing for inexact decentralized/distributed solutions of the coordination QP. Moreover, we show how decentralized variants of conjugate gradient and alternating direction of multipliers method (ADMM) can be employed at the inner level. We draw upon examples from power systems and robotics to illustrate the performance of the proposed framework.},
author = {Engelmann, Alexander and Jiang, Yuning and Houska, Boris and Faulwasser, Timm},
doi = {10.1109/TCNS.2020.3005079},
journal = {IEEE Transactions on Control of Network Systems},
keywords = {Alternating direction of multipliers method (ADMM),augmented Lagrangian alternating direction inexact,conjugate gradient (CG),decentralized optimization,decomposition,distributed model predictive control,distributed optimal power flow,distributed optimization},
month = {dec},
number = {4},
pages = {1848--1858},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{Decomposition of Nonconvex Optimization via Bi-Level Distributed ALADIN}},
volume = {7},
year = {2020}
}
@article{Aguirre2018,
abstract = {This work presents efficient MILP-based approaches for the planning and scheduling of multiproduct multistage continuous plants with sequence-dependent changeovers in a supply chain network under demand uncertainty and price elasticity of demand. This problem considers multiproduct plants, where several products must be produced and delivered to supply the distribution centres (DCs), while DCs are in charge of storing and delivering these products to the final markets to be sold. A hybrid discrete/continuous model is proposed for this problem by using the ideas of the Travelling Salesman Problem (TSP) and global precedence representation. In order to deal with the uncertainty, we proposed a Hierarchical Model Predictive Control (HMPC) approach for this particular problem. Despite of its efficiency, the final solution reported still could be far from the global optimum. Due to this, Local Search (LS) algorithms are developed to improve the solution of HMPC by rescheduling successive products in the current schedule. The effectiveness of the proposed solution techniques is demonstrated by solving a large-scale instance and comparing the solution with the original MPC and a classic Cutting Plane approach adapted for this work.},
author = {Aguirre, Adri{\'{a}}n M. and Liu, Songsong and Papageorgiou, Lazaros G.},
doi = {10.1016/j.cherd.2018.08.021},
file = {::},
issn = {02638762},
journal = {Chemical Engineering Research and Design},
keywords = {Local Search algorithm,MILP,Model predictive control,Planning and scheduling under uncertainty,Supply chain network},
month = {oct},
pages = {341--357},
publisher = {Institution of Chemical Engineers},
title = {{Optimisation approaches for supply chain planning and scheduling under demand uncertainty}},
volume = {138},
year = {2018}
}
@article{Larson2019a,
abstract = {In many optimization problems arising from scientific, engineering and artificial intelligence applications, objective and constraint functions are available only as the output of a black-box or simulation oracle that does not provide derivative information. Such settings necessitate the use of methods for derivative-free, or zeroth-order, optimization. We provide a review and perspectives on developments in these methods, with an emphasis on highlighting recent developments and on unifying treatment of such problems in the non-linear optimization and machine learning literature. We categorize methods based on assumed properties of the black-box functions, as well as features of the methods. We first overview the primary setting of deterministic methods applied to unconstrained, non-convex optimization problems where the objective function is defined by a deterministic black-box oracle. We then discuss developments in randomized methods, methods that assume some additional structure about the objective (including convexity, separability and general non-smooth compositions), methods for problems where the output of the black-box oracle is stochastic, and methods for handling different types of constraints.},
archivePrefix = {arXiv},
arxivId = {1904.11585},
author = {Larson, Jeffrey and Menickelly, Matt and Wild, Stefan M.},
doi = {10.1017/S0962492919000060},
eprint = {1904.11585},
issn = {14740508},
journal = {Acta Numerica},
title = {{Derivative-free optimization methods}},
year = {2019}
}
@article{Li2004a,
abstract = {This paper attempts to set a unified scene for various linear time-invariant (LTI) control system design schemes, by transforming the existing concept of "computer-aided control system design" (CACSD) to novel "computer-automated control system design" (CAutoCSD). The first step towards this goal is to accommodate, under practical constraints, various design objectives that are desirable in both time and frequency domains. Such performance-prioritised unification is aimed at relieving practising engineers from having to select a particular control scheme and from sacrificing certain performance goals resulting from pre-commitment to such schemes. With recent progress in evolutionary computing based extra-numeric, multi-criterion search and optimisation techniques, such unification of LTI control schemes becomes feasible, analytical and practical, and the resultant designs can be creative. The techniques developed are applied to, and illustrated by, three design problems. The unified approach automatically provides an integrator for zero-steady state error in velocity control of a DC motor, and meets multiple objectives in the design of an LTI controller for a non-minimum phase plant and offers a high-performance LTI controller network for a non-linear chemical process.},
author = {Li, Yun and Ang, Kiam Heong and Chong, Gregory C. Y. and Feng, Wenyuan and Tan, Kay Chen and Kashiwagi, Hiroshi},
doi = {10.1007/s11633-004-0076-8},
issn = {1476-8186},
journal = {International Journal of Automation and Computing},
month = {oct},
number = {1},
pages = {76--88},
publisher = {Springer Science and Business Media LLC},
title = {{CAutoCSD-evolutionary search and optimisation enabled computer automated control system design}},
volume = {1},
year = {2004}
}
@article{Clayton2020,
abstract = {There has been an increasing interest in the use of automated self-optimising continuous flow platforms for the development and manufacture in synthesis in recent years. Such processes include multiple reactive and work-up steps, which need to be efficiently optimised. Here, we report the combination of multi-objective optimisation based on machine learning methods (TSEMO algorithm) with self-optimising platforms for the optimisation of multi-step continuous reaction processes. This is demonstrated for a pharmaceutically relevant Sonogashira reaction. We demonstrate how optimum reaction conditions are re-evaluated with the changing downstream work-up specifications in the active learning process. Furthermore, a Claisen-Schmidt condensation reaction with subsequent liquid-liquid separation was optimised with respect to three-objectives. This approach provides the ability to simultaneously optimise multi-step processes with respect to multiple objectives, and thus has the potential to make substantial savings in time and resources.},
author = {Clayton, Adam D. and Schweidtmann, Artur M. and Clemens, Graeme and Manson, Jamie A. and Taylor, Connor J. and Ni{\~{n}}o, Carlos G. and Chamberlain, Thomas W. and Kapur, Nikil and Blacker, A. John and Lapkin, Alexei A. and Bourne, Richard A.},
doi = {10.1016/j.cej.2019.123340},
file = {::},
issn = {13858947},
journal = {Chemical Engineering Journal},
keywords = {Automated flow reactor,Environmental chemistry,Machine learning,Reaction engineering,Sustainable chemistry},
month = {mar},
pages = {123340},
publisher = {Elsevier B.V.},
title = {{Automated self-optimisation of multi-step reaction and separation processes using machine learning}},
volume = {384},
year = {2020}
}
@misc{Brown2017,
abstract = {We present a method to create universal, robust, targeted adversarial image patches in the real world. The patches are universal because they can be used to attack any scene, robust because they work under a wide variety of transformations, and targeted because they can cause a classifier to output any target class. These adversarial patches can be printed, added to any scene, photographed, and presented to image classifiers; even when the patches are small, they cause the classifiers to ignore the other items in the scene and report a chosen target class.},
archivePrefix = {arXiv},
arxivId = {1712.09665},
author = {Brown, Tom B. and Man{\'{e}}, Dandelion and Roy, Aurko and Abadi, Mart{\'{i}}n and Gilmer, Justin},
booktitle = {arXiv},
eprint = {1712.09665},
issn = {23318422},
title = {{Adversarial patch}},
year = {2017}
}
@article{Bottou2016,
abstract = {This paper provides a review and commentary on the past, present, and future of numerical optimization algorithms in the context of machine learning applications. Through case studies on text classification and the training of deep neural networks, we discuss how optimization problems arise in machine learning and what makes them challenging. A major theme of our study is that large-scale machine learning represents a distinctive setting in which the stochastic gradient (SG) method has traditionally played a central role while conventional gradient-based nonlinear optimization techniques typically falter. Based on this viewpoint, we present a comprehensive theory of a straightforward, yet versatile SG algorithm, discuss its practical behavior, and highlight opportunities for designing algorithms with improved performance. This leads to a discussion about the next generation of optimization methods for large-scale machine learning, including an investigation of two main streams of research on techniques that diminish noise in the stochastic directions and methods that make use of second-order derivative approximations.},
archivePrefix = {arXiv},
arxivId = {1606.04838},
author = {Bottou, L{\'{e}}on and Curtis, Frank E. and Nocedal, Jorge},
eprint = {1606.04838},
file = {::},
journal = {SIAM Review},
keywords = {Algorithm complexity analysis,Machine learning,Noise reduction methods,Numerical optimization,Second-order methods,Stochastic gradient methods},
month = {jun},
number = {2},
pages = {223--311},
publisher = {Society for Industrial and Applied Mathematics Publications},
title = {{Optimization Methods for Large-Scale Machine Learning}},
url = {http://arxiv.org/abs/1606.04838},
volume = {60},
year = {2016}
}
@article{Tsay2017,
abstract = {We present a novel design of experiments (DOE) approach to incorporate model identification into optimal experimental designs based on a postulated model superstructure and an associated relaxation strategy. We show that an adaptive online design of experiments allows for the accurate estimation of the parameters of a domain-restricted model, as well as the model structure and domain on which that model is valid. We further show that previous attempts at combining model identification and parameter estimation are a special case of this framework (when the objective function is formulated in terms of the trace of the Fisher information matrix), and thus the proposed formulation provides the option to use alternate or more complex objective functions. The efficacy of the proposed framework is shown through two case studies: a batch reactor with Arrhenius-type reactions and a carbon dioxide adsorption system.},
author = {Tsay, Calvin and Pattison, Richard C. and Baldea, Michael and Weinstein, Ben and Hodson, Steven J. and Johnson, Robert D.},
doi = {10.1016/j.compchemeng.2017.02.014},
file = {::},
issn = {00981354},
journal = {Computers \& Chemical Engineering},
keywords = {Design of experiments,Dynamic model identification,Parameter estimation},
month = {dec},
pages = {408--426},
publisher = {Elsevier Ltd},
title = {{A superstructure-based design of experiments framework for simultaneous domain-restricted model identification and parameter estimation}},
volume = {107},
year = {2017}
}
@inproceedings{Jia2004,
abstract = {The problem addressed in this work is to develop a comprehensive mathematical programming model for the efficient scheduling of oil-refinery operations. Our approach is first to decompose the overall problem spatially into three domains: the crude-oil unloading and blending, the production unit operations and the product blending and delivery. In particular, the first problem involves the crude-oil unloading from vessels, its transfer to storage tanks and the charging schedule for each crude-oil mixture to the distillation units. The second problem consists of the production unit scheduling which includes both fractionation and reaction processes and the third problem describes the finished product blending and shipping end of the refinery. Each of those sub-problems is modeled and solved in a most efficient way using continuous time representation to take advantage of the relatively smaller number of variables and constraints compared to discrete time formulation. The proposed methodology is applied to realistic case studies and significant computational savings can be achieved compared with existing approaches. {\textcopyright} 2003 Elsevier Ltd. All rights reserved.},
author = {Jia, Zhenya and Ierapetritou, Marianthi},
booktitle = {Computers \& Chemical Engineering},
doi = {10.1016/j.compchemeng.2003.09.007},
file = {::},
issn = {00981354},
keywords = {Continuous time formulation,Refinery operation,Scheduling,Spatial decomposition},
month = {jun},
number = {6-7},
pages = {1001--1019},
publisher = {Pergamon},
title = {{Efficient short-term scheduling of refinery operations based on a continuous time formulation}},
volume = {28},
year = {2004}
}
@misc{Gounaris2019,
abstract = {Enterprise-wide optimization (EWO) has become a major goal in the industry due to the increasing pressures for remaining competitive in the global marketplace. Enterprise-wide Optimization is concerned with the coordinated optimization of the operations in the full supply chain, including R&D, sourcing of raw materials, production operations, and distribution of final products. Process supply chains range from those in the petroleum industry to the ones in the pharmaceutical industry, and include manufacturing as a major component. The main objectives in EWO include maximization of profits or minimization of costs, responsiveness to customers, asset utilization, management of inventory levels, and the improvement of a supply chain's ecological footprint. Major operational activities include planning, scheduling , real-time optimization and control. A major challenge that is involved in EWO of process industries is the integrated and coordinated decision-making across the various functions in a company (purchasing, manufacturing, distribution, sales), across various geographically distributed organizations (vendors, facilities, markets), and across various levels of decision-making (strategic, tactical, operational). One of the key features in EWO is the integration of information and decision-making among the various functions that comprise the supply chain of the company. Integration of information is being achieved with modern IT tools. While these tools allow many groups in an enterprise to access the same information, they do not provide comprehensive decision making capabilities for optimization that account for complex trade-offs and interactions across the various functions, subsystems and levels of decision making. In order to realize the full potential of such integrated supply chains, the development of sophisticated decision-support tools based on mathematical programming is needed Grossmann (2012).},
author = {Gounaris, Chrysanthos E. and Grossmann, Ignacio E.},
booktitle = {Optimization and Engineering},
doi = {10.1007/s11081-019-09468-9},
file = {:C\:/Users/dv516/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Gounaris, Grossmann - 2019 - A preface to the special issue on enterprise-wide optimization.pdf:pdf},
issn = {15732924},
keywords = {Control,Engineering,Environmental Management,Financial Engineering,Operations Research/Decision Theory,Optimization,Systems Theory,general},
month = {dec},
number = {4},
pages = {965--968},
publisher = {Springer New York LLC},
title = {{A preface to the special issue on enterprise-wide optimization}},
url = {https://doi.org/10.1007/s11081-019-09468-9},
volume = {20},
year = {2019}
}
@article{Hullen2020a,
abstract = {Optimization using data from complex simulations has become an attractive decision-making option, due to ability to embed high-fidelity, non-linear understanding of processes within the search for optimal values. Due to lack of tractable algebraic equations, the link between simulations and optimization is oftentimes a surrogate metamodel. However, several forms of uncertainty exist within the cycle that links simulation data, to metamodels, to optimization. Uncertainty may originate from parameters of the simulation, or the form and fitted parameters of the metamodel. This paper reviews different literatures that are relevant to surrogate-based optimization and proposes different strategies for handling uncertainty, by combining machine learning with stochastic programming, robust optimization, and discrepancy modeling. We show that incorporating uncertainty management within simulation-based optimization leads to more robust solutions, which protect the decision-maker from infeasible solutions. We present the results of our proposed approaches through a case study for direct-air capture through temperature swing adsorption.},
author = {H{\"{u}}llen, Gordon and Zhai, Jianyuan and Kim, Sun Hye and Sinha, Anshuman and Realff, Matthew J. and Boukouvala, Fani},
doi = {10.1016/j.compchemeng.2019.106519},
file = {:C\:/Users/dv516/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/H{\"{u}}llen et al. - 2020 - Managing uncertainty in data-driven simulation-based optimization.pdf:pdf},
issn = {00981354},
journal = {Computers \& Chemical Engineering},
keywords = {Direct air capture,Neural networks,Polynomial interpolation,Simulation optimization,Surrogate modeling},
month = {may},
pages = {106519},
publisher = {Elsevier Ltd},
title = {{Managing uncertainty in data-driven simulation-based optimization}},
volume = {136},
year = {2020}
}
@inproceedings{Kouzoupis2016,
abstract = {Nonlinear Model Predictive Control (NMPC) requires the online solution of a nonlinear Optimal Control Problem (OCP) at each sampling instant. This paper presents a novel, block based and highly parallelizable algorithm which solves nonlinear OCPs using a recently proposed Augmented Lagrangian based method (ALADIN). The latter employs techniques from standard Sequential Quadratic Programming (SQP) methods within a more parallelizable framework. An implementation tailored to optimal control is proposed where Nonlinear Programs (NLPs) are solved approximately and concurrently on each stage while a centralized consensus step is used to update the dual variables of the coupling constraints. The implementation also comprises algorithmic concepts to extend the parallelizability of the consensus step and a blocking technique to accelerate convergence. The performance of the resulting scheme is illustrated using as benchmark example the control of an overhead crane.},
author = {Kouzoupis, Dimitris and Quirynen, Rien and Houska, Boris and Diehl, Moritz},
booktitle = {Proceedings of the American Control Conference},
doi = {10.1109/ACC.2016.7525066},
isbn = {9781467386821},
issn = {07431619},
title = {{A block based ALADIN scheme for highly parallelizable direct Optimal Control}},
year = {2016}
}
@article{Abbas2019,
abstract = {<p>Although an analytical design approach-based digital controller—which is essentially a deadbeat controller—shows zero steady-state error and no intersampling oscillations, it takes a finite number of sampling periods to settle down to a steady-state value. This paper describes the application of a derivative-free Nelder–Mead (N–M) simplex method to the digital controller for retuning of its coefficients intelligently to ensure improved settling and rise times without disturbing the deadbeat controller characteristics (i.e., no ripples between the sampling periods and no steady-state error). A switching-mode buck regulator working at 1 MHz in continuous conduction mode (CCM) is considered as a plant. Numerical simulation results depict that the N–M algorithm-based optimized digital controller not only shows improved steady-state and transient performance but also guarantees rigorous robustness against model uncertainty and disturbance as compared to its traditional counterpart, as well as the other optimized digital controller fine-tuned through other derivative-free metaheuristic optimization techniques, such as the genetic algorithm (GA). A system generator-based hardware software co-simulation is also performed to validate the simulation results.</p>},
author = {Abbas, Ghulam and Nazeer, Muhammad Qumar and Balas, Valentina E. and Lin, Tsung-Chih and Balas, Marius M. and Asad, Muhammad Usman and Raza, Ali and Shehzad, Muhammad Naeem and Farooq, Umar and Gu, Jason},
doi = {10.3390/en12112183},
file = {:C\:/Users/dv516/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Abbas et al. - 2019 - Derivative-Free Direct Search Optimization Method for Enhancing Performance of Analytical Design Approach-Based Di.pdf:pdf},
issn = {1996-1073},
journal = {Energies},
keywords = {Analytical design approach based digital controlle,Engineering optimization,Nelder–Mead simplex method,Switching regulator},
month = {jun},
number = {11},
pages = {2183},
publisher = {MDPI AG},
title = {{Derivative-Free Direct Search Optimization Method for Enhancing Performance of Analytical Design Approach-Based Digital Controller for Switching Regulator}},
url = {https://www.mdpi.com/1996-1073/12/11/2183},
volume = {12},
year = {2019}
}
@article{Coulson2018a,
abstract = {We consider the problem of optimal trajectory tracking for unknown systems. A novel data-enabled predictive control (DeePC) algorithm is presented that computes optimal and safe control policies using real-time feedback driving the unknown system along a desired trajectory while satisfying system constraints. Using a finite number of data samples from the unknown system, our proposed algorithm uses a behavioural systems theory approach to learn a non-parametric system model used to predict future trajectories. The DeePC algorithm is shown to be equivalent to the classical and widely adopted Model Predictive Control (MPC) algorithm in the case of deterministic linear time-invariant systems. In the case of nonlinear stochastic systems, we propose regularizations to the DeePC algorithm. Simulations are provided to illustrate performance and compare the algorithm with other methods.},
archivePrefix = {arXiv},
arxivId = {1811.05890},
author = {Coulson, Jeremy and Lygeros, John and D{\"{o}}rfler, Florian},
eprint = {1811.05890},
file = {:C\:/Users/dv516/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Coulson, Lygeros, D{\"{o}}rfler - 2018 - Data-Enabled Predictive Control In the Shallows of the DeePC.pdf:pdf},
month = {nov},
title = {{Data-Enabled Predictive Control: In the Shallows of the DeePC}},
url = {http://arxiv.org/abs/1811.05890},
year = {2018}
}
@misc{Clayton2019,
abstract = {Self-optimising chemical systems have experienced a growing momentum in recent years, with the evolution of self-optimising platforms leading to their application for reaction screening and chemical synthesis. With the desire for improved process sustainability, self-optimisation provides a cheaper, faster and greener approach to the chemical development process. The use of such platforms aims to enhance the capabilities of the researcher by removing the need for labor-intensive experimentation, allowing them to focus on more challenging tasks. The establishment of these systems have enabled opportunities for self-optimising platforms to become a key element of a laboratory's repertoire. To enable the wider adoption of self-optimising chemical platforms, this review summarises the history of algorithmic usage in chemical reaction self-optimisation, detailing the functionality of the algorithms and their applications in a way that is accessible for chemists and highlights opportunities for the further exploitation of algorithms in chemical synthesis moving forward.},
author = {Clayton, Adam D. and Manson, Jamie A. and Taylor, Connor J. and Chamberlain, Thomas W. and Taylor, Brian A. and Clemens, Graeme and Bourne, Richard A.},
booktitle = {Reaction Chemistry and Engineering},
doi = {10.1039/c9re00209j},
issn = {20589883},
month = {sep},
number = {9},
pages = {1545--1554},
publisher = {Royal Society of Chemistry},
title = {{Algorithms for the self-optimisation of chemical reactions}},
url = {https://pubs.rsc.org/en/content/articlehtml/2019/re/c9re00209j https://pubs.rsc.org/en/content/articlelanding/2019/re/c9re00209j},
volume = {4},
year = {2019}
}
@article{Sorek2017a,
abstract = {The objective of this paper is to introduce a novel paradigm to reduce the computational effort in waterflooding global optimization problems while realizing smooth well control trajectories amenable for practical deployments in the field. In order to overcome the problems of slow convergence and non-smooth impractical control strategies, often associated with gradient-free optimization (GFO) methods, we introduce a generalized approach which represent the controls by smooth polynomial approximations either by a polynomial function or by a piecewise polynomial interpolation, which we denote as function control method (FCM) and interpolation control method (ICM), respectively. Using these approaches, we aim to optimize the coefficients of the selected functions or the interpolation points in order to represent the well-control trajectories along a time horizon. Our results demonstrate significant computational savings, due to a substantial reduction in the number of control parameters, as we seek the optimal polynomial coefficients or the interpolation points to describe the control trajectories as opposed to directly searching for the optimal control values (bottom hole pressure) at each time interval. We demonstrate the efficiency of the method on two and three-dimensional models, where we found the optimal variables using a parallel dynamic-neighborhood particle swarm optimization (PSO). We compared our FCM-PSO and ICM-PSO to the traditional formulation solved by both gradient-free and gradient-based methods. In all comparisons, both FCM and ICM show very good to superior performances.},
author = {Sorek, Nadav and Gildin, Eduardo and Boukouvala, Fani and Beykal, Burcu and Floudas, Christodoulos A.},
doi = {10.1007/s10596-016-9610-3},
issn = {15731499},
journal = {Computational Geosciences},
keywords = {Adjoint method,Control set cardinality reduction,Optimization dimensionality reduction,Parametrization,Particle swarm optimization,Polynomial control method,Production optimization,Smooth well-control,Waterflooding optimization},
month = {apr},
number = {2},
pages = {247--266},
publisher = {Springer International Publishing},
title = {{Dimensionality reduction for production optimization using polynomial approximations}},
url = {https://link.springer.com/article/10.1007/s10596-016-9610-3},
volume = {21},
year = {2017}
}
@article{Coulson2018b,
abstract = {We consider the problem of optimal trajectory tracking for unknown systems. A novel data-enabled predictive control (DeePC) algorithm is presented that computes optimal and safe control policies using real-time feedback driving the unknown system along a desired trajectory while satisfying system constraints. Using a finite number of data samples from the unknown system, our proposed algorithm uses a behavioural systems theory approach to learn a non-parametric system model used to predict future trajectories. The DeePC algorithm is shown to be equivalent to the classical and widely adopted Model Predictive Control (MPC) algorithm in the case of deterministic linear time-invariant systems. In the case of nonlinear stochastic systems, we propose regularizations to the DeePC algorithm. Simulations are provided to illustrate performance and compare the algorithm with other methods.},
archivePrefix = {arXiv},
arxivId = {1811.05890},
author = {Coulson, Jeremy and Lygeros, John and D{\"{o}}rfler, Florian},
eprint = {1811.05890},
file = {:C\:/Users/dv516/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Coulson, Lygeros, D{\"{o}}rfler - 2018 - Data-Enabled Predictive Control In the Shallows of the DeePC.pdf:pdf},
month = {nov},
title = {{Data-Enabled Predictive Control: In the Shallows of the DeePC}},
url = {http://arxiv.org/abs/1811.05890},
year = {2018}
}
@article{Wachter2006,
abstract = {We present a primal-dual interior-point algorithm with a filter line-search method for nonlinear programming. Local and global convergence properties of this method were analyzed in previous work. Here we provide a comprehensive description of the algorithm, including the feasibility restoration phase for the filter method, second-order corrections, and inertia correction of the KKT matrix. Heuristics are also considered that allow faster performance. This method has been implemented in the IPOPT code, which we demonstrate in a detailed numerical study based on 954 problems from the CUTEr test set. An evaluation is made of several line-search options, and a comparison is provided with two state-of-the-art interior-point codes for nonlinear programming.},
author = {W{\"{a}}chter, Andreas and Biegler, Lorenz T.},
doi = {10.1007/s10107-004-0559-y},
file = {::},
issn = {00255610},
journal = {Mathematical Programming},
keywords = {Barrier method,Filter method,Interior-point method,Line search,Nonconvex constrained optimization,Nonlinear programming},
month = {may},
number = {1},
pages = {25--57},
publisher = {Springer},
title = {{On the implementation of an interior-point filter line-search algorithm for large-scale nonlinear programming}},
url = {https://link.springer.com/article/10.1007/s10107-004-0559-y},
volume = {106},
year = {2006}
}
@article{Geoffrion1972,
abstract = {J. F. Benders devised a clever approach for exploiting the structure of mathematical programming problems with complicating variables (variables which, when temporarily fixed, render the remaining optimization problem considerably more tractable). For the class of problems specifically considered by Benders, fixing the values of the complicating variables reduces the given problem to an ordinary linear program, parameterized, of course, by the value of the complicating variables vector. The algorithm he proposed for finding the optimal value of this vector employs a cutting-plane approach for building up adequate representations of (i) the extremal value of the linear program as a function of the parameterizing vector and (ii) the set of values of the parameterizing vector for which the linear program is feasible. Linear programming duality theory was employed to derive the natural families of cuts characterizing these representations, and the parameterized linear program itself is used to generate what are usually deepest cuts for building up the representations. In this paper, Benders' approach is generalized to a broader class of programs in which the parametrized subproblem need no longer be a linear program. Nonlinear convex duality theory is employed to derive the natural families of cuts corresponding to those in Benders' case. The conditions under which such a generalization is possible and appropriate are examined in detail. An illustrative specialization is made to the variable factor programming problem introduced by R. Wilson, where it offers an especially attractive approach. Preliminary computational experience is given. {\textcopyright} 1972 Plenum Publishing Corporation.},
author = {Geoffrion, A. M.},
doi = {10.1007/BF00934810},
file = {::},
issn = {00223239},
journal = {Journal of Optimization Theory and Applications},
keywords = {Applications of Mathematics,Calculus of Variations and Optimal Control,Engineering,Operations Research/Decision Theory,Optimization,Theory of Computation,general},
month = {oct},
number = {4},
pages = {237--260},
publisher = {Kluwer Academic Publishers-Plenum Publishers},
title = {{Generalized Benders decomposition}},
url = {https://link.springer.com/article/10.1007/BF00934810},
volume = {10},
year = {1972}
}
@article{Diamond2016,
abstract = {CVXPY is a domain-specific language for convex optimization embedded in Python. It allows the user to express convex optimization problems in a natural syntax that follows the math, rather than in the restrictive standard form required by solvers. CVXPY makes it easy to combine convex optimization with high-level features of Python such as parallelism and object-oriented design. CVXPY is available at http://www.cvxpy.org/ under the GPL license, along with documentation and examples.},
archivePrefix = {arXiv},
arxivId = {1603.00943},
author = {Diamond, Steven and Boyd, Stephen},
eprint = {1603.00943},
file = {::},
journal = {Journal of Machine Learning Research},
keywords = {Conic programming,Convex optimization,Convexity verification,Domain-specific languages,Python},
month = {mar},
pages = {1--5},
publisher = {Microtome Publishing},
title = {{CVXPY: A Python-Embedded Modeling Language for Convex Optimization}},
url = {http://arxiv.org/abs/1603.00943},
volume = {17},
year = {2016}
}

@article{DelRio-Chanona2016a,
abstract = {The design and control of large-scale engineering systems, consisting of a number of interacting subsystems, is a heavily researched topic with relevance both for industry and academia. This paper presents two methodologies for optimal model-based decomposition, where an optimization problem is decomposed into several smaller sub-problems and subsequently solved by augmented Lagrangian decomposition methods. Large-scale and highly nonlinear problems commonly arise in process optimization, and could greatly benefit from these approaches, as they reduce the storage requirements and computational costs for global optimization. The strategy presented translates the problem into a constraint graph. The first approach uses a heuristic community detection algorithm to identify highly connected clusters in the optimization problem graph representation. The second approach uses a multilevel graph bisection algorithm to find the optimal partition, given a desired number of sub-problems. The partitioned graphs are translated back into decomposed sets of sub-problems with a minimal number of coupling constraints. Results show both of these methods can be used as efficient frameworks to decompose optimization problems in linear time, in comparison to traditional methods which require polynomial time.},
author = {del Rio-Chanona, Ehecatl Antonio and Fiorelli, Fabio and Vassiliadis, Vassilios S.},
doi = {10.1016/J.COMPCHEMENG.2016.03.014},
issn = {0098-1354},
journal = {Computers \& Chemical Engineering},
month = {jun},
pages = {135--148},
publisher = {Pergamon},
title = {{Automated structure detection for distributed process optimization}},
url = {https://www.sciencedirect.com/science/article/abs/pii/S0098135416300758},
volume = {89},
year = {2016}
}
@article{Bozarth2009a,
abstract = {This paper puts forth a model of supply chain complexity and empirically tests it using plant-level data from 209 plants across seven countries. The results show that upstream complexity, internal manufacturing complexity, and downstream complexity all have a negative impact on manufacturing plant performance. Furthermore, supply chain characteristics that drive dynamic complexity are shown to have a greater impact on performance than those that drive only detail complexity. In addition to providing a definition and empirical test of supply chain complexity, the study serves to link the systems complexity literature to the prescriptions found in the flexibility and lean production literatures. Finally, this research establishes a base from which to extend previous work linking operations strategy to organization design [Flynn, B.B., Flynn, E.J., 1999. Information-processing alternatives for coping with manufacturing environment complexity. Decision Sciences 30 (4), 1021-1052]. {\textcopyright} 2008 Elsevier B.V. All rights reserved.},
author = {Bozarth, Cecil C. and Warsing, Donald P. and Flynn, Barbara B. and Flynn, E. James},
doi = {10.1016/j.jom.2008.07.003},
file = {::},
issn = {02726963},
journal = {Journal of Operations Management},
keywords = {Empirical research methods,Manufacturing strategy,Supply chain complexity,Supply chain management,Supply management},
month = {jan},
number = {1},
pages = {78--93},
title = {{The impact of supply chain complexity on manufacturing plant performance}},
volume = {27},
year = {2009}
}
@article{Kohler2017a,
abstract = {In this work, we propose a sequential distributed MPC algorithm for control of a linear supply chain. The algorithm is developed by closely taking into account supply chain specifics and requirements from practice, e.g., orders and leavings are both treated as decision variables at each stage and communication between stages is kept low. We present the rather surprising result that terminal equality constraints employed in the local MPC formulations are inherently satisfied for the overall system, despite the presence of bilateral dynamic couplings and solving the local MPC problems sequentially. This is due to the stock and flow nature of the problem. The proposed algorithm is shown to be recursively feasible, to asymptotically satisfy a constant customer demand and to achieve asymptotic convergence of the local stock and backlog to the desired levels. This is illustrated by numerical simulations.},
author = {K{\"{o}}hler, Philipp N. and M{\"{u}}ller, Matthias A. and Pannek, J{\"{u}}rgen and Allg{\"{o}}wer, Frank},
doi = {10.1016/J.IFACOL.2017.08.706},
file = {:C\:/Users/dv516/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/K{\"{o}}hler et al. - 2017 - On Exploitation of Supply Chain Properties by Sequential Distributed MPC.pdf:pdf},
issn = {2405-8963},
journal = {IFAC-PapersOnLine},
month = {jul},
number = {1},
pages = {7947--7952},
publisher = {Elsevier},
title = {{On Exploitation of Supply Chain Properties by Sequential Distributed MPC}},
url = {https://www.sciencedirect.com/science/article/pii/S2405896317311473},
volume = {50},
year = {2017}
}
@article{Duran1986,
abstract = {An outer-approximation algorithm is presented for solving mixed-integer nonlinear programming problems of a particular class. Linearity of the integer (or discrete) variables, and convexity of the nonlinear functions involving continuous variables are the main features in the underlying mathematical structure. Based on principles of decomposition, outer-approximation and relaxation, the proposed algorithm effectively exploits the structure of the problems, and consists of solving an alternating finite sequence of nonlinear programming subproblems and relaxed versions of a mixed-integer linear master program. Convergence and optimality properties of the algorithm are presented, as well as a general discussion on its implementation. Numerical results are reported for several example problems to illustrate the potential of the proposed algorithm for programs in the class addressed in this paper. Finally, a theoretical comparison with generalized Benders decomposition is presented on the lower bounds predicted by the relaxed master programs. {\textcopyright} 1986 The Mathematical Programming Society, Inc.},
author = {Duran, Marco A. and Grossmann, Ignacio E.},
doi = {10.1007/BF02592064},
file = {::},
issn = {00255610},
journal = {Mathematical Programming},
keywords = {Mixed-integer nonlinear programming,computer-aided design,cutting planes,decomposition,outer-approximation},
month = {oct},
number = {3},
pages = {307--339},
publisher = {Springer},
title = {{An outer-approximation algorithm for a class of mixed-integer nonlinear programs}},
url = {https://link.springer.com/article/10.1007/BF02592064},
volume = {36},
year = {1986}
}
@techreport{Simon1962,
author = {Simon, Herbert A},
booktitle = {Proceedings of the American Philosophical Society},
file = {::},
number = {6},
pages = {467--482},
title = {{The Architecture of Complexity}},
volume = {106},
year = {1962}
}
@techreport{Huyer,
abstract = {The software package Snobfit for bound constrained (and soft constrained) noisy optimization of an expensive objective function is described. It combines global and local search by branching and local fits. The program is made robust and flexible for practical use by allowing for hidden constraints, batch function evaluations, change of search regions, etc.},
author = {Huyer, Waltraud and Neumaier, Arnold},
file = {::},
keywords = {G16 [Optimization]: Global optimization; Constrain,derivative-free,expensive function values,hidden constraints,noisy function values,parallel evaluation,soft constraints,surrogate model},
title = {{Snobfit-Stable Noisy Optimization by Branch and Fit}}
}

@article{Pison,
author = {Arauz Pison, Teresa and Chanfreut, Paula and Maestre, J.M.},
year = {2021},
month = {11},
pages = {},
title = {Cyber-security in networked and distributed model predictive control},
journal = {Annual Reviews in Control},
doi = {10.1016/j.arcontrol.2021.10.005}
}

@inproceedings{Rantzer2009a,
author = {Rantzer, Anders},
booktitle = {2009 American Control Conference},
doi = {10.1109/ACC.2009.5160224},
isbn = {978-1-4244-4523-3},
pages = {884--888},
publisher = {IEEE},
title = {{Dynamic dual decomposition for distributed control}},
url = {http://ieeexplore.ieee.org/document/5160224/},
year = {2009}
}
@inproceedings{Burk2020,
abstract = {This paper extends the recently introduced ALADIN algorithm to non-convex continuous-time optimal con- trol problems with nonlinear dynamics and linear coupling constraints. The algorithm alternates between solving a con- vexified local problem in a distributed manner and a linearized quadratic problem on a centralized entity while using the solution of both for an update step. This paper presents an analysis of the local convergence of the algorithm and shows a quadratic convergence rate. Furthermore, a globalization strategy is presented that ensures global convergence. The paper closes with a numerical evaluation of the algorithm.},
address = {Jeju Island, Republic of Korea, December 14-18, 2020},
author = {Burk, Daniel and V{\"{o}}lz, Andreas and Graichen, Knut},
file = {::},
isbn = {9781728174464},
keywords = {ALADIN,distributed MPC,distributed optimisation},
mendeley-tags = {ALADIN,distributed MPC,distributed optimisation},
number = {59th IEEE Conference on Decision and Control (CDC)},
pages = {4387--4392},
title = {{Distributed Optimization with ALADIN for Non-convex Optimal Control Problems}},
year = {2020}
}
@article{Hein2021,
abstract = {An accessible machine-learning tool has been developed that can accelerate the optimization of a wide range of synthetic reactions — and reveals how cognitive bias might have undermined optimization by humans. Bayesian optimization for synthetic chemistry reactions.},
author = {Hein, Jason E.},
doi = {10.1038/d41586-021-00209-6},
file = {:C\:/Users/dv516/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Hein - 2021 - Machine learning made easy for optimizing chemical reactions.pdf:pdf},
issn = {0028-0836},
journal = {Nature},
keywords = {Chemical synthesis,Chemistry,Computer science,Organic chemistry},
month = {feb},
number = {7844},
pages = {40--41},
publisher = {Springer Science and Business Media LLC},
title = {{Machine learning made easy for optimizing chemical reactions}},
url = {https://www.nature.com/articles/d41586-021-00209-6},
volume = {590},
year = {2021}
}
@article{Kohler2017,
abstract = {In this work, we propose a sequential distributed MPC algorithm for control of a linear supply chain. The algorithm is developed by closely taking into account supply chain specifics and requirements from practice, e.g., orders and leavings are both treated as decision variables at each stage and communication between stages is kept low. We present the rather surprising result that terminal equality constraints employed in the local MPC formulations are inherently satisfied for the overall system, despite the presence of bilateral dynamic couplings and solving the local MPC problems sequentially. This is due to the stock and flow nature of the problem. The proposed algorithm is shown to be recursively feasible, to asymptotically satisfy a constant customer demand and to achieve asymptotic convergence of the local stock and backlog to the desired levels. This is illustrated by numerical simulations.},
author = {K{\"{o}}hler, Philipp N. and M{\"{u}}ller, Matthias A. and Pannek, J{\"{u}}rgen and Allg{\"{o}}wer, Frank},
doi = {10.1016/J.IFACOL.2017.08.706},
file = {:C\:/Users/dv516/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/K{\"{o}}hler et al. - 2017 - On Exploitation of Supply Chain Properties by Sequential Distributed MPC.pdf:pdf},
issn = {2405-8963},
journal = {IFAC-PapersOnLine},
month = {jul},
number = {1},
pages = {7947--7952},
publisher = {Elsevier},
title = {{On Exploitation of Supply Chain Properties by Sequential Distributed MPC}},
url = {https://www.sciencedirect.com/science/article/pii/S2405896317311473},
volume = {50},
year = {2017}
}
@article{Gabay1976,
abstract = {For variational problems of the form Inf v∈V{f(Av)+g(v)}, we propose a dual method which decouples the difficulties relative to the functionals f and g from the possible ill-conditioning effects of the linear operator A. The approach is based on the use of an Augmented Lagrangian functional and leads to an efficient and simply implementable algorithm. We study also the finite element approximation of such problems, compatible with the use of our algorithm. The method is finally applied to solve several problems of continuum mechanics. {\textcopyright} 1976.},
author = {Gabay, Daniel and Mercier, Bertrand},
doi = {10.1016/0898-1221(76)90003-1},
file = {::},
issn = {08981221},
journal = {Computers and Mathematics with Applications},
month = {jan},
number = {1},
pages = {17--40},
publisher = {Pergamon},
title = {{A dual algorithm for the solution of nonlinear variational problems via finite element approximation}},
volume = {2},
year = {1976}
}
@article{Shin2019,
abstract = {We present a hierarchical optimization architecture for large-scale power networks that overcomes limitations of fully centralized and fully decentralized architectures. The architecture leverages principles of multigrid computing schemes, which are widely used in the solution of partial differential equations on massively parallel computers. The top layer of the architecture uses a coarse representation of the entire network, whereas the bottom layer is composed of a family of decentralized optimization agents each operating on a network subdomain at full resolution. We use an alternating direction method of multipliers (ADMM) framework to drive coordination of the decentralized agents. We show that state and dual information obtained from the top layer can be used to accelerate the coordination of the decentralized optimization agents and to recover optimality for the entire system. We demonstrate that the hierarchical architecture can be used to manage large collections of microgrids.},
archivePrefix = {arXiv},
arxivId = {2002.09796},
author = {Shin, Sungho and Hart, Philip and Jahns, Thomas and Zavala, Victor M.},
doi = {10.1109/TCNS.2019.2906917},
eprint = {2002.09796},
file = {::},
issn = {23255870},
journal = {IEEE Transactions on Control of Network Systems},
keywords = {Centralized,coordination,decentralized,hierarchical optimization,power networks},
month = {sep},
number = {3},
pages = {1004--1014},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{A hierarchical optimization architecture for large-scale power networks}},
volume = {6},
year = {2019}
}
@article{Wang2020,
abstract = {While many distributed optimization algorithms have been proposed for solving smooth or convex problems over the networks, few of them can handle non-convex and non-smooth problems. Based on a proximal primal-dual approach, this paper presents a new (stochastic) distributed algorithm with Nesterov momentum for accelerated optimization of non-convex and non-smooth problems. Theoretically, we show that the proposed algorithm can achieve an ǫ-stationary solution under a constant step size with O(1/ǫ 2) computation complexity and O(1/ǫ) communication complexity. When compared to the existing gradient tracking based methods, the proposed algorithm has the same order of computation complexity but lower order of communication complexity. To the best of our knowledge, the presented result is the first stochastic algorithm with the O(1/ǫ) communication complexity for non-convex and non-smooth problems. Numerical experiments for a distributed non-convex regression problem and a deep neural network based classification problem are presented to illustrate the effectiveness of the proposed algorithms.},
archivePrefix = {arXiv},
arxivId = {2011.05082v1},
author = {Wang, Zhiguo and Zhang, Jiawei and Chang, Tsung-Hui and Li, Jian and Luo, Zhi-Quan},
eprint = {2011.05082v1},
file = {::},
keywords = {Index Terms-Distributed optimization,momentum,non-convex and non-smooth optimization,stochastic optimiza-tion},
title = {{Distributed Stochastic Consensus Optimization with Momentum for Nonconvex Nonsmooth Problems}},
year = {2020}
}
@article{Rodriguez2018a,
abstract = {We study connections between the alternating direction method of multipliers (ADMM), the classical method of multipliers (MM), and progressive hedging (PH). The connections are used to derive benchmark metrics and strategies to monitor and accelerate convergence and to help explain why ADMM and PH are capable of solving complex nonconvex NLPs. Specifically, we observe that ADMM is an inexact version of MM and approaches its performance when multiple coordination steps are performed. In addition, we use the observation that PH is a specialization of ADMM and borrow Lyapunov function and primal-dual feasibility metrics used in ADMM to explain why PH is capable of solving nonconvex NLPs. This analysis also highlights that specialized PH schemes can be derived to tackle a wider range of stochastic programs and even other problem classes. Our exposition is tutorial in nature and seeks to to motivate algorithmic improvements and new decomposition strategies},
author = {Rodriguez, Jose S. and Nicholson, Bethany and Laird, Carl and Zavala, Victor M.},
doi = {10.1016/J.COMPCHEMENG.2018.08.036},
issn = {0098-1354},
journal = {Computers \& Chemical Engineering},
keywords = {ADMM,Augmented Lagrangian,Coordination,Decomposition,Large-scale,NLP},
month = {nov},
pages = {315--325},
publisher = {Pergamon},
title = {{Benchmarking ADMM in nonconvex NLPs}},
volume = {119},
year = {2018}
}
@article{Zavala2016,
abstract = {We present a systematic framework to manage conflicts among decision makers (stakeholders) arising in multiobjective design and operations of process systems. Conflicts arise in these settings because stakeholders have different opinions about objectives and\/or their relative priorities. The proposed framework factors in the opinion of all the stakeholders and computes a compromise solution that seeks to minimize disagreement among the stakeholders. A key advantage of the framework is that it does not require the computation of a Pareto front and can thus be used to address problems with many stakeholders and objectives. Examples are presented to illustrate the concepts.},
author = {Zavala, V. M.},
doi = {10.1016/B978-0-12-802032-6.00007-4},
isbn = {9780128020647},
journal = {Sustainability in the Design, Synthesis and Analysis of Chemical Engineering Processes},
keywords = {Conditional-value-at-risk metric,Decision making,Disagreement,Multiobjective,Pareto front,Stakeholders},
month = {jan},
pages = {169--180},
publisher = {Butterworth-Heinemann},
title = {{Managing Conflicts Among Decision-Makers in Multiobjective Design and Operations}},
year = {2016}
}
@article{Caspari2020,
abstract = {The flexible operation of continuous processes often requires the integration of scheduling and control. This can be achieved by top-down or bottom-up approaches. We compare the two paradigms in-silico using an air separation unit as a benchmark process. To demonstrate the top-down paradigm, we identify data-driven models of the closed-loop process dynamics based on a mechanistic model and use them in scheduling calculations that are performed offline. The resulting target trajectories are passed to a linear model predictive control (LMPC) system and implemented in the process. To demonstrate the bottom-up paradigm, we define an economic nonlinear model predictive control (eNMPC) scheme, which performs dynamic optimization using the full model in closed-loop to directly obtain the control variable profiles to be implemented in the process. We provide implementations of the process model equations as both a gPROMS and a Modelica model to encourage future comparison of approaches for flexible operation, process control, and/or handling disturbances. The performance, advantages, and disadvantages of the two strategies are analyzed using demand-response scenarios with varying levels of fluctuations in electricity prices, as well as considering the cases of known, instantaneous, and completely unknown load changes. The similarities and differences of the two approaches as relevant to flexible operation of continuous processes are discussed. Integrated scheduling and control leverages existing infrastructure and can be immediately applied to real operation tasks. Both operation strategies achieve successful process operation with remarkable economic improvements (up to 8%) compared to constant operation. eNMPC requires more computational resources, and is – at the moment – not implementable in real-time due to maximum optimization times exceeding the controller sampling time. However, eNMPC achieves up to 2.5 times higher operating cost savings compared to the top-down approach, owing in part to the more accurate modeling of key process dynamics.},
author = {Caspari, Adrian and Tsay, Calvin and Mhamdi, Adel and Baldea, Michael and Mitsos, Alexander},
doi = {10.1016/J.JPROCONT.2020.05.008},
issn = {0959-1524},
journal = {Journal of Process Control},
keywords = {Air separation units,Demand side management,Economic model predictive control,Integrated scheduling and control},
month = {jul},
pages = {50--62},
publisher = {Elsevier},
title = {{The integration of scheduling and control: Top-down vs. bottom-up}},
volume = {91},
year = {2020}
}
@article{Daoutidis2018,
abstract = {This “white paper” is a concise perspective based on a session during FIPSE 3, held in Rhodes, Greece, June 20–23, 2016. This was the third conference in the series “Future Innovation in Process Systems Engineering” (http://fi-in-pse.org), which takes place every other year in Greece, with a limited number of participants and just three topics/sessions whose objective is to pose and discuss open research challenges in Process Systems Engineering. This specific session comprised invited talks by Sigurd Skogestad and Iiro Harjunkoski, followed by short presentations by the participants and extensive discussions. The paper does not intend to provide a comprehensive review on the subject, or a detailed exposition of the concepts and problems. Its aim is to highlight open problems and directions for future research.},
author = {Daoutidis, Prodromos and Lee, Jay H. and Harjunkoski, Iiro and Skogestad, Sigurd and Baldea, Michael and Georgakis, Christos},
doi = {10.1016/J.COMPCHEMENG.2018.04.011},
issn = {0098-1354},
journal = {Computers \& Chemical Engineering},
keywords = {Integration,Operations,Planning,Plant-wide control,Scheduling},
month = {jul},
pages = {179--184},
publisher = {Pergamon},
title = {{Integrating operations and control: A perspective and roadmap for future research}},
volume = {115},
year = {2018}
}
@article{Grossmann2005a,
abstract = {Enterprise-wide optimization (EWO) is a new emerging area that lies at the interface of chemical engineering and operations research, and has become a major goal in the process industries due to the increasing pressures for remaining competitive in the global marketplace. EWO involves optimizing the operations of supply, manufacturing and distribution activities of a company to reduce costs and inventories. A major focus in EWO is the optimal operation of manufacturing facilities, which often requires the use of nonlinear process models. Major operational items include planning, scheduling, real-time optimization and inventory control. One of the key features of EWO is integration of the information and the decision-making among the various functions that comprise the supply chain of the company. This can be achieved with modern IT tools, which together with the internet, have promoted e-commerce. However, as will be discussed, to fully realize the potential of transactional IT tools, the development of sophisticated deterministic and stochastic linear/nonlinear optimization models and algorithms (analytical IT tools) is needed to explore and analyze alternatives of the supply chain to yield overall optimum economic performance, as well as high levels of customer satisfaction. An additional challenge is the integrated and coordinated decision-making across the various functions in a company (purchasing, manufacturing, distribution, sales), across various geographically distributed organizations (vendors, facilities and markets), and across various levels of decision-making (strategic, tactical and operational). {\textcopyright} 2005 American Institute of Chemical Engineers.},
author = {Grossmann, Ignacio},
doi = {10.1002/AIC.10617},
issn = {1547-5905},
journal = {AIChE Journal},
month = {jul},
number = {7},
pages = {1846--1857},
publisher = {John Wiley & Sons, Ltd},
title = {{Enterprise-wide optimization: A new frontier in process systems engineering}},
url = {https://onlinelibrary.wiley.com/doi/full/10.1002/aic.10617 https://onlinelibrary.wiley.com/doi/abs/10.1002/aic.10617 https://aiche.onlinelibrary.wiley.com/doi/10.1002/aic.10617},
volume = {51},
year = {2005}
}
@article{Gounaris2019a,
abstract = {Enterprise-wide optimization (EWO) has become a major goal in the industry due to the increasing pressures for remaining competitive in the global marketplace. Enterprise-wide Optimization is concerned with the coordinated optimization of the operations in the full supply chain, including R&D, sourcing of raw materials, production operations, and distribution of final products. Process supply chains range from those in the petroleum industry to the ones in the pharmaceutical industry, and include manufacturing as a major component. The main objectives in EWO include maximization of profits or minimization of costs, responsiveness to customers, asset utilization, management of inventory levels, and the improvement of a supply chain's ecological footprint. Major operational activities include planning, scheduling , real-time optimization and control. A major challenge that is involved in EWO of process industries is the integrated and coordinated decision-making across the various functions in a company (purchasing, manufacturing, distribution, sales), across various geographically distributed organizations (vendors, facilities, markets), and across various levels of decision-making (strategic, tactical, operational). One of the key features in EWO is the integration of information and decision-making among the various functions that comprise the supply chain of the company. Integration of information is being achieved with modern IT tools. While these tools allow many groups in an enterprise to access the same information, they do not provide comprehensive decision making capabilities for optimization that account for complex trade-offs and interactions across the various functions, subsystems and levels of decision making. In order to realize the full potential of such integrated supply chains, the development of sophisticated decision-support tools based on mathematical programming is needed Grossmann (2012).},
author = {Gounaris, Chrysanthos E. and Grossmann, Ignacio E.},
doi = {10.1007/S11081-019-09468-9},
file = {::},
isbn = {0123456789},
issn = {1573-2924},
journal = {Optimization and Engineering 2019 20:4},
keywords = {Control,Engineering,Environmental Management,Financial Engineering,Operations Research/Decision Theory,Optimization,Systems Theory,general},
month = {sep},
number = {4},
pages = {965--968},
publisher = {Springer},
title = {{A preface to the special issue on enterprise-wide optimization}},
url = {https://link.springer.com/article/10.1007/s11081-019-09468-9},
volume = {20},
year = {2019}
}

@article{Boyd2010a,
author = {Boyd, S and Parikh, N and Chu, E and Eckstein, J and Boyd, Stephen and Parikh, Neal and Chu, Eric and Peleato, Borja and Eckstein, Jonathan},
doi = {10.1561/2200000016},
file = {:C\:/Users/dv516/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Boyd et al. - 2010 - Distributed Optimization and Statistical Learning via the Alternating Direction Method of Multipliers(2).pdf:pdf},
journal = {Foundations and Trends R in Machine Learning},
number = {1},
pages = {1--122},
title = {{Distributed Optimization and Statistical Learning via the Alternating Direction Method of Multipliers}},
volume = {3},
year = {2010}
}
@book{Conn2000,
abstract = {This is the first comprehensive reference on trust-region methods, a class of numerical algorithms for the solution of nonlinear convex optimization methods. Its unified treatment covers both unconstrained and constrained problems and reviews a large part of the specialized literature on the subject. It also provides an up-to-date view of numerical optimization. Written primarily for postgraduates and researchers, the book features an extensive commented bibliography, which contains more than 1000 references by over 750 authors. The book also contains several practical comments and an entire chapter devoted to software and implementation issues. Its many illustrations, including nearly 100 figures, balance the formal and intuitive treatment of the presented topics.},
author = {Conn, Andrew R. and Gould, Nicholas I. M. and Toint, Philippe L.},
booktitle = {Trust Region Methods},
doi = {10.1137/1.9780898719857},
file = {:C\:/Users/dv516/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Conn, Gould, Toint - 2000 - Trust Region Methods.pdf:pdf},
month = {jan},
publisher = {Society for Industrial and Applied Mathematics},
title = {{Trust Region Methods}},
url = {https://epubs.siam.org/page/terms},
year = {2000}
}
@article{Lee2018,
abstract = {Machine learning (ML) has recently gained in popularity, spurred by well-publicized advances like deep learning and widespread commercial interest in big data analytics. Despite the enthusiasm, some renowned experts of the field have expressed skepticism, which is justifiable given the disappointment with the previous wave of neural networks and other AI techniques. On the other hand, new fundamental advances like the ability to train neural networks with a large number of layers for hierarchical feature learning may present significant new technological and commercial opportunities. This paper critically examines the main advances in deep learning. In addition, connections with another ML branch of reinforcement learning are elucidated and its role in control and decision problems is discussed. Implications of these advances for the fields of process and energy systems engineering are also discussed.},
author = {Lee, Jay H. and Shin, Joohyun and Realff, Matthew J.},
doi = {10.1016/J.COMPCHEMENG.2017.10.008},
file = {:C\:/Users/dv516/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Lee, Shin, Realff - 2018 - Machine learning Overview of the recent progresses and implications for the process systems engineering field.pdf:pdf},
issn = {0098-1354},
journal = {Computers \& Chemical Engineering},
month = {jun},
pages = {111--121},
publisher = {Pergamon},
title = {{Machine learning: Overview of the recent progresses and implications for the process systems engineering field}},
url = {https://www.sciencedirect.com/science/article/abs/pii/S0098135417303538},
volume = {114},
year = {2018}
}
@article{Ning2018,
abstract = {A novel data-driven stochastic robust optimization (DDSRO) framework is proposed for optimization under uncertainty leveraging labeled multi-class uncertainty data. Uncertainty data in large datasets are often collected from various conditions, which are encoded by class labels. Machine learning methods including Dirichlet process mixture model and maximum likelihood estimation are employed for uncertainty modeling. A DDSRO framework is further proposed based on the data-driven uncertainty model through a bi-level optimization structure. The outer optimization problem follows a two-stage stochastic programming approach to optimize the expected objective across different data classes; adaptive robust optimization is nested as the inner problem to ensure the robustness of the solution while maintaining computational tractability. A decomposition-based algorithm is further developed to solve the resulting multi-level optimization problem efficiently. Case studies on process network design and planning are presented to demonstrate the applicability of the proposed framework and algorithm.},
author = {Ning, Chao and You, Fengqi},
doi = {10.1016/j.compchemeng.2017.12.015},
file = {:C\:/Users/dv516/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Ning, You - 2018 - Data-driven stochastic robust optimization General computational framework and algorithm leveraging machine learning.pdf:pdf},
issn = {00981354},
journal = {Computers \& Chemical Engineering},
keywords = {Bayesian model,Big data,Machine learning,Optimization under uncertainty,Process design and operations},
month = {mar},
pages = {115--133},
publisher = {Elsevier Ltd},
title = {{Data-driven stochastic robust optimization: General computational framework and algorithm leveraging machine learning for optimization under uncertainty in the big data era}},
volume = {111},
year = {2018}
}
@article{Calfa2013,
abstract = {Motivated by a real-world industrial problem, this work deals with the integration of planning and scheduling in the operation of a network of batch plants. The network consists of single-stage, multiproduct batch plants located in different sites, which can exchange intermediate products in order to blend them to obtain finished products. The time horizon is given and divided into multiple time periods, at the end of which, the customer demands have to be exactly satisfied. The planning model is a simplified and aggregate formulation derived from the detailed precedence-based scheduling formulation. Traveling Salesman Problem (TSP) constraints are incorporated at the planning level in order to predict the sequence-dependent changeovers between groups of products, within and across time periods, without requiring the detailed timing of operations, which is performed at the scheduling level. In an effort to avoid solving the full-space, rigorous scheduling model, especially for large problem sizes, two decomposition strategies are investigated: Bilevel and Temporal Lagrangean. We demonstrate that Bilevel Decomposition is efficient for small to medium problem instances and that further decomposition of the planning problem, yielding a hybrid decomposition scheme, is advantageous for tackling a large-scale industrial test case.},
author = {Calfa, Bruno A and Agarwal, Anshul and Grossmann, Ignacio E and Wassick, John M},
doi = {10.1021/ie302788g},
file = {:C\:/Users/dv516/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Calfa et al. - 2013 - Hybrid Bilevel-Lagrangean Decomposition Scheme for the Integration of Planning and Scheduling of a Network of Batc.pdf:pdf},
title = {{Hybrid Bilevel-Lagrangean Decomposition Scheme for the Integration of Planning and Scheduling of a Network of Batch Plants}},
url = {https://pubs.acs.org/sharingguidelines},
year = {2013}
}
@article{Dias2019,
abstract = {A framework for the integration of planning and scheduling using data-driven methodologies is proposed. First, the constraints at the planning level related to the scheduling problem are identified. This includes the feasibility of production targets assigned to each planning period (which are equivalent to scheduling horizons). Then, classification methods are used to identify feasible regions from large amounts of scheduling data, and an algebraic equation for the predictor is obtained. The predictor is incorporated in the planning problem, and the integrated problem is solved to optimality. Computational studies are presented to demonstrate the performance of the proposed framework, and results show that the approach is more efficient than current practices in the integration of planning and scheduling problems.},
author = {Dias, Lisia S. and Ierapetritou, Marianthi G.},
doi = {10.1007/s11081-019-09459-w},
file = {:C\:/Users/dv516/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Dias, Ierapetritou - 2019 - Data-driven feasibility analysis for the integration of planning and scheduling problems.pdf:pdf},
issn = {15732924},
journal = {Optimization and Engineering},
keywords = {Feasibility analysis,Integrated planning and scheduling,Production planning,Scheduling of production,Supervised learning},
month = {dec},
number = {4},
pages = {1029--1066},
publisher = {Springer New York LLC},
title = {{Data-driven feasibility analysis for the integration of planning and scheduling problems}},
url = {https://doi.org/10.1007/s11081-019-09459-w},
volume = {20},
year = {2019}
}
@article{Tatara2007a,
abstract = {Control of spatially distributed systems is a challenging problem because of their complex nature, nonlinearity, and generally high order. The lack of accurate and computationally efficient model-based techniques for large, spatially distributed systems leads to challenges in controlling the system. Agent-based control structures provide a powerful tool to manage distributed systems by utilizing (organizing) local and global information obtained from the system. A hierarchical, agent-based system with local and global controller agents is developed to control networks of interconnected chemical reactors (CSTRs). The global controller agent dynamically updates local controller agent's objectives as the reactor network conditions change. One challenge posed is control of the spatial distribution of autocatalytic species in a network of reactors hosting multiple species. The multi-agent control system is able to intelligently manipulate the network flow rates such that the desired spatial distribution of species is achieved. Furthermore, the robustness and flexibility of the agent-based control system is illustrated through examples of disturbance rejection and scalability with respect to the size of the network.},
author = {Tatara, Eric and {\c{C}}ınar, Ali and Teymour, Fouad},
doi = {10.1016/J.JPROCONT.2006.06.008},
file = {:C\:/Users/dv516/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Tatara, {\c{C}}ınar, Teymour - 2007 - Control of complex distributed systems with distributed intelligent agents(2).pdf:pdf},
issn = {0959-1524},
journal = {Journal of Process Control},
month = {jun},
number = {5},
pages = {415--427},
publisher = {Elsevier},
title = {{Control of complex distributed systems with distributed intelligent agents}},
url = {https://www.sciencedirect.com/science/article/pii/S0959152406000771},
volume = {17},
year = {2007}
}
@article{Christofides2013a,
abstract = {In this paper, we provide a tutorial review of recent results in the design of distributed model predictive control systems. Our goal is to not only conceptually review the results in this area but also to provide enough algorithmic details so that the advantages and disadvantages of the various approaches can become quite clear. In this sense, our hope is that this paper would complement a series of recent review papers and catalyze future research in this rapidly evolving area. We conclude discussing our viewpoint on future research directions in this area.},
author = {Christofides, Panagiotis D. and Scattolini, Riccardo and {Mu{\~{n}}oz de la Pe{\~{n}}a}, David and Liu, Jinfeng},
doi = {10.1016/J.COMPCHEMENG.2012.05.011},
file = {:C\:/Users/dv516/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Christofides et al. - 2013 - Distributed model predictive control A tutorial review and future research directions(2).pdf:pdf},
issn = {0098-1354},
journal = {Computers \& Chemical Engineering},
month = {apr},
pages = {21--41},
publisher = {Pergamon},
title = {{Distributed model predictive control: A tutorial review and future research directions}},
url = {https://www.sciencedirect.com/science/article/pii/S0098135412001573},
volume = {51},
year = {2013}
}
@article{Christofides2013,
abstract = {In this paper, we provide a tutorial review of recent results in the design of distributed model predictive control systems. Our goal is to not only conceptually review the results in this area but also to provide enough algorithmic details so that the advantages and disadvantages of the various approaches can become quite clear. In this sense, our hope is that this paper would complement a series of recent review papers and catalyze future research in this rapidly evolving area. We conclude discussing our viewpoint on future research directions in this area.},
author = {Christofides, Panagiotis D. and Scattolini, Riccardo and {Mu{\~{n}}oz de la Pe{\~{n}}a}, David and Liu, Jinfeng},
doi = {10.1016/J.COMPCHEMENG.2012.05.011},
file = {:C\:/Users/dv516/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Christofides et al. - 2013 - Distributed model predictive control A tutorial review and future research directions(2).pdf:pdf},
issn = {0098-1354},
journal = {Computers \& Chemical Engineering},
month = {apr},
pages = {21--41},
publisher = {Pergamon},
title = {{Distributed model predictive control: A tutorial review and future research directions}},
url = {https://www.sciencedirect.com/science/article/pii/S0098135412001573},
volume = {51},
year = {2013}
}
@article{Scattolini,
abstract = {The aim of this paper is to review and to propose a classification of a number of decentralized, distributed and hierarchical control architectures for large scale systems. Attention is focused on the design approaches based on Model Predictive Control. For the considered architectures, the underlying rationale, the fields of application, the merits and limitations are discussed, the main references to the literature are reported and some future developments are suggested. Finally, a number of open problems is listed.},
author = {Scattolini, Riccardo},
doi = {10.1016/j.jprocont.2009.02.003},
file = {:C\:/Users/dv516/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Scattolini - Unknown - Architectures for distributed and hierarchical Model Predictive Control – A review.pdf:pdf},
journal = {Journal of Process Control},
keywords = {Distributed control,Hierarchical control,Model Predictive Control,Process control},
pages = {723--731},
title = {{Architectures for distributed and hierarchical Model Predictive Control – A review}},
url = {http://bme2.aut.ac.ir/$\sim$towhidkhah/mpc/seminars-ppt/90/seminar MPC/Fazane karami/Reference/Architectures for distributed and hierarchical Model Predictive Control – A review.pdf},
volume = {19}
}
@misc{Rahmaniani2017,
abstract = {The Benders decomposition algorithm has been successfully applied to a wide range of difficult optimization problems. This paper presents a state-of-the-art survey of this algorithm, emphasizing its use in combinatorial optimization. We discuss the classical algorithm, the impact of the problem formulation on its convergence, and the relationship to other decomposition methods. We introduce a taxonomy of algorithmic enhancements and acceleration strategies based on the main components of the algorithm. The taxonomy provides the framework to synthesize the literature, and to identify shortcomings, trends and potential research directions. We also discuss the use of the Benders Decomposition to develop efficient (meta-)heuristics, describe the limitations of the classical algorithm, and present extensions enabling its application to a broader range of problems.},
author = {Rahmaniani, Ragheb and Crainic, Teodor Gabriel and Gendreau, Michel and Rei, Walter},
booktitle = {European Journal of Operational Research},
doi = {10.1016/j.ejor.2016.12.005},
file = {:C\:/Users/dv516/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Rahmaniani et al. - 2017 - The Benders decomposition algorithm A literature review.pdf:pdf},
issn = {03772217},
keywords = {Acceleration techniques,Benders decomposition,Combinatorial optimization,Literature review},
month = {jun},
number = {3},
pages = {801--817},
publisher = {Elsevier B.V.},
title = {{The Benders decomposition algorithm: A literature review}},
volume = {259},
year = {2017}
}
@article{Grossmann2012a,
abstract = {Enterprise-wide Optimization (EWO) has become a major goal in the process industries due to the increasing pressures for remaining competitive in the global marketplace. EWO involves optimizing the supply, manufacturing and distribution activities of a company to reduce costs, inventories and environmental impact, and to maximize profits and responsiveness. Major operational items include planning, scheduling, real-time optimization and control. We provide an overview of EWO in terms of a mathematical programming framework. We first provide a brief overview of mathematical programming techniques (mixed-integer linear and nonlinear optimization methods), as well as decomposition methods, stochastic programming and modeling systems. We then address some of the major issues involved in the modeling and solution of these problems. Finally, based on the EWO program at the Center of Advanced Process Decision-making at Carnegie Mellon, we describe several applications to show the potential of this area.},
author = {Grossmann, Ignacio E.},
doi = {10.1016/J.COMPCHEMENG.2012.06.038},
file = {:C\:/Users/dv516/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Grossmann - 2012 - Advances in mathematical programming models for enterprise-wide optimization(2).pdf:pdf},
issn = {0098-1354},
journal = {Computers \& Chemical Engineering},
month = {dec},
pages = {2--18},
publisher = {Pergamon},
title = {{Advances in mathematical programming models for enterprise-wide optimization}},
url = {https://www.sciencedirect.com/science/article/abs/pii/S0098135412002220},
volume = {47},
year = {2012}
}
@article{Allman2019,
abstract = {Nonconvex optimization problems, such as those often seen in chemical engineering applications due to integer decisions and inherent system physics, are known to scale poorly with problem size. Decomposition methods, such as Benders or Lagrangean decomposition, offer much promise for improving solution efficiency. However, automatically identifying subproblems for use with these solution methods remains an open problem. Herein, a general algorithmic framework entitled Detection of Communities for Optimization Decomposition (DeCODe) is presented. DeCODe uses community detection, a concept originating from network theory, to generate optimization subproblems which are strongly interacting within individual subproblems but weakly interacting between different ones. The importance of communities in solving problems using decomposition solution methods is showcased via a least squares regression problem. The ability of DeCODe to identify nontrivial decompositions of optimization problems is demonstrated through a large renewable energy and chemical production optimal design problem and two mixed integer nonlinear program test problems.},
author = {Allman, Andrew and Tang, Wentao and Daoutidis, Prodromos},
doi = {10.1007/s11081-019-09450-5},
file = {:C\:/Users/dv516/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Allman, Tang, Daoutidis - 2019 - DeCODe a community-based algorithm for generating high-quality decompositions of optimization problems.pdf:pdf},
issn = {15732924},
journal = {Optimization and Engineering},
keywords = {Automated subproblem generation,Community detection,Decomposition,Structure detection,Variable–constraint graph},
month = {dec},
number = {4},
pages = {1067--1084},
publisher = {Springer New York LLC},
title = {{DeCODe: a community-based algorithm for generating high-quality decompositions of optimization problems}},
url = {https://doi.org/10.1007/s11081-019-09450-5},
volume = {20},
year = {2019}
}
@article{Biegler2014a,
abstract = {Efficient nonlinear programming (NLP) algorithms and modeling platforms have led to powerful process optimization strategies. Nevertheless, these algorithms are challenged by recent evolution and deployment of multi-scale models (such as molecular dynamics and complex fluid flow) that apply over broad time and length scales. Integrated optimization of these models requires accurate and efficient reduced models (RMs). This study develops a rigorous multi-scale optimization framework that substitutes RMs for complex original detailed models (ODMs) and guarantees convergence to the original optimization problem. Based on trust region concepts this framework leads to three related NLP algorithms for RM-based optimization. The first follows the classical gradient-based trust-region method, the second avoids gradient calculations from the ODM, and the third avoids frequent recourse to ODM evaluations, using the concept of $\epsilon$-exact RMs. We illustrate these algorithms with small examples and discuss RM-based optimization case studies that demonstrate their performance and effectiveness. {\textcopyright} 2013 Elsevier Ltd.},
author = {Biegler, Lorenz T. and dong Lang, Yi and Lin, Weijie},
doi = {10.1016/j.compchemeng.2013.07.009},
file = {:C\:/Users/dv516/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Biegler, Lang, Lin - 2014 - Multi-scale optimization for process systems engineering.pdf:pdf},
issn = {00981354},
journal = {Computers \& Chemical Engineering},
keywords = {Model reduction,Nonlinear programming,Process optimization,Trust region},
month = {jan},
pages = {17--30},
publisher = {Pergamon},
title = {{Multi-scale optimization for process systems engineering}},
volume = {60},
year = {2014}
}
@article{Sampat2019,
abstract = {Allocating utility among stakeholders is a fundamental decision-making task that arises in complex organizations, social planning, infrastructures, and markets. In this work, we reconcile concepts of fairness from the perspectives of game theory, economics, statistics, and engineering by using an axiomatic approach. Our work reveals significant deficiencies in the social welfare allocation approach (which is widely used in the engineering literature) and highlights interesting and desirable properties and connections between Nash and entropy allocation approaches.},
author = {Sampat, Apoorva M. and Zavala, Victor M.},
doi = {10.1007/s11081-019-09452-3},
file = {:C\:/Users/dv516/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Sampat, Zavala - 2019 - Fairness measures for decision-making and conflict resolution.pdf:pdf},
issn = {15732924},
journal = {Optimization and Engineering},
keywords = {Decision-making,Fairness,Optimization,Utility allocation},
month = {dec},
number = {4},
pages = {1249--1272},
publisher = {Springer New York LLC},
title = {{Fairness measures for decision-making and conflict resolution}},
url = {https://doi.org/10.1007/s11081-019-09452-3},
volume = {20},
year = {2019}
}
